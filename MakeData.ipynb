{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61044it [00:05, 11269.81it/s]\n",
      "100%|██████████| 7000/7000 [02:23<00:00, 48.82it/s]\n"
     ]
    }
   ],
   "source": [
    "## 피클파일 없을 때 실행\n",
    "\n",
    "# 메타데이터 및 텍스트 데이터 로드\n",
    "\n",
    "file_name = 'data_256.pkl'\n",
    "train_path = './train_data/%s'\n",
    "metadata = pickle.load(open('./data/sentence_gamjung2.pkl', 'rb'))\n",
    "\n",
    "target_size = 256\n",
    "\n",
    "# clean_text에 시작, 끝 추가\n",
    "# clean_text 기준 256글자 넘지 않도록 필터링\n",
    "# 각 감정 클래스가 최대한 균등하도록 샘플 추출\n",
    "# 학습 5000, 검증 1000, 테스트 1000\n",
    "\n",
    "metadata['clean_text'] = metadata['clean_text'].apply(lambda x: '\\t%s\\n' %x.strip())\n",
    "metadata = metadata[metadata['hashtag'].map(len) > 2]\n",
    "metadata = metadata[metadata['clean_text'].str.len() <= 256]\n",
    "\n",
    "hashtag_data = []\n",
    "for i, row in tqdm(metadata.iterrows()):\n",
    "    _hash = row['hashtag'].replace(\"'\", '\"')\n",
    "    pos = _hash.find('\\\\U')\n",
    "    while pos != -1:\n",
    "        _hash = _hash.replace(_hash[pos:pos+10], chr(int(_hash[pos+2:pos+10], 16)))\n",
    "        pos = _hash.find('\\\\U')\n",
    "    hashtag_data.append(json.loads(_hash))\n",
    "\n",
    "metadata['hashtag'] = hashtag_data\n",
    "del hashtag_data\n",
    "metadata = metadata[metadata['hashtag'].map(len) <= 100]\n",
    "    \n",
    "sentiment_list = ['emotion_0', 'emotion_1', 'emotion_3', 'emotion_4']\n",
    "sentiment_indices = [metadata[metadata[senti] == 1].index for senti in sentiment_list]\n",
    "data_indices = []\n",
    "\n",
    "i = 0\n",
    "condition = True\n",
    "while condition:\n",
    "    for senti in sentiment_indices:\n",
    "        if len(set(data_indices)) < 7000:\n",
    "            data_indices.append(senti[i])\n",
    "        else:\n",
    "            condition = False\n",
    "            break\n",
    "    i += 1\n",
    "    \n",
    "metadata = metadata.iloc[sorted(list(set(data_indices)))]\n",
    "\n",
    "def get_image_from_path(path):\n",
    "    image = Image.open(train_path %path)\n",
    "    size = image.size\n",
    "\n",
    "    if size[0] <= size[1]:\n",
    "        scaled_size = (target_size, int(size[1]/size[0]*target_size))\n",
    "        crop_area = (0, int((scaled_size[1]-target_size)/2), target_size, int((scaled_size[1]+target_size)/2))\n",
    "    else:\n",
    "        scaled_size = (int(size[0]/size[1]*target_size), target_size)\n",
    "        crop_area = (int((scaled_size[0]-target_size)/2), 0, int((scaled_size[0]+target_size)/2), target_size)\n",
    "\n",
    "    image = image.resize(scaled_size)\n",
    "    image = image.crop(crop_area)\n",
    "    return image\n",
    "\n",
    "def get_array_from_path(path):\n",
    "    return np.asarray(get_image_from_path(path))\n",
    "\n",
    "# 이미지 불러와서 데이터셋 생성\n",
    "image_list = [get_array_from_path(path) for path in tqdm(metadata['image_path'])]\n",
    "image_data = np.array(image_list)\n",
    "del image_list\n",
    "sentiment_data = np.array(metadata[sentiment_list])\n",
    "sentence_data = np.array(metadata['clean_text'])\n",
    "hashtag_data = np.array(metadata['hashtag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 256, 256, 3)\n",
      "(7000, 4)\n",
      "(7000,)\n",
      "(7000,)\n"
     ]
    }
   ],
   "source": [
    "print(image_data.shape)\n",
    "print(sentiment_data.shape)\n",
    "print(sentence_data.shape)\n",
    "print(hashtag_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7000/7000 [00:24<00:00, 289.07it/s]\n",
      "100%|██████████| 7000/7000 [00:00<00:00, 13008.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "use_tags = ['V', 'N', 'M', 'IC', 'XR']\n",
    "\n",
    "original_tags = [komoran.pos(s) for s in tqdm(sentence_data)]\n",
    "sentence_tags = []\n",
    "\n",
    "for tags in tqdm(original_tags):\n",
    "    sentence_tag = []\n",
    "    for tag in tags:\n",
    "        for use_tag in use_tags:\n",
    "            if tag[1].startswith(use_tag):\n",
    "                sentence_tag.append(tag)\n",
    "    sentence_tags.append(sentence_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pickle.dump([['image_data', 'sentiment_data', 'sentence_data', 'sentence_tags', 'hashtag_data', 'metadata'], [image_data, sentiment_data, sentence_data, sentence_tags, hashtag_data, metadata]], open(file_name, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keich Capstone",
   "language": "python",
   "name": "venv_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
