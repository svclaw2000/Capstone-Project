{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "target_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/sentence_gamjung2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-081789088748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./train_data/%s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/sentence_gamjung2.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# clean_text에 시작, 끝 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/sentence_gamjung2.pkl'"
     ]
    }
   ],
   "source": [
    "## 피클파일 없을 때 실행\n",
    "\n",
    "# 메타데이터 및 텍스트 데이터 로드\n",
    "\n",
    "train_path = './train_data/%s'\n",
    "metadata = pickle.load(open('./data/sentence_gamjung2.pkl', 'rb'))\n",
    "\n",
    "# clean_text에 시작, 끝 추가\n",
    "# clean_text 기준 256글자 넘지 않도록 필터링\n",
    "# 각 감정 클래스가 최대한 균등하도록 샘플 추출\n",
    "# 학습 5000, 검증 1000, 테스트 1000\n",
    "\n",
    "metadata['clean_text'] = metadata['clean_text'].apply(lambda x: '\\t%s\\n' %x.strip())\n",
    "metadata = metadata[metadata['clean_text'].str.len() <= 256]\n",
    "\n",
    "sentiment_list = ['emotion_0', 'emotion_1', 'emotion_3', 'emotion_4']\n",
    "sentiment_indices = [metadata[metadata[senti] == 1].index for senti in sentiment_list]\n",
    "data_indices = []\n",
    "\n",
    "i = 0\n",
    "condition = True\n",
    "while condition:\n",
    "    for senti in sentiment_indices:\n",
    "        if len(set(data_indices)) < 7000:\n",
    "            data_indices.append(senti[i])\n",
    "        else:\n",
    "            condition = False\n",
    "            break\n",
    "    i += 1\n",
    "    \n",
    "metadata = metadata.iloc[sorted(list(set(data_indices)))]\n",
    "\n",
    "def get_image_from_path(path):\n",
    "    image = Image.open(train_path %path)\n",
    "    size = image.size\n",
    "\n",
    "    if size[0] <= size[1]:\n",
    "        scaled_size = (target_size, int(size[1]/size[0]*target_size))\n",
    "        crop_area = (0, int((scaled_size[1]-target_size)/2), target_size, int((scaled_size[1]+target_size)/2))\n",
    "    else:\n",
    "        scaled_size = (int(size[0]/size[1]*target_size), target_size)\n",
    "        crop_area = (int((scaled_size[0]-target_size)/2), 0, int((scaled_size[0]+target_size)/2), target_size)\n",
    "\n",
    "    image = image.resize(scaled_size)\n",
    "    image = image.crop(crop_area)\n",
    "    return image\n",
    "\n",
    "def get_array_from_path(path):\n",
    "    return np.asarray(get_image_from_path(path))\n",
    "\n",
    "# 이미지 불러와서 데이터셋 생성\n",
    "image_data = np.array([image for image in metadata['image_path'].map(get_array_from_path)])\n",
    "sentiment_data = np.array(metadata[sentiment_list])\n",
    "sentence_data = np.array(metadata['clean_text'])\n",
    "\n",
    "# 데이터 피클로 저장\n",
    "pickle.dump([image_data, sentiment_data, sentence_data], open('data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피클로 저장된 데이터 로드\n",
    "image_data, sentiment_data, sentence_data = pickle.load(open('data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 256, 256, 3)\n",
      "(7000, 4)\n",
      "(7000,)\n"
     ]
    }
   ],
   "source": [
    "print(image_data.shape)\n",
    "print(sentiment_data.shape)\n",
    "print(sentence_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.build(input_shape=(None, target_size, target_size, 3))\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keich Capstone",
   "language": "python",
   "name": "venv_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
