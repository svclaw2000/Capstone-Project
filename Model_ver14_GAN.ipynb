{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from konlpy.tag import Komoran\n",
    "import os\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessed = pickle.load(open('preprocessed.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n = 5\n",
    "total_data = [[], [], [], [], []]\n",
    "for i in range(1, max_n + 1):\n",
    "    file_name = 'data_256_cat%s.pkl' %i\n",
    "    loaded_data = pickle.load(open(file_name, 'rb'))\n",
    "\n",
    "    _image_data, _sentence_data, _sentence_tags, _hashtag_data, _metadata = loaded_data[1]\n",
    "\n",
    "    _sentence_tags = np.array(_sentence_tags)\n",
    "    _hashtag_data = np.array(_hashtag_data)\n",
    "    \n",
    "    total_data[0].append(_image_data)\n",
    "    total_data[1].append(_sentence_data)\n",
    "    total_data[2].append(_sentence_tags)\n",
    "    total_data[3].append(_hashtag_data)\n",
    "    total_data[4].append(_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_image_data = np.concatenate(total_data[0])\n",
    "_sentence_data = np.concatenate(total_data[1])\n",
    "_sentence_tags = np.concatenate(total_data[2])\n",
    "_hashtag_data = np.concatenate(total_data[3])\n",
    "_metadata = pd.concat(total_data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "n_valid = 700\n",
    "n_train = _image_data.shape[0] - n_valid\n",
    "n_total = n_train + n_valid\n",
    "indices = np.random.choice(np.arange(_image_data.shape[0]), n_total, replace=False)\n",
    "train_idx = indices[:n_train]\n",
    "valid_idx = indices[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = _image_data[train_idx]\n",
    "sentence_data = _sentence_data[train_idx]\n",
    "sentence_tags = _sentence_tags[train_idx]\n",
    "hashtag_data = _hashtag_data[train_idx]\n",
    "metadata = _metadata.iloc[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_valid = _image_data[valid_idx]\n",
    "sentence_valid = _sentence_data[valid_idx]\n",
    "sentence_tags_valid = _sentence_tags[valid_idx]\n",
    "hashtag_valid = _hashtag_data[valid_idx]\n",
    "metadata_valid = _metadata.iloc[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 867737/867737 [29:20<00:00, 492.90it/s] \n"
     ]
    }
   ],
   "source": [
    "komoran = Komoran()\n",
    "w2v_tags = [[t[0] for t in komoran.pos(s)] for s in tqdm(preprocessed['clean_text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(w2v_tags, open('w2v_tags.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_tags = pickle.load(open('w2v_tags.pkl', 'rb'))\n",
    "\n",
    "for tags in w2v_tags:\n",
    "    tags.insert(0, '\\t')\n",
    "    tags.append('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_w2v = Word2Vec(\n",
    "    w2v_tags,\n",
    "    workers=os.cpu_count(),\n",
    "    size=200,\n",
    "    window=5,\n",
    "    min_count=50,\n",
    "    sample=1e-3\n",
    ").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('히히', 0.4601551294326782),\n",
       " ('그럼', 0.4597155749797821),\n",
       " ('근데', 0.45525985956192017),\n",
       " ('증말', 0.454887330532074),\n",
       " ('헤헤', 0.4441181421279907),\n",
       " ('그래도', 0.3884080648422241),\n",
       " ('그나저나', 0.3708135187625885),\n",
       " ('얼른', 0.35448527336120605),\n",
       " ('그래야', 0.35260123014450073),\n",
       " ('헿', 0.3460230231285095)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_w2v.most_similar('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34300, 256, 256, 3)\n",
      "(34300,)\n",
      "(34300,)\n",
      "(34300,)\n",
      "(34300, 15)\n"
     ]
    }
   ],
   "source": [
    "print(image_data.shape)\n",
    "print(sentence_data.shape)\n",
    "print(sentence_tags.shape)\n",
    "print(hashtag_data.shape)\n",
    "print(metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34300/34300 [01:01<00:00, 561.20it/s] \n"
     ]
    }
   ],
   "source": [
    "komoran = Komoran()\n",
    "all_tags = np.array([[t[0] for t in komoran.pos(s)] for s in tqdm(sentence_data)])\n",
    "\n",
    "train_indices = [i for i,n in enumerate(map(len, all_tags)) if 0 < n <= 100]\n",
    "train_imgs = image_data[train_indices]\n",
    "train_tags = all_tags[train_indices]\n",
    "train_sens = sentence_data[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:01<00:00, 440.47it/s] \n"
     ]
    }
   ],
   "source": [
    "valid_imgs = image_valid\n",
    "valid_tags = np.array([[t[0] for t in komoran.pos(s)] for s in tqdm(sentence_valid)])\n",
    "valid_sens = sentence_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_dict = {}\n",
    "# for i in map(len, all_tags):\n",
    "#     if i not in len_dict:\n",
    "#         len_dict[i] = 1\n",
    "#     else:\n",
    "#         len_dict[i] += 1\n",
    "        \n",
    "# for i, n in sorted(len_dict.items()):\n",
    "#     print(i, '\\t', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = max(map(len, train_tags))\n",
    "gensim_data = np.zeros(shape=(len(train_tags), max_seq_length, 200))\n",
    "\n",
    "for i, tags in enumerate(train_tags):\n",
    "    for j, tag in enumerate([t for t in tags if t in new_w2v]):\n",
    "        gensim_data[i, j] = new_w2v[tag]\n",
    "        \n",
    "gensim_valid = np.zeros(shape=(len(valid_tags), max_seq_length, 200))\n",
    "\n",
    "for i, tags in enumerate(valid_tags):\n",
    "    for j, tag in enumerate([t for t in tags if t in new_w2v][:100]):\n",
    "        gensim_valid[i, j] = new_w2v[tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "n_output = 200\n",
    "\n",
    "def generator(images, labels=None):\n",
    "    with tf.variable_scope('generator'):\n",
    "        conv1 = tf.layers.conv2d(images, 16, [5,5], strides=2, padding='SAME')\n",
    "        conv2 = tf.layers.conv2d(conv1, 8, [5,5], strides=2, padding='SAME')\n",
    "        conv3 = tf.layers.conv2d(conv2, 4, [5,5], strides=2, padding='SAME')\n",
    "        reshaped = tf.reshape(conv3, shape=(-1, 128, 32))\n",
    "        rnn_cell = tf.nn.rnn_cell.LSTMCell(n_hidden)\n",
    "        rnn_cell = tf.nn.rnn_cell.DropoutWrapper(rnn_cell, output_keep_prob=0.8)\n",
    "        outputs, states = tf.nn.dynamic_rnn(rnn_cell, reshaped, dtype=tf.float32)\n",
    "        w2v_outputs = tf.layers.dense(outputs[:max_seq_length], n_output)\n",
    "    return w2v_outputs\n",
    "\n",
    "def discriminator(inputs, labels=None, reuse=None):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "        rnn_cell = tf.nn.rnn_cell.LSTMCell(n_hidden)\n",
    "        rnn_cell = tf.nn.rnn_cell.DropoutWrapper(rnn_cell, output_keep_prob=0.8)\n",
    "        outputs, states = tf.nn.dynamic_rnn(rnn_cell, inputs, dtype=tf.float32)\n",
    "        rnn_output = outputs[:, -1]\n",
    "        output = tf.layers.dense(rnn_output, 1, activation=None)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'generator/dense/BiasAdd:0' shape=(?, 128, 200) dtype=float32>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 256, 256, 3])\n",
    "Y = tf.placeholder(tf.float32, [None, max_seq_length, 200])\n",
    "\n",
    "G = generator(X)\n",
    "D_real = discriminator(Y)\n",
    "D_gene = discriminator(G, reuse=True)\n",
    "\n",
    "loss_D_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real, labels=tf.ones_like(D_real)))\n",
    "loss_D_gene = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_gene, labels=tf.zeros_like(D_gene)))\n",
    "loss_D = loss_D_real + loss_D_gene\n",
    "loss_G = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_gene, labels=tf.ones_like(D_gene)))\n",
    "\n",
    "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "\n",
    "train_D = tf.train.AdamOptimizer().minimize(loss_D, var_list=vars_D)\n",
    "train_G = tf.train.AdamOptimizer().minimize(loss_G, var_list=vars_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:68:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, \n",
    "                                            log_device_placement=True))\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:51<00:00,  2.89s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1] loss_D = 1.444, loss_G = 2.359, loss_valid_D = 1.722, loss_valid_G = 1.299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:51<00:00,  2.85s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 2] loss_D = 0.232, loss_G = 3.564, loss_valid_D = 0.075, loss_valid_G = 4.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:51<00:00,  2.85s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 3] loss_D = 0.037, loss_G = 4.361, loss_valid_D = 0.100, loss_valid_G = 3.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:51<00:00,  2.85s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 4] loss_D = 0.048, loss_G = 3.972, loss_valid_D = 0.082, loss_valid_G = 4.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 11/18 [00:34<00:21,  3.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-af7ca4bd7dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_D\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_tag\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_val_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_G\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_img\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtotal_loss_D\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val_D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1800\n",
    "n_epoch = 100\n",
    "n_batch = train_imgs.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    total_loss_D = 0\n",
    "    total_loss_G = 0\n",
    "    for batch in tqdm(range(n_batch)):\n",
    "        batch_img = train_imgs[batch*batch_size:(batch+1)*batch_size]\n",
    "        batch_tag = gensim_data[batch*batch_size:(batch+1)*batch_size]\n",
    "        \n",
    "        _, loss_val_D = sess.run([train_D, loss_D], feed_dict={X:batch_img, Y:batch_tag})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G], feed_dict={X:batch_img})\n",
    "        \n",
    "        total_loss_D += loss_val_D\n",
    "        total_loss_G += loss_val_G\n",
    "        \n",
    "#         print('[Epoch: %s Batch: %s] loss_D = %.3f, loss_G = %.3f' %(epoch+1, batch+1, loss_val_D, loss_val_G))\n",
    "        \n",
    "    _, loss_val_D = sess.run([train_D, loss_D], feed_dict={X:valid_imgs, Y:gensim_valid})\n",
    "    _, loss_val_G = sess.run([train_G, loss_G], feed_dict={X:valid_imgs})\n",
    "    \n",
    "    print('[Epoch: %s] loss_D = %.3f, loss_G = %.3f, loss_valid_D = %.3f, loss_valid_G = %.3f' %(epoch+1, total_loss_D / n_batch, total_loss_G / n_batch, loss_val_D, loss_val_G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실버커플링중 언벨런스느낌과 독특한면이 독보이는 디자인입니다 남자반지는 유광무광으로 고급스러움을 살림 커플링입니다 홈페이지 카카오톡문의 고객센터 대한민국에서 제일 저렴한 쥬얼리쇼핑몰 검색창에 피카커플링을 검색해주세요 오프라인매장 종로가역 번출구 앞 조흥상가층\n",
      "도록 며 며 도록 며 도록 ㅂ니다 도록 ㅂ니다 도록 도록 며 ㅂ니다 며 도록 도록 며 도록 도록 도록 도록 도록 ㅂ니다 ㅂ니다 며 ㅂ니다 ㅂ니다 ㅂ니다 도록 도록 ㅂ니다 도록 ㅂ니다 며 도록 도록 며 도록 ㅂ니다 ㅂ니다 ㅂ니다 도록 도록 도록 도록 도록 도록 며 도록 도록 도록 도록 며 도록 ㅂ니다 도록 도록 도록 도록 며 며 며 ㅂ니다 며 며 ㅂ니다 도록 도록 ㅂ니다 ㅂ니다 ㅂ니다 며 도록 ㅂ니다 도록 며 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 며 며 ㅂ니다 도록 며 도 며 ㅂ니다 며 도록 ㅂ니다 며 며 도록 도록 ㅂ니다 ㅂ니다 ㅂ니다 도록\n",
      "우지혁 하이\n",
      "며 ㅂ니다 ㅂ니다 도록 며 도록 ㅂ니다 며 며 며 ㅂ니다 도록 ㅂ니다 며 ㅂ니다 도록 도록 ㅂ니다 며 ㅂ니다 도록 ㅂ니다 ㅂ니다 도록 ㅂ니다 ㅂ니다 ㅂ니다 도록 ㅂ니다 ㅂ니다 며 ㅂ니다 도록 도록 ㅂ니다 ㅂ니다 도록 며 ㅂ니다 며 며 ㅂ니다 며 며 도록 도록 ㅂ니다 도록 며 도록 ㅂ니다 ㅂ니다 도록 며 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 도록 며 며 도록 며 ㅂ니다 도록 도록 도록 며 ㅂ니다 도록 도록 ㅂ니다 도록 ㅂ니다 도록 ㅂ니다 ㅂ니다 도록 ㅂ니다 ㅂ니다 도록 며 ㅂ니다 도록 ㅂ니다 도록 며 도록 ㅂ니다 ㅂ니다 도록 ㅂ니다 며 며 도록 며 ㅂ니다 도록 며 도록\n",
      "어흥 눈뜨면 아침이고 월요일인가하면 벌써 주말이고 월초인가하면 어느새 월말을 향하고 세월이 빠른건지 내가 급한건지 아니면 삶이 짧아진건지 마음속의 나는 그대로인데 거울속의 나는 어느덧 늙어있네\n",
      "며 며 도록 도록 도록 며 도록 ㅂ니다 도록 ㅂ니다 도록 ㅂ니다 ㅂ니다 며 며 ㅂ니다 며 며 며 며 도록 도록 도록 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 며 도록 ㅂ니다 ㅂ니다 며 며 며 ㅂ니다 도록 ㅂ니다 며 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 며 ㅂ니다 ㅂ니다 도록 며 며 도록 도록 며 도록 ㅂ니다 도록 도록 도록 도록 ㅂ니다 도록 도록 며 ㅂ니다 도록 도록 며 ㅂ니다 도록 도록 ㅂ니다 ㅂ니다 도록 며 ㅂ니다 ㅂ니다 도록 도록 도록 도록 며 ㅂ니다 며 ㅂ니다 며 며 도록 ㅂ니다 며 도록 ㅂ니다 ㅂ니다 ㅂ니다 도록 ㅂ니다\n",
      "남자 포인트 라인 배색 오버핏 자가드 니트 가디건\n",
      "며 ㅂ니다 며 ㅂ니다 도록 ㅂ니다 도록 도록 며 ㅂ니다 며 도록 도록 며 ㅂ니다 ㅂ니다 도록 며 ㅂ니다 며 ㅂ니다 도록 ㅂ니다 며 ㅂ니다 ㅂ니다 며 며 도록 며 며 도록 ㅂ니다 도록 도록 도록 도록 ㅂ니다 며 며 ㅂ니다 ㅂ니다 ㅂ니다 도록 ㅂ니다 ㅂ니다 도록 ㅂ니다 도록 도록 ㅂ니다 도록 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 며 도록 도록 며 도록 ㅂ니다 며 도록 도록 ㅂ니다 도록 도록 며 ㅂ니다 ㅂ니다 며 ㅂ니다 도록 ㅂ니다 도록 ㅂ니다 며 도록 ㅂ니다 ㅂ니다 도록 며 도록 ㅂ니다 도록 ㅂ니다 ㅂ니다 도록 도록 ㅂ니다 며 ㅂ니다 ㅂ니다 며 ㅂ니다 며 며\n",
      "나 원래 옷안입는거 알지 옷사떠\n",
      "며 며 도록 도록 도록 도록 ㅂ니다 도록 도록 ㅂ니다 도록 도록 ㅂ니다 며 며 ㅂ니다 도록 며 ㅂ니다 며 도록 ㅂ니다 도록 ㅂ니다 도록 도록 ㅂ니다 도록 며 도록 ㅂ니다 도록 ㅂ니다 도록 며 ㅂ니다 ㅂ니다 도록 도록 ㅂ니다 도록 며 ㅂ니다 며 ㅂ니다 ㅂ니다 ㅂ니다 며 도록 ㅂ니다 도록 ㅂ니다 며 도록 ㅂ니다 도록 며 도록 도록 도록 며 ㅂ니다 도록 ㅂ니다 도록 도록 ㅂ니다 며 ㅂ니다 ㅂ니다 ㅂ니다 도록 ㅂ니다 도록 며 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 도록 며 ㅂ니다 ㅂ니다 ㅂ니다 도록 도록 ㅂ니다 며 며 도록 도록 ㅂ니다 며 며 도록 도록 도록 ㅂ니다 ㅂ니다 도록\n",
      "스너그 퍼 자켓 다크그레이 블랙\n",
      "ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 도록 도록 ㅂ니다 ㅂ니다 ㅂ니다 도록 도록 며 도록 ㅂ니다 며 ㅂ니다 며 도록 ㅂ니다 며 ㅂ니다 ㅂ니다 ㅂ니다 며 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 도록 ㅂ니다 ㅂ니다 며 ㅂ니다 ㅂ니다 도록 며 며 며 도록 도록 도록 ㅂ니다 ㅂ니다 도록 ㅂ니다 도록 ㅂ니다 ㅂ니다 ㅂ니다 도록 ㅂ니다 ㅂ니다 도록 도록 ㅂ니다 도록 ㅂ니다 도록 며 도록 도록 며 며 도록 ㅂ니다 도록 ㅂ니다 며 도록 도록 ㅂ니다 ㅂ니다 도록 도록 도록 ㅂ니다 ㅂ니다 도록 도록 며 도록 도록 도록 ㅂ니다 도록 며 ㅂ니다 도록 도록 도록 ㅂ니다 며 도록 ㅂ니다 ㅂ니다 ㅂ니다 며 도록 ㅂ니다 ㅂ니다\n",
      "너없이 어떻게 살지\n",
      "ㅂ니다 며 도록 며 ㅂ니다 ㅂ니다 ㅂ니다 도록 ㅂ니다 도록 도록 도록 며 도록 도록 도록 도록 며 도록 도록 도록 도록 며 ㅂ니다 도록 도록 ㅂ니다 도록 ㅂ니다 ㅂ니다 도록 도록 ㅂ니다 도록 ㅂ니다 도록 도록 며 ㅂ니다 ㅂ니다 도록 며 도록 며 며 도록 도록 도록 도록 며 ㅂ니다 며 도록 도록 며 ㅂ니다 도록 ㅂ니다 며 도록 ㅂ니다 ㅂ니다 ㅂ니다 며 도록 ㅂ니다 도록 ㅂ니다 도록 ㅂ니다 도록 도록 ㅂ니다 며 도록 며 며 며 도록 며 도록 며 며 ㅂ니다 며 ㅂ니다 며 며 ㅂ니다 ㅂ니다 도록 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 며 ㅂ니다 도록 ㅂ니다 도록\n",
      "깔깔\n",
      "ㅂ니다 도록 ㅂ니다 도록 며 ㅂ니다 도록 도록 ㅂ니다 도록 ㅂ니다 ㅂ니다 ㅂ니다 며 며 ㅂ니다 ㅂ니다 며 ㅂ니다 도록 며 며 ㅂ니다 며 ㅂ니다 며 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 도록 ㅂ니다 ㅂ니다 도록 도록 며 ㅂ니다 도록 ㅂ니다 ㅂ니다 ㅂ니다 도록 ㅂ니다 며 며 ㅂ니다 며 며 도록 며 며 며 ㅂ니다 도록 ㅂ니다 ㅂ니다 ㅂ니다 도록 며 며 ㅂ니다 도록 며 며 ㅂ니다 며 며 며 ㅂ니다 도록 도록 도록 도록 며 ㅂ니다 ㅂ니다 도록 며 며 며 며 도록 도록 며 며 ㅂ니다 며 ㅂ니다 도록 ㅂ니다 도록 도록 며 도록 며 며 며 도록 ㅂ니다 도록\n",
      "벌써 월 마지막 금욜이라뇨\n",
      "ㅂ니다 도 도록 ㅂ니다 며 ㅂ니다 며 며 ㅂ니다 ㅂ니다 도록 도록 ㅂ니다 도록 며 도록 도 ㅂ니다 며 ㅂ니다 며 며 ㅂ니다 며 ㅂ니다 ㅂ니다 며 며 며 ㅂ니다 ㅂ니다 도록 도록 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 며 며 도록 ㅂ니다 ㅂ니다 도록 며 으로 도록 으로 ㅂ니다 며 며 도록 ㅂ니다 으로 도록 도록 도록 ㅂ니다 며 며 도록 도록 으로 며 도록 도록 도록 도록 도록 도록 ㅂ니다 도록 도록 ㅂ니다 ㅂ니다 ㅂ니다 도록 ㅂ니다 도록 며 며 도록 으로 며 며 며 ㅂ니다 도록 ㅂ니다 도록 ㅂ니다 도록 도록 도록 도록 며 도록 ㅂ니다 며 도록\n",
      "엥\n",
      "도록 ㅂ니다 ㅂ니다 며 ㅂ니다 ㅂ니다 ㅂ니다 도록 도록 도록 며 며 며 도록 도록 도록 도록 ㅂ니다 도록 ㅂ니다 도록 ㅂ니다 며 며 ㅂ니다 ㅂ니다 도록 도록 도록 ㅂ니다 도록 ㅂ니다 도록 ㅂ니다 ㅂ니다 도록 며 ㅂ니다 도록 며 도록 ㅂ니다 며 며 며 도록 도록 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 도록 도록 도록 며 ㅂ니다 며 며 도록 며 도록 도록 도록 도록 도록 며 도록 도록 도록 며 며 며 도록 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 ㅂ니다 며 며 ㅂ니다 도록 도록 도록 며 도록 도록 도록 도록 ㅂ니다 도록 ㅂ니다 도록 도록 도록 며 도록 도록 도록\n"
     ]
    }
   ],
   "source": [
    "results = sess.run(G, feed_dict={X: train_imgs[:10]})\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(train_sens[i][1:-1])\n",
    "    print(' '.join([new_w2v.most_similar([v])[0][0] for v in result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(image):\n",
    "    prediction = tf.argmax(outputs2, 2)\n",
    "    dec_inp = np.zeros(shape=(1, max_seq_length, dict_len), dtype='float32')\n",
    "    dec_inp[0,:,output_dict['\\t']] = 1.\n",
    "    # dec_out = np.eye(dict_len)[dec_out]\n",
    "    result = sess.run(prediction, \n",
    "                      feed_dict={inputs: [image],\n",
    "                                 dec_inputs: dec_inp})\n",
    "    decoded = [output_chars[i] for i in result[0]]\n",
    "    end = decoded.index('\\n') if '\\n' in decoded else len(decoded)\n",
    "    translated = ''.join(decoded[:end])\n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오<UNK><UNK>'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(image_data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,256,2069]\n\t [[node Placeholder_1 (defined at <ipython-input-70-42deb1a72a5c>:19) ]]\n\t [[generation_dec/dense/BiasAdd/_167]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,256,2069]\n\t [[node Placeholder_1 (defined at <ipython-input-70-42deb1a72a5c>:19) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'Placeholder_1':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3147, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-70-42deb1a72a5c>\", line 19, in <module>\n    dec_inputs = tf.placeholder(tf.float32, shape=[None, max_seq_length, dict_len])\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 3100, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 6809, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3485, in _create_op_internal\n    op_def=op_def)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1949, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,256,2069]\n\t [[{{node Placeholder_1}}]]\n\t [[generation_dec/dense/BiasAdd/_167]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,256,2069]\n\t [[{{node Placeholder_1}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-7c7c8dbc6866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'정답 예측'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,256,2069]\n\t [[node Placeholder_1 (defined at <ipython-input-70-42deb1a72a5c>:19) ]]\n\t [[generation_dec/dense/BiasAdd/_167]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,256,2069]\n\t [[node Placeholder_1 (defined at <ipython-input-70-42deb1a72a5c>:19) ]]\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'Placeholder_1':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3147, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-70-42deb1a72a5c>\", line 19, in <module>\n    dec_inputs = tf.placeholder(tf.float32, shape=[None, max_seq_length, dict_len])\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 3100, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 6809, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 744, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3485, in _create_op_internal\n    op_def=op_def)\n  File \"/home/svclaw2000/venv_capstone/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1949, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "start_idx, end_idx = 50, 100\n",
    "\n",
    "results = sess.run(outputs2, feed_dict={inputs:image_data[start_idx:end_idx]})\n",
    "print('정답 예측')\n",
    "\n",
    "for l, p, img in zip(y_train[start_idx:end_idx], l_label[np.argmax(results, axis=1)], image_data[start_idx:end_idx]):\n",
    "    print([l==p, l, p])\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정답 예측\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[False, '애완동물', '여행'],\n",
       " [False, '일상', '여행'],\n",
       " [False, '애완동물', '여행'],\n",
       " [False, '셀카', '패션'],\n",
       " [False, '여행', '셀카'],\n",
       " [False, '여행', '연애'],\n",
       " [False, '애완동물', '음식'],\n",
       " [False, '음식', '여행'],\n",
       " [False, '패션', '여행'],\n",
       " [True, '애완동물', '애완동물'],\n",
       " [False, '일상', '애완동물'],\n",
       " [False, '여행', '애완동물'],\n",
       " [False, '패션', '연애'],\n",
       " [True, '패션', '패션'],\n",
       " [False, '음식', '여행'],\n",
       " [False, '여행', '음식'],\n",
       " [False, '음식', '여행'],\n",
       " [False, '패션', '애완동물'],\n",
       " [False, '음식', '셀카'],\n",
       " [False, '애완동물', '연애'],\n",
       " [False, '일상', '음식'],\n",
       " [True, '여행', '여행'],\n",
       " [False, '음식', '패션'],\n",
       " [False, '연애', '셀카'],\n",
       " [False, '셀카', '음식'],\n",
       " [False, '음식', '패션'],\n",
       " [False, '애완동물', '연애'],\n",
       " [False, '패션', '일상'],\n",
       " [False, '셀카', '애완동물'],\n",
       " [False, '일상', '패션'],\n",
       " [False, '음식', '여행'],\n",
       " [True, '패션', '패션'],\n",
       " [False, '패션', '일상'],\n",
       " [False, '일상', '연애'],\n",
       " [True, '연애', '연애'],\n",
       " [False, '애완동물', '패션'],\n",
       " [False, '일상', '연애'],\n",
       " [False, '애완동물', '패션'],\n",
       " [False, '애완동물', '패션'],\n",
       " [False, '연애', '여행'],\n",
       " [False, '셀카', '여행'],\n",
       " [True, '음식', '음식'],\n",
       " [False, '여행', '애완동물'],\n",
       " [True, '애완동물', '애완동물'],\n",
       " [False, '셀카', '패션'],\n",
       " [False, '일상', '셀카'],\n",
       " [False, '여행', '패션'],\n",
       " [False, '여행', '음식'],\n",
       " [True, '셀카', '셀카'],\n",
       " [False, '음식', '여행']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_idx, end_idx = 0, 50\n",
    "\n",
    "results = sess.run(outputs2, feed_dict={inputs:image_valid[start_idx:end_idx]})\n",
    "print('정답 예측')\n",
    "[[l==p, l, p] for l, p in zip(y_train[start_idx:end_idx], l_label[np.argmax(results, axis=1)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keich Capstone",
   "language": "python",
   "name": "venv_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
