{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data_256.pkl'\n",
    "image_data, sentiment_data, sentence_data, sentence_tags, hashtag_data = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 3000\n",
    "\n",
    "image_data = image_data[:size]\n",
    "sentiment_data = sentiment_data[:size]\n",
    "sentence_data = sentence_data[:size]\n",
    "sentence_tags = sentence_tags[:size]\n",
    "hashtag_data = hashtag_data[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 256, 256, 3)\n",
      "(3000, 4)\n",
      "(3000,)\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(image_data.shape)\n",
    "print(sentiment_data.shape)\n",
    "print(sentence_data.shape)\n",
    "print(len(sentence_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tags = [sorted([tag[0] for tag in tags][:5]) for tags in sentence_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:03<00:00, 933.24it/s] \n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "\n",
    "output_tags = [[p[0] for p in komoran.pos(s)] for s in tqdm(sentence_data)]\n",
    "[tags.insert(0, '\\t') for tags in output_tags]\n",
    "[tags.append('\\n') for tags in output_tags]\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words = set()\n",
    "for tags in output_tags:\n",
    "    for tag in tags:\n",
    "        if tag not in output_words:\n",
    "            output_words.add(tag)\n",
    "            \n",
    "output_words = sorted(list(output_words))\n",
    "output_words.insert(0, 'P')\n",
    "n_output_words = len(output_words)\n",
    "\n",
    "max_seq_length = max([len(_in) + len(_out) for _in, _out in zip(input_tags, output_tags)])\n",
    "\n",
    "w2i_output = {w:i for i, w in enumerate(output_words)}\n",
    "seq_list = []\n",
    "\n",
    "for i, (_in, _out) in enumerate(zip(input_tags, output_tags)):\n",
    "    for j in range(1, len(_out)):\n",
    "        seq_list.append(_in + _out[:j+1])\n",
    "        \n",
    "n_seq_data = len(seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = np.zeros(shape=(n_seq_data, max_seq_length+1), dtype='int32')\n",
    "\n",
    "for i, seq in enumerate(seq_list):\n",
    "    seq_data[i, -len(seq):] = np.array([w2i_output[w] for w in seq])\n",
    "    \n",
    "x_seq_data = seq_data[:, :-1]\n",
    "\n",
    "output_eye = np.eye(n_output_words)\n",
    "y_seq_data = output_eye[seq_data[:, -1]]\n",
    "# y_seq_data = seq_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129470, 152), (129470, 9948))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq_data.shape, y_seq_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0\n",
    "train_size = n_seq_data - valid_size\n",
    "batch_size = 10000\n",
    "n_batch = train_size // batch_size\n",
    "n_valid = valid_size // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_seq_data[:train_size], y_seq_data[:train_size]\n",
    "x_valid, y_valid = x_seq_data[train_size:], y_seq_data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129470, 152), (129470, 9948))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_output_words, 64, input_length=max_seq_length))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(n_output_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 152, 64)           636672    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 9948)              1283292   \n",
      "=================================================================\n",
      "Total params: 2,018,780\n",
      "Trainable params: 2,018,780\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 5s 423ms/step - loss: 1.2136 - accuracy: 0.7480 - val_loss: 9.6644 - val_accuracy: 0.1648\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.2153 - accuracy: 0.7473 - val_loss: 9.6746 - val_accuracy: 0.1643\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.2131 - accuracy: 0.7478 - val_loss: 9.6873 - val_accuracy: 0.1647\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.2127 - accuracy: 0.7486 - val_loss: 9.6911 - val_accuracy: 0.1641\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.2286 - accuracy: 0.7436 - val_loss: 9.6564 - val_accuracy: 0.1638\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 1.2314 - accuracy: 0.7430 - val_loss: 9.6857 - val_accuracy: 0.1637\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.2219 - accuracy: 0.7452 - val_loss: 9.7076 - val_accuracy: 0.1627\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.2135 - accuracy: 0.7471 - val_loss: 9.7128 - val_accuracy: 0.1629\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.2083 - accuracy: 0.7485 - val_loss: 9.7120 - val_accuracy: 0.1634\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.2049 - accuracy: 0.7491 - val_loss: 9.7098 - val_accuracy: 0.1645\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.2017 - accuracy: 0.7500 - val_loss: 9.7198 - val_accuracy: 0.1630\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1995 - accuracy: 0.7509 - val_loss: 9.7354 - val_accuracy: 0.1639\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.1994 - accuracy: 0.7508 - val_loss: 9.7374 - val_accuracy: 0.1637\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1983 - accuracy: 0.7512 - val_loss: 9.7380 - val_accuracy: 0.1637\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1970 - accuracy: 0.7517 - val_loss: 9.7371 - val_accuracy: 0.1640\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 1.1943 - accuracy: 0.7522 - val_loss: 9.7350 - val_accuracy: 0.1639\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1933 - accuracy: 0.7519 - val_loss: 9.7342 - val_accuracy: 0.1647\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.1945 - accuracy: 0.7512 - val_loss: 9.7375 - val_accuracy: 0.1641\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1950 - accuracy: 0.7517 - val_loss: 9.7499 - val_accuracy: 0.1639\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.1940 - accuracy: 0.7522 - val_loss: 9.7547 - val_accuracy: 0.1634\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 1.1923 - accuracy: 0.7522 - val_loss: 9.7578 - val_accuracy: 0.1637\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1900 - accuracy: 0.7532 - val_loss: 9.7611 - val_accuracy: 0.1645\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1888 - accuracy: 0.7530 - val_loss: 9.7576 - val_accuracy: 0.1633\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1868 - accuracy: 0.7534 - val_loss: 9.7814 - val_accuracy: 0.1626\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1839 - accuracy: 0.7541 - val_loss: 9.7678 - val_accuracy: 0.1640\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1837 - accuracy: 0.7542 - val_loss: 9.7723 - val_accuracy: 0.1638\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1813 - accuracy: 0.7547 - val_loss: 9.7913 - val_accuracy: 0.1624\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1812 - accuracy: 0.7552 - val_loss: 9.8034 - val_accuracy: 0.1624\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1801 - accuracy: 0.7554 - val_loss: 9.8074 - val_accuracy: 0.1641\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1777 - accuracy: 0.7561 - val_loss: 9.8088 - val_accuracy: 0.1627\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1754 - accuracy: 0.7558 - val_loss: 9.7999 - val_accuracy: 0.1635\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.1737 - accuracy: 0.7568 - val_loss: 9.8005 - val_accuracy: 0.1640\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.1725 - accuracy: 0.7563 - val_loss: 9.8072 - val_accuracy: 0.1635\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.1736 - accuracy: 0.7564 - val_loss: 9.8146 - val_accuracy: 0.1633\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1728 - accuracy: 0.7567 - val_loss: 9.8174 - val_accuracy: 0.1627\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 1.1714 - accuracy: 0.7575 - val_loss: 9.8353 - val_accuracy: 0.1621\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1719 - accuracy: 0.7572 - val_loss: 9.8380 - val_accuracy: 0.1626\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 4s 371ms/step - loss: 1.1690 - accuracy: 0.7576 - val_loss: 9.8365 - val_accuracy: 0.1630\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1677 - accuracy: 0.7579 - val_loss: 9.8368 - val_accuracy: 0.1627\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 1.1712 - accuracy: 0.7573 - val_loss: 9.8317 - val_accuracy: 0.1638\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1728 - accuracy: 0.7562 - val_loss: 9.8159 - val_accuracy: 0.1634\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.1722 - accuracy: 0.7563 - val_loss: 9.8327 - val_accuracy: 0.1631\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 1.1707 - accuracy: 0.7568 - val_loss: 9.8417 - val_accuracy: 0.1633\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.1658 - accuracy: 0.7581 - val_loss: 9.8674 - val_accuracy: 0.1624\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1627 - accuracy: 0.7591 - val_loss: 9.8530 - val_accuracy: 0.1620\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 1.1613 - accuracy: 0.7595 - val_loss: 9.8522 - val_accuracy: 0.1630\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 1.1604 - accuracy: 0.7595 - val_loss: 9.8664 - val_accuracy: 0.1632\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1590 - accuracy: 0.7593 - val_loss: 9.8660 - val_accuracy: 0.1632\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1596 - accuracy: 0.7594 - val_loss: 9.8823 - val_accuracy: 0.1620\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1624 - accuracy: 0.7588 - val_loss: 9.8744 - val_accuracy: 0.1624\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 1.1592 - accuracy: 0.7596 - val_loss: 9.8754 - val_accuracy: 0.1624\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.1557 - accuracy: 0.7605 - val_loss: 9.8886 - val_accuracy: 0.1634\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1531 - accuracy: 0.7606 - val_loss: 9.8947 - val_accuracy: 0.1623\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 1.1513 - accuracy: 0.7609 - val_loss: 9.9054 - val_accuracy: 0.1626\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1504 - accuracy: 0.7613 - val_loss: 9.8954 - val_accuracy: 0.1626\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 1.1553 - accuracy: 0.7602 - val_loss: 9.9001 - val_accuracy: 0.1626\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1612 - accuracy: 0.7578 - val_loss: 9.9188 - val_accuracy: 0.1620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 1.1635 - accuracy: 0.7575 - val_loss: 9.9127 - val_accuracy: 0.1623\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.1584 - accuracy: 0.7589 - val_loss: 9.9241 - val_accuracy: 0.1620\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 1.1517 - accuracy: 0.7607 - val_loss: 9.9281 - val_accuracy: 0.1629\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.1481 - accuracy: 0.7615 - val_loss: 9.9274 - val_accuracy: 0.1617\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.1462 - accuracy: 0.7623 - val_loss: 9.9369 - val_accuracy: 0.1616\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1442 - accuracy: 0.7623 - val_loss: 9.9512 - val_accuracy: 0.1607\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1420 - accuracy: 0.7632 - val_loss: 9.9438 - val_accuracy: 0.1617\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.1399 - accuracy: 0.7643 - val_loss: 9.9490 - val_accuracy: 0.1616\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1380 - accuracy: 0.7645 - val_loss: 9.9565 - val_accuracy: 0.1615\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 4s 357ms/step - loss: 1.1359 - accuracy: 0.7649 - val_loss: 9.9517 - val_accuracy: 0.1627\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1363 - accuracy: 0.7644 - val_loss: 9.9511 - val_accuracy: 0.1614\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1364 - accuracy: 0.7645 - val_loss: 9.9480 - val_accuracy: 0.1632\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.1351 - accuracy: 0.7643 - val_loss: 9.9611 - val_accuracy: 0.1617\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.1329 - accuracy: 0.7655 - val_loss: 9.9740 - val_accuracy: 0.1625\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.1312 - accuracy: 0.7658 - val_loss: 9.9806 - val_accuracy: 0.1613\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.1309 - accuracy: 0.7655 - val_loss: 9.9924 - val_accuracy: 0.1617\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1306 - accuracy: 0.7656 - val_loss: 9.9825 - val_accuracy: 0.1613\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 1.1285 - accuracy: 0.7666 - val_loss: 9.9908 - val_accuracy: 0.1616\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 1.1261 - accuracy: 0.7669 - val_loss: 9.9956 - val_accuracy: 0.1616\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 1.1255 - accuracy: 0.7672 - val_loss: 9.9913 - val_accuracy: 0.1614\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1249 - accuracy: 0.7671 - val_loss: 10.0038 - val_accuracy: 0.1606\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1236 - accuracy: 0.7673 - val_loss: 10.0056 - val_accuracy: 0.1613\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1234 - accuracy: 0.7677 - val_loss: 10.0057 - val_accuracy: 0.1605\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 4s 358ms/step - loss: 1.1214 - accuracy: 0.7676 - val_loss: 10.0226 - val_accuracy: 0.1610\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1200 - accuracy: 0.7679 - val_loss: 10.0211 - val_accuracy: 0.1599\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 1.1186 - accuracy: 0.7684 - val_loss: 10.0294 - val_accuracy: 0.1610\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1165 - accuracy: 0.7687 - val_loss: 10.0356 - val_accuracy: 0.1605\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.1151 - accuracy: 0.7689 - val_loss: 10.0310 - val_accuracy: 0.1603\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1181 - accuracy: 0.7681 - val_loss: 10.0278 - val_accuracy: 0.1597\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 1.1195 - accuracy: 0.7677 - val_loss: 10.0346 - val_accuracy: 0.1610\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1217 - accuracy: 0.7669 - val_loss: 10.0253 - val_accuracy: 0.1614\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1206 - accuracy: 0.7677 - val_loss: 10.0392 - val_accuracy: 0.1614\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.1183 - accuracy: 0.7685 - val_loss: 10.0303 - val_accuracy: 0.1607\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1172 - accuracy: 0.7682 - val_loss: 10.0292 - val_accuracy: 0.1621\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.1123 - accuracy: 0.7699 - val_loss: 10.0632 - val_accuracy: 0.1605\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1306 - accuracy: 0.7641 - val_loss: 10.0643 - val_accuracy: 0.1593\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.1316 - accuracy: 0.7636 - val_loss: 10.0657 - val_accuracy: 0.1618\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1295 - accuracy: 0.7644 - val_loss: 10.0449 - val_accuracy: 0.1622\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.1223 - accuracy: 0.7666 - val_loss: 10.0573 - val_accuracy: 0.1619\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1146 - accuracy: 0.7679 - val_loss: 10.0791 - val_accuracy: 0.1616\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.1096 - accuracy: 0.7703 - val_loss: 10.0829 - val_accuracy: 0.1623\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1069 - accuracy: 0.7706 - val_loss: 10.0755 - val_accuracy: 0.1611\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 1.1055 - accuracy: 0.7709 - val_loss: 10.0904 - val_accuracy: 0.1611\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1032 - accuracy: 0.7717 - val_loss: 10.0944 - val_accuracy: 0.1614\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.1004 - accuracy: 0.7720 - val_loss: 10.1092 - val_accuracy: 0.1612\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.0989 - accuracy: 0.7726 - val_loss: 10.1057 - val_accuracy: 0.1612\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.0987 - accuracy: 0.7722 - val_loss: 10.1157 - val_accuracy: 0.1609\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0963 - accuracy: 0.7732 - val_loss: 10.1137 - val_accuracy: 0.1619\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0952 - accuracy: 0.7735 - val_loss: 10.1202 - val_accuracy: 0.1612\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 1.0936 - accuracy: 0.7739 - val_loss: 10.1212 - val_accuracy: 0.1610\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0922 - accuracy: 0.7745 - val_loss: 10.1269 - val_accuracy: 0.1605\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 1.0909 - accuracy: 0.7741 - val_loss: 10.1418 - val_accuracy: 0.1603\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0898 - accuracy: 0.7742 - val_loss: 10.1264 - val_accuracy: 0.1615\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.0893 - accuracy: 0.7745 - val_loss: 10.1342 - val_accuracy: 0.1607\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0886 - accuracy: 0.7752 - val_loss: 10.1334 - val_accuracy: 0.1610\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.0893 - accuracy: 0.7748 - val_loss: 10.1388 - val_accuracy: 0.1604\n",
      "Epoch 114/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 369ms/step - loss: 1.0879 - accuracy: 0.7749 - val_loss: 10.1379 - val_accuracy: 0.1612\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.0870 - accuracy: 0.7746 - val_loss: 10.1624 - val_accuracy: 0.1610\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.0851 - accuracy: 0.7750 - val_loss: 10.1746 - val_accuracy: 0.1611\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0839 - accuracy: 0.7758 - val_loss: 10.1822 - val_accuracy: 0.1614\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.0840 - accuracy: 0.7759 - val_loss: 10.1907 - val_accuracy: 0.1605\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0823 - accuracy: 0.7757 - val_loss: 10.1916 - val_accuracy: 0.1606\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 1.0801 - accuracy: 0.7763 - val_loss: 10.1758 - val_accuracy: 0.1611\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.0788 - accuracy: 0.7767 - val_loss: 10.1939 - val_accuracy: 0.1609\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0777 - accuracy: 0.7773 - val_loss: 10.1926 - val_accuracy: 0.1601\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.0790 - accuracy: 0.7760 - val_loss: 10.2022 - val_accuracy: 0.1607\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.0787 - accuracy: 0.7771 - val_loss: 10.2088 - val_accuracy: 0.1602\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.0765 - accuracy: 0.7765 - val_loss: 10.2125 - val_accuracy: 0.1611\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0742 - accuracy: 0.7776 - val_loss: 10.2056 - val_accuracy: 0.1614\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 1.0724 - accuracy: 0.7779 - val_loss: 10.2167 - val_accuracy: 0.1604\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.0793 - accuracy: 0.7760 - val_loss: 10.1804 - val_accuracy: 0.1611\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.1619 - accuracy: 0.7522 - val_loss: 10.1834 - val_accuracy: 0.1600\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.1282 - accuracy: 0.7614 - val_loss: 10.1856 - val_accuracy: 0.1617\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.1036 - accuracy: 0.7695 - val_loss: 10.1797 - val_accuracy: 0.1613\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.0895 - accuracy: 0.7731 - val_loss: 10.2142 - val_accuracy: 0.1616\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.0789 - accuracy: 0.7755 - val_loss: 10.2223 - val_accuracy: 0.1610\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 1.0728 - accuracy: 0.7768 - val_loss: 10.2355 - val_accuracy: 0.1607\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0697 - accuracy: 0.7777 - val_loss: 10.2375 - val_accuracy: 0.1616\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.0676 - accuracy: 0.7781 - val_loss: 10.2462 - val_accuracy: 0.1602\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 1.0658 - accuracy: 0.7789 - val_loss: 10.2391 - val_accuracy: 0.1613\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.0638 - accuracy: 0.7795 - val_loss: 10.2391 - val_accuracy: 0.1610\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 1.0624 - accuracy: 0.7796 - val_loss: 10.2506 - val_accuracy: 0.1603\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 1.0603 - accuracy: 0.7802 - val_loss: 10.2515 - val_accuracy: 0.1607\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.0589 - accuracy: 0.7802 - val_loss: 10.2676 - val_accuracy: 0.1593\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.0585 - accuracy: 0.7806 - val_loss: 10.2669 - val_accuracy: 0.1608\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.0573 - accuracy: 0.7808 - val_loss: 10.2858 - val_accuracy: 0.1590\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0573 - accuracy: 0.7810 - val_loss: 10.2994 - val_accuracy: 0.1591\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.0577 - accuracy: 0.7805 - val_loss: 10.2966 - val_accuracy: 0.1597\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 1.0562 - accuracy: 0.7806 - val_loss: 10.3022 - val_accuracy: 0.1591\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0539 - accuracy: 0.7815 - val_loss: 10.2972 - val_accuracy: 0.1602\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0521 - accuracy: 0.7824 - val_loss: 10.3055 - val_accuracy: 0.1600\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.0523 - accuracy: 0.7819 - val_loss: 10.3142 - val_accuracy: 0.1599\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.0520 - accuracy: 0.7820 - val_loss: 10.3184 - val_accuracy: 0.1597\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.0494 - accuracy: 0.7829 - val_loss: 10.3079 - val_accuracy: 0.1606\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.0477 - accuracy: 0.7831 - val_loss: 10.3122 - val_accuracy: 0.1602\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0467 - accuracy: 0.7828 - val_loss: 10.3287 - val_accuracy: 0.1594\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 1.0457 - accuracy: 0.7830 - val_loss: 10.3332 - val_accuracy: 0.1586\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 4s 358ms/step - loss: 1.0448 - accuracy: 0.7834 - val_loss: 10.3300 - val_accuracy: 0.1592\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.0524 - accuracy: 0.7811 - val_loss: 10.3395 - val_accuracy: 0.1587\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0510 - accuracy: 0.7820 - val_loss: 10.3335 - val_accuracy: 0.1594\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0499 - accuracy: 0.7816 - val_loss: 10.3474 - val_accuracy: 0.1596\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0455 - accuracy: 0.7828 - val_loss: 10.3523 - val_accuracy: 0.1593\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0415 - accuracy: 0.7840 - val_loss: 10.3652 - val_accuracy: 0.1595\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0406 - accuracy: 0.7843 - val_loss: 10.3498 - val_accuracy: 0.1597\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0394 - accuracy: 0.7840 - val_loss: 10.3534 - val_accuracy: 0.1593\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 1.0383 - accuracy: 0.7843 - val_loss: 10.3529 - val_accuracy: 0.1606\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 1.0383 - accuracy: 0.7842 - val_loss: 10.3797 - val_accuracy: 0.1580\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 1.0389 - accuracy: 0.7846 - val_loss: 10.3707 - val_accuracy: 0.1603\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0361 - accuracy: 0.7850 - val_loss: 10.3865 - val_accuracy: 0.1588\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0349 - accuracy: 0.7850 - val_loss: 10.4057 - val_accuracy: 0.1596\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 1.0351 - accuracy: 0.7854 - val_loss: 10.3825 - val_accuracy: 0.1597\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0356 - accuracy: 0.7853 - val_loss: 10.3629 - val_accuracy: 0.1605\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 370ms/step - loss: 1.0355 - accuracy: 0.7848 - val_loss: 10.3999 - val_accuracy: 0.1583\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.0325 - accuracy: 0.7861 - val_loss: 10.3993 - val_accuracy: 0.1595\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.0311 - accuracy: 0.7864 - val_loss: 10.4082 - val_accuracy: 0.1592\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0302 - accuracy: 0.7865 - val_loss: 10.4184 - val_accuracy: 0.1584\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 4s 373ms/step - loss: 1.0296 - accuracy: 0.7864 - val_loss: 10.4116 - val_accuracy: 0.1594\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 1.0285 - accuracy: 0.7864 - val_loss: 10.4122 - val_accuracy: 0.1594\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.0278 - accuracy: 0.7871 - val_loss: 10.4235 - val_accuracy: 0.1591\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.0256 - accuracy: 0.7871 - val_loss: 10.4304 - val_accuracy: 0.1584\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.0245 - accuracy: 0.7874 - val_loss: 10.4470 - val_accuracy: 0.1597\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.0219 - accuracy: 0.7889 - val_loss: 10.4384 - val_accuracy: 0.1590\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 1.0205 - accuracy: 0.7888 - val_loss: 10.4471 - val_accuracy: 0.1592\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0221 - accuracy: 0.7880 - val_loss: 10.4462 - val_accuracy: 0.1590\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.0245 - accuracy: 0.7872 - val_loss: 10.4289 - val_accuracy: 0.1597\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0250 - accuracy: 0.7868 - val_loss: 10.4476 - val_accuracy: 0.1584\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 1.0217 - accuracy: 0.7872 - val_loss: 10.4588 - val_accuracy: 0.1600\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 1.0186 - accuracy: 0.7888 - val_loss: 10.4583 - val_accuracy: 0.1595\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.0156 - accuracy: 0.7897 - val_loss: 10.4694 - val_accuracy: 0.1588\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0140 - accuracy: 0.7897 - val_loss: 10.4818 - val_accuracy: 0.1592\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.0135 - accuracy: 0.7901 - val_loss: 10.4703 - val_accuracy: 0.1595\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 1.0122 - accuracy: 0.7907 - val_loss: 10.4852 - val_accuracy: 0.1586\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 1.0136 - accuracy: 0.7898 - val_loss: 10.4825 - val_accuracy: 0.1593\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0130 - accuracy: 0.7898 - val_loss: 10.4890 - val_accuracy: 0.1600\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 1.0106 - accuracy: 0.7906 - val_loss: 10.5008 - val_accuracy: 0.1595\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0093 - accuracy: 0.7906 - val_loss: 10.4938 - val_accuracy: 0.1596\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 1.0079 - accuracy: 0.7916 - val_loss: 10.4897 - val_accuracy: 0.1595\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0070 - accuracy: 0.7915 - val_loss: 10.5323 - val_accuracy: 0.1589\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 4s 358ms/step - loss: 1.0074 - accuracy: 0.7913 - val_loss: 10.5279 - val_accuracy: 0.1585\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.0054 - accuracy: 0.7918 - val_loss: 10.5502 - val_accuracy: 0.1590\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 1.0079 - accuracy: 0.7912 - val_loss: 10.5452 - val_accuracy: 0.1587\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0096 - accuracy: 0.7906 - val_loss: 10.5278 - val_accuracy: 0.1591\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.0080 - accuracy: 0.7914 - val_loss: 10.5222 - val_accuracy: 0.1594\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 1.0051 - accuracy: 0.7919 - val_loss: 10.5491 - val_accuracy: 0.1584\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 1.0006 - accuracy: 0.7932 - val_loss: 10.5392 - val_accuracy: 0.1588\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 0.9996 - accuracy: 0.7937 - val_loss: 10.5536 - val_accuracy: 0.1589\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9974 - accuracy: 0.7936 - val_loss: 10.5636 - val_accuracy: 0.1582\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9966 - accuracy: 0.7941 - val_loss: 10.5562 - val_accuracy: 0.1588\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.9961 - accuracy: 0.7938 - val_loss: 10.5666 - val_accuracy: 0.1592\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.9950 - accuracy: 0.7942 - val_loss: 10.5697 - val_accuracy: 0.1583\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 0.9955 - accuracy: 0.7939 - val_loss: 10.5663 - val_accuracy: 0.1594\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9933 - accuracy: 0.7948 - val_loss: 10.5686 - val_accuracy: 0.1590\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9917 - accuracy: 0.7952 - val_loss: 10.5768 - val_accuracy: 0.1588\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.9898 - accuracy: 0.7954 - val_loss: 10.5818 - val_accuracy: 0.1589\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 0.9889 - accuracy: 0.7960 - val_loss: 10.5842 - val_accuracy: 0.1583\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9884 - accuracy: 0.7955 - val_loss: 10.5958 - val_accuracy: 0.1589\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9880 - accuracy: 0.7956 - val_loss: 10.5925 - val_accuracy: 0.1589\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9871 - accuracy: 0.7962 - val_loss: 10.5837 - val_accuracy: 0.1586\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.9859 - accuracy: 0.7964 - val_loss: 10.6134 - val_accuracy: 0.1590\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9851 - accuracy: 0.7958 - val_loss: 10.6039 - val_accuracy: 0.1585\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9873 - accuracy: 0.7959 - val_loss: 10.6130 - val_accuracy: 0.1580\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9875 - accuracy: 0.7951 - val_loss: 10.6198 - val_accuracy: 0.1584\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9849 - accuracy: 0.7965 - val_loss: 10.6127 - val_accuracy: 0.1599\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.9827 - accuracy: 0.7968 - val_loss: 10.6254 - val_accuracy: 0.1577\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.9819 - accuracy: 0.7975 - val_loss: 10.6256 - val_accuracy: 0.1577\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9797 - accuracy: 0.7974 - val_loss: 10.6227 - val_accuracy: 0.1588\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9789 - accuracy: 0.7976 - val_loss: 10.6281 - val_accuracy: 0.1583\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 0.9764 - accuracy: 0.7982 - val_loss: 10.6485 - val_accuracy: 0.1588\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9756 - accuracy: 0.7988 - val_loss: 10.6467 - val_accuracy: 0.1593\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9751 - accuracy: 0.7987 - val_loss: 10.6570 - val_accuracy: 0.1584\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.9749 - accuracy: 0.7990 - val_loss: 10.6496 - val_accuracy: 0.1593\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 4s 371ms/step - loss: 0.9752 - accuracy: 0.7983 - val_loss: 10.6788 - val_accuracy: 0.1587\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9740 - accuracy: 0.7990 - val_loss: 10.6699 - val_accuracy: 0.1587\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.9748 - accuracy: 0.7980 - val_loss: 10.6755 - val_accuracy: 0.1587\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9765 - accuracy: 0.7976 - val_loss: 10.6951 - val_accuracy: 0.1588\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9746 - accuracy: 0.7982 - val_loss: 10.7106 - val_accuracy: 0.1583\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.9722 - accuracy: 0.7985 - val_loss: 10.6873 - val_accuracy: 0.1580\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.9695 - accuracy: 0.7999 - val_loss: 10.7040 - val_accuracy: 0.1571\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9682 - accuracy: 0.8003 - val_loss: 10.7081 - val_accuracy: 0.1585\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9673 - accuracy: 0.8010 - val_loss: 10.7180 - val_accuracy: 0.1590\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.9678 - accuracy: 0.8005 - val_loss: 10.7182 - val_accuracy: 0.1586\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9661 - accuracy: 0.8008 - val_loss: 10.7232 - val_accuracy: 0.1590\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9645 - accuracy: 0.8006 - val_loss: 10.7159 - val_accuracy: 0.1591\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.9693 - accuracy: 0.7993 - val_loss: 10.7271 - val_accuracy: 0.1590\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.9677 - accuracy: 0.8004 - val_loss: 10.7421 - val_accuracy: 0.1600\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9651 - accuracy: 0.8008 - val_loss: 10.7340 - val_accuracy: 0.1597\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.9634 - accuracy: 0.8006 - val_loss: 10.7495 - val_accuracy: 0.1587\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9624 - accuracy: 0.8011 - val_loss: 10.7396 - val_accuracy: 0.1591\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9616 - accuracy: 0.8016 - val_loss: 10.7503 - val_accuracy: 0.1579\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9602 - accuracy: 0.8018 - val_loss: 10.7536 - val_accuracy: 0.1582\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9588 - accuracy: 0.8020 - val_loss: 10.7456 - val_accuracy: 0.1593\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9612 - accuracy: 0.8015 - val_loss: 10.7503 - val_accuracy: 0.1592\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 4s 358ms/step - loss: 0.9628 - accuracy: 0.8010 - val_loss: 10.7496 - val_accuracy: 0.1588\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9629 - accuracy: 0.8010 - val_loss: 10.7615 - val_accuracy: 0.1583\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9596 - accuracy: 0.8019 - val_loss: 10.7737 - val_accuracy: 0.1585\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.9639 - accuracy: 0.8012 - val_loss: 10.7955 - val_accuracy: 0.1587\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9615 - accuracy: 0.8012 - val_loss: 10.7825 - val_accuracy: 0.1591\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9574 - accuracy: 0.8022 - val_loss: 10.7859 - val_accuracy: 0.1587\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9535 - accuracy: 0.8029 - val_loss: 10.7837 - val_accuracy: 0.1587\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9504 - accuracy: 0.8040 - val_loss: 10.7881 - val_accuracy: 0.1581\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9489 - accuracy: 0.8045 - val_loss: 10.7980 - val_accuracy: 0.1584\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9482 - accuracy: 0.8044 - val_loss: 10.8075 - val_accuracy: 0.1585\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 0.9460 - accuracy: 0.8050 - val_loss: 10.8177 - val_accuracy: 0.1583\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9439 - accuracy: 0.8057 - val_loss: 10.8156 - val_accuracy: 0.1572\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9434 - accuracy: 0.8057 - val_loss: 10.8266 - val_accuracy: 0.1580\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.9437 - accuracy: 0.8057 - val_loss: 10.8390 - val_accuracy: 0.1578\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.9449 - accuracy: 0.8055 - val_loss: 10.8317 - val_accuracy: 0.1580\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.9425 - accuracy: 0.8052 - val_loss: 10.8283 - val_accuracy: 0.1583\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9405 - accuracy: 0.8060 - val_loss: 10.8324 - val_accuracy: 0.1580\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.9390 - accuracy: 0.8061 - val_loss: 10.8347 - val_accuracy: 0.1578\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.9384 - accuracy: 0.8068 - val_loss: 10.8327 - val_accuracy: 0.1575\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.9386 - accuracy: 0.8066 - val_loss: 10.8389 - val_accuracy: 0.1585\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.9388 - accuracy: 0.8068 - val_loss: 10.8426 - val_accuracy: 0.1583\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.9368 - accuracy: 0.8068 - val_loss: 10.8507 - val_accuracy: 0.1583\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.9362 - accuracy: 0.8068 - val_loss: 10.8359 - val_accuracy: 0.1579\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9356 - accuracy: 0.8070 - val_loss: 10.8608 - val_accuracy: 0.1577\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 0.9340 - accuracy: 0.8076 - val_loss: 10.8646 - val_accuracy: 0.1576\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.9335 - accuracy: 0.8074 - val_loss: 10.8570 - val_accuracy: 0.1574\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9326 - accuracy: 0.8080 - val_loss: 10.8895 - val_accuracy: 0.1571\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.9314 - accuracy: 0.8079 - val_loss: 10.8789 - val_accuracy: 0.1576\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9295 - accuracy: 0.8083 - val_loss: 10.8804 - val_accuracy: 0.1575\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.9293 - accuracy: 0.8085 - val_loss: 10.8763 - val_accuracy: 0.1576\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.9297 - accuracy: 0.8087 - val_loss: 10.8773 - val_accuracy: 0.1575\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9314 - accuracy: 0.8078 - val_loss: 10.8923 - val_accuracy: 0.1576\n",
      "Epoch 282/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9290 - accuracy: 0.8087 - val_loss: 10.8946 - val_accuracy: 0.1566\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 0.9267 - accuracy: 0.8085 - val_loss: 10.8971 - val_accuracy: 0.1575\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 0.9249 - accuracy: 0.8096 - val_loss: 10.8979 - val_accuracy: 0.1578\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9264 - accuracy: 0.8091 - val_loss: 10.9064 - val_accuracy: 0.1574\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9255 - accuracy: 0.8095 - val_loss: 10.9063 - val_accuracy: 0.1578\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9243 - accuracy: 0.8101 - val_loss: 10.9177 - val_accuracy: 0.1572\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9226 - accuracy: 0.8098 - val_loss: 10.9145 - val_accuracy: 0.1577\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9215 - accuracy: 0.8102 - val_loss: 10.9119 - val_accuracy: 0.1579\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.9219 - accuracy: 0.8096 - val_loss: 10.9386 - val_accuracy: 0.1579\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.9209 - accuracy: 0.8102 - val_loss: 10.9408 - val_accuracy: 0.1580\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9227 - accuracy: 0.8095 - val_loss: 10.9272 - val_accuracy: 0.1576\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9302 - accuracy: 0.8078 - val_loss: 10.9465 - val_accuracy: 0.1566\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9248 - accuracy: 0.8091 - val_loss: 10.9429 - val_accuracy: 0.1576\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.9214 - accuracy: 0.8097 - val_loss: 10.9614 - val_accuracy: 0.1577\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.9188 - accuracy: 0.8105 - val_loss: 10.9554 - val_accuracy: 0.1580\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9190 - accuracy: 0.8106 - val_loss: 10.9408 - val_accuracy: 0.1576\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9203 - accuracy: 0.8102 - val_loss: 10.9506 - val_accuracy: 0.1582\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9169 - accuracy: 0.8108 - val_loss: 10.9550 - val_accuracy: 0.1583\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.9142 - accuracy: 0.8118 - val_loss: 10.9673 - val_accuracy: 0.1574\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9119 - accuracy: 0.8121 - val_loss: 10.9810 - val_accuracy: 0.1573\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9098 - accuracy: 0.8130 - val_loss: 10.9719 - val_accuracy: 0.1573\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9089 - accuracy: 0.8134 - val_loss: 10.9691 - val_accuracy: 0.1573\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 1.0157 - accuracy: 0.7872 - val_loss: 10.8565 - val_accuracy: 0.1592\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 1.0480 - accuracy: 0.7725 - val_loss: 10.8994 - val_accuracy: 0.1580\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 1.0026 - accuracy: 0.7853 - val_loss: 10.9447 - val_accuracy: 0.1577\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9666 - accuracy: 0.7961 - val_loss: 10.9499 - val_accuracy: 0.1593\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9496 - accuracy: 0.8009 - val_loss: 10.9466 - val_accuracy: 0.1590\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9335 - accuracy: 0.8061 - val_loss: 10.9510 - val_accuracy: 0.1589\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 0.9229 - accuracy: 0.8092 - val_loss: 10.9532 - val_accuracy: 0.1591\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.9162 - accuracy: 0.8106 - val_loss: 10.9663 - val_accuracy: 0.1583\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9121 - accuracy: 0.8121 - val_loss: 10.9748 - val_accuracy: 0.1581\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.9090 - accuracy: 0.8126 - val_loss: 10.9778 - val_accuracy: 0.1589\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.9062 - accuracy: 0.8131 - val_loss: 10.9884 - val_accuracy: 0.1579\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.9046 - accuracy: 0.8131 - val_loss: 10.9975 - val_accuracy: 0.1580\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 4s 358ms/step - loss: 0.9025 - accuracy: 0.8143 - val_loss: 11.0052 - val_accuracy: 0.1581\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9008 - accuracy: 0.8142 - val_loss: 11.0070 - val_accuracy: 0.1585\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8999 - accuracy: 0.8147 - val_loss: 11.0219 - val_accuracy: 0.1579\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 0.8985 - accuracy: 0.8154 - val_loss: 11.0144 - val_accuracy: 0.1584\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8975 - accuracy: 0.8150 - val_loss: 11.0267 - val_accuracy: 0.1586\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8964 - accuracy: 0.8155 - val_loss: 11.0405 - val_accuracy: 0.1586\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8954 - accuracy: 0.8159 - val_loss: 11.0404 - val_accuracy: 0.1580\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8952 - accuracy: 0.8158 - val_loss: 11.0506 - val_accuracy: 0.1574\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.8940 - accuracy: 0.8162 - val_loss: 11.0436 - val_accuracy: 0.1582\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8936 - accuracy: 0.8161 - val_loss: 11.0579 - val_accuracy: 0.1580\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8932 - accuracy: 0.8165 - val_loss: 11.0429 - val_accuracy: 0.1583\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.8924 - accuracy: 0.8167 - val_loss: 11.0687 - val_accuracy: 0.1574\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8908 - accuracy: 0.8169 - val_loss: 11.0676 - val_accuracy: 0.1573\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8899 - accuracy: 0.8170 - val_loss: 11.0651 - val_accuracy: 0.1578\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.8884 - accuracy: 0.8174 - val_loss: 11.0698 - val_accuracy: 0.1573\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.8875 - accuracy: 0.8182 - val_loss: 11.0936 - val_accuracy: 0.1581\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8870 - accuracy: 0.8183 - val_loss: 11.0853 - val_accuracy: 0.1579\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.8850 - accuracy: 0.8188 - val_loss: 11.0857 - val_accuracy: 0.1572\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8840 - accuracy: 0.8190 - val_loss: 11.0881 - val_accuracy: 0.1570\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8840 - accuracy: 0.8184 - val_loss: 11.0952 - val_accuracy: 0.1577\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8849 - accuracy: 0.8182 - val_loss: 11.0994 - val_accuracy: 0.1577\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 0.8836 - accuracy: 0.8188 - val_loss: 11.1183 - val_accuracy: 0.1566\n",
      "Epoch 338/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8838 - accuracy: 0.8186 - val_loss: 11.1159 - val_accuracy: 0.1575\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8833 - accuracy: 0.8183 - val_loss: 11.1246 - val_accuracy: 0.1572\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.8810 - accuracy: 0.8194 - val_loss: 11.1246 - val_accuracy: 0.1571\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8794 - accuracy: 0.8194 - val_loss: 11.1272 - val_accuracy: 0.1572\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.8787 - accuracy: 0.8200 - val_loss: 11.1301 - val_accuracy: 0.1574\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8788 - accuracy: 0.8197 - val_loss: 11.1373 - val_accuracy: 0.1577\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8777 - accuracy: 0.8196 - val_loss: 11.1307 - val_accuracy: 0.1568\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8772 - accuracy: 0.8194 - val_loss: 11.1328 - val_accuracy: 0.1570\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8767 - accuracy: 0.8202 - val_loss: 11.1429 - val_accuracy: 0.1571\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8777 - accuracy: 0.8195 - val_loss: 11.1385 - val_accuracy: 0.1577\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8819 - accuracy: 0.8185 - val_loss: 11.1352 - val_accuracy: 0.1569\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8861 - accuracy: 0.8174 - val_loss: 11.1473 - val_accuracy: 0.1572\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 0.8822 - accuracy: 0.8184 - val_loss: 11.1658 - val_accuracy: 0.1578\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8784 - accuracy: 0.8192 - val_loss: 11.1763 - val_accuracy: 0.1566\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8757 - accuracy: 0.8196 - val_loss: 11.1705 - val_accuracy: 0.1580\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8725 - accuracy: 0.8211 - val_loss: 11.1686 - val_accuracy: 0.1573\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8710 - accuracy: 0.8214 - val_loss: 11.1848 - val_accuracy: 0.1568\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.8693 - accuracy: 0.8216 - val_loss: 11.1796 - val_accuracy: 0.1572\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8677 - accuracy: 0.8226 - val_loss: 11.2023 - val_accuracy: 0.1573\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8700 - accuracy: 0.8213 - val_loss: 11.1892 - val_accuracy: 0.1570\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8898 - accuracy: 0.8164 - val_loss: 11.1925 - val_accuracy: 0.1573\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.9429 - accuracy: 0.8007 - val_loss: 11.1468 - val_accuracy: 0.1580\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 0.9158 - accuracy: 0.8078 - val_loss: 11.1848 - val_accuracy: 0.1579\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8996 - accuracy: 0.8124 - val_loss: 11.1791 - val_accuracy: 0.1569\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8964 - accuracy: 0.8135 - val_loss: 11.1929 - val_accuracy: 0.1575\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.8908 - accuracy: 0.8146 - val_loss: 11.1947 - val_accuracy: 0.1569\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.8787 - accuracy: 0.8187 - val_loss: 11.1965 - val_accuracy: 0.1578\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8731 - accuracy: 0.8205 - val_loss: 11.2031 - val_accuracy: 0.1581\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8691 - accuracy: 0.8215 - val_loss: 11.2189 - val_accuracy: 0.1579\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8667 - accuracy: 0.8217 - val_loss: 11.2283 - val_accuracy: 0.1578\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.8637 - accuracy: 0.8228 - val_loss: 11.2202 - val_accuracy: 0.1575\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8619 - accuracy: 0.8235 - val_loss: 11.2396 - val_accuracy: 0.1580\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.8609 - accuracy: 0.8238 - val_loss: 11.2400 - val_accuracy: 0.1576\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8596 - accuracy: 0.8236 - val_loss: 11.2437 - val_accuracy: 0.1577\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.8574 - accuracy: 0.8250 - val_loss: 11.2416 - val_accuracy: 0.1579\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8568 - accuracy: 0.8248 - val_loss: 11.2524 - val_accuracy: 0.1565\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8553 - accuracy: 0.8255 - val_loss: 11.2561 - val_accuracy: 0.1573\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8535 - accuracy: 0.8253 - val_loss: 11.2700 - val_accuracy: 0.1567\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8524 - accuracy: 0.8254 - val_loss: 11.2759 - val_accuracy: 0.1568\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.8520 - accuracy: 0.8256 - val_loss: 11.2783 - val_accuracy: 0.1569\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.8522 - accuracy: 0.8259 - val_loss: 11.2869 - val_accuracy: 0.1567\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 4s 361ms/step - loss: 0.8523 - accuracy: 0.8253 - val_loss: 11.2869 - val_accuracy: 0.1566\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8514 - accuracy: 0.8258 - val_loss: 11.2900 - val_accuracy: 0.1571\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8508 - accuracy: 0.8257 - val_loss: 11.2944 - val_accuracy: 0.1565\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8506 - accuracy: 0.8254 - val_loss: 11.2827 - val_accuracy: 0.1573\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8500 - accuracy: 0.8261 - val_loss: 11.3012 - val_accuracy: 0.1569\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8482 - accuracy: 0.8265 - val_loss: 11.2962 - val_accuracy: 0.1570\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8462 - accuracy: 0.8268 - val_loss: 11.3161 - val_accuracy: 0.1575\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8444 - accuracy: 0.8275 - val_loss: 11.3128 - val_accuracy: 0.1573\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8446 - accuracy: 0.8274 - val_loss: 11.3082 - val_accuracy: 0.1578\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8437 - accuracy: 0.8277 - val_loss: 11.3142 - val_accuracy: 0.1570\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8429 - accuracy: 0.8276 - val_loss: 11.3228 - val_accuracy: 0.1582\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8426 - accuracy: 0.8278 - val_loss: 11.3314 - val_accuracy: 0.1564\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8408 - accuracy: 0.8281 - val_loss: 11.3343 - val_accuracy: 0.1570\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8396 - accuracy: 0.8289 - val_loss: 11.3385 - val_accuracy: 0.1568\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.8399 - accuracy: 0.8285 - val_loss: 11.3337 - val_accuracy: 0.1562\n",
      "Epoch 394/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 370ms/step - loss: 0.8389 - accuracy: 0.8284 - val_loss: 11.3439 - val_accuracy: 0.1570\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8372 - accuracy: 0.8289 - val_loss: 11.3505 - val_accuracy: 0.1564\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8370 - accuracy: 0.8290 - val_loss: 11.3367 - val_accuracy: 0.1581\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8470 - accuracy: 0.8258 - val_loss: 11.3366 - val_accuracy: 0.1569\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8433 - accuracy: 0.8273 - val_loss: 11.3565 - val_accuracy: 0.1575\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.8475 - accuracy: 0.8259 - val_loss: 11.3635 - val_accuracy: 0.1569\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8464 - accuracy: 0.8259 - val_loss: 11.3455 - val_accuracy: 0.1582\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8423 - accuracy: 0.8268 - val_loss: 11.3712 - val_accuracy: 0.1569\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8388 - accuracy: 0.8277 - val_loss: 11.3677 - val_accuracy: 0.1573\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.8364 - accuracy: 0.8287 - val_loss: 11.3727 - val_accuracy: 0.1574\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8357 - accuracy: 0.8286 - val_loss: 11.3750 - val_accuracy: 0.1565\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.8340 - accuracy: 0.8294 - val_loss: 11.3745 - val_accuracy: 0.1572\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8333 - accuracy: 0.8294 - val_loss: 11.3906 - val_accuracy: 0.1570\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.8318 - accuracy: 0.8298 - val_loss: 11.4115 - val_accuracy: 0.1566\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8304 - accuracy: 0.8302 - val_loss: 11.4070 - val_accuracy: 0.1569\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8275 - accuracy: 0.8308 - val_loss: 11.4068 - val_accuracy: 0.1565\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8258 - accuracy: 0.8319 - val_loss: 11.4237 - val_accuracy: 0.1561\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8283 - accuracy: 0.8307 - val_loss: 11.4073 - val_accuracy: 0.1569\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8299 - accuracy: 0.8306 - val_loss: 11.4249 - val_accuracy: 0.1566\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8279 - accuracy: 0.8306 - val_loss: 11.4216 - val_accuracy: 0.1581\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 0.8263 - accuracy: 0.8309 - val_loss: 11.4246 - val_accuracy: 0.1566\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8246 - accuracy: 0.8316 - val_loss: 11.4276 - val_accuracy: 0.1563\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8237 - accuracy: 0.8315 - val_loss: 11.4384 - val_accuracy: 0.1567\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8222 - accuracy: 0.8317 - val_loss: 11.4485 - val_accuracy: 0.1573\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8826 - accuracy: 0.8155 - val_loss: 11.4709 - val_accuracy: 0.1558\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8751 - accuracy: 0.8162 - val_loss: 11.4055 - val_accuracy: 0.1569\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8563 - accuracy: 0.8213 - val_loss: 11.4259 - val_accuracy: 0.1572\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8420 - accuracy: 0.8263 - val_loss: 11.4361 - val_accuracy: 0.1580\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.8340 - accuracy: 0.8282 - val_loss: 11.4402 - val_accuracy: 0.1574\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8271 - accuracy: 0.8305 - val_loss: 11.4572 - val_accuracy: 0.1583\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8221 - accuracy: 0.8318 - val_loss: 11.4512 - val_accuracy: 0.1572\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8193 - accuracy: 0.8325 - val_loss: 11.4556 - val_accuracy: 0.1569\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8179 - accuracy: 0.8327 - val_loss: 11.4716 - val_accuracy: 0.1566\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8167 - accuracy: 0.8333 - val_loss: 11.4612 - val_accuracy: 0.1570\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8168 - accuracy: 0.8339 - val_loss: 11.4803 - val_accuracy: 0.1573\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.8167 - accuracy: 0.8333 - val_loss: 11.4791 - val_accuracy: 0.1571\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8139 - accuracy: 0.8335 - val_loss: 11.4808 - val_accuracy: 0.1572\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8123 - accuracy: 0.8348 - val_loss: 11.4867 - val_accuracy: 0.1573\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8108 - accuracy: 0.8351 - val_loss: 11.4920 - val_accuracy: 0.1570\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 0.8094 - accuracy: 0.8351 - val_loss: 11.4934 - val_accuracy: 0.1569\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8091 - accuracy: 0.8356 - val_loss: 11.4992 - val_accuracy: 0.1568\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8098 - accuracy: 0.8353 - val_loss: 11.4933 - val_accuracy: 0.1568\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.8103 - accuracy: 0.8348 - val_loss: 11.5079 - val_accuracy: 0.1568\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.8092 - accuracy: 0.8347 - val_loss: 11.5140 - val_accuracy: 0.1563\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8069 - accuracy: 0.8356 - val_loss: 11.5242 - val_accuracy: 0.1566\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.8058 - accuracy: 0.8363 - val_loss: 11.5326 - val_accuracy: 0.1555\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8052 - accuracy: 0.8364 - val_loss: 11.5309 - val_accuracy: 0.1562\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8053 - accuracy: 0.8356 - val_loss: 11.5387 - val_accuracy: 0.1554\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8043 - accuracy: 0.8363 - val_loss: 11.5395 - val_accuracy: 0.1569\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.8025 - accuracy: 0.8367 - val_loss: 11.5385 - val_accuracy: 0.1563\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.8016 - accuracy: 0.8371 - val_loss: 11.5425 - val_accuracy: 0.1559\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.8007 - accuracy: 0.8374 - val_loss: 11.5509 - val_accuracy: 0.1561\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.7997 - accuracy: 0.8378 - val_loss: 11.5518 - val_accuracy: 0.1557\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.7996 - accuracy: 0.8376 - val_loss: 11.5548 - val_accuracy: 0.1559\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.7994 - accuracy: 0.8374 - val_loss: 11.5510 - val_accuracy: 0.1555\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 0.8020 - accuracy: 0.8366 - val_loss: 11.5390 - val_accuracy: 0.1559\n",
      "Epoch 450/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 369ms/step - loss: 0.8069 - accuracy: 0.8349 - val_loss: 11.5448 - val_accuracy: 0.1561\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.8029 - accuracy: 0.8364 - val_loss: 11.5820 - val_accuracy: 0.1553\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.7987 - accuracy: 0.8377 - val_loss: 11.5738 - val_accuracy: 0.1560\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7953 - accuracy: 0.8386 - val_loss: 11.5759 - val_accuracy: 0.1558\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7956 - accuracy: 0.8385 - val_loss: 11.5718 - val_accuracy: 0.1559\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.7970 - accuracy: 0.8376 - val_loss: 11.6026 - val_accuracy: 0.1552\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 0.7974 - accuracy: 0.8380 - val_loss: 11.5857 - val_accuracy: 0.1556\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.7963 - accuracy: 0.8384 - val_loss: 11.5918 - val_accuracy: 0.1555\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.7945 - accuracy: 0.8386 - val_loss: 11.6031 - val_accuracy: 0.1564\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7931 - accuracy: 0.8389 - val_loss: 11.6059 - val_accuracy: 0.1562\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.7913 - accuracy: 0.8389 - val_loss: 11.6140 - val_accuracy: 0.1557\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7897 - accuracy: 0.8398 - val_loss: 11.6175 - val_accuracy: 0.1559\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.7886 - accuracy: 0.8403 - val_loss: 11.6244 - val_accuracy: 0.1552\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7886 - accuracy: 0.8401 - val_loss: 11.6299 - val_accuracy: 0.1556\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 4s 372ms/step - loss: 0.7878 - accuracy: 0.8403 - val_loss: 11.6442 - val_accuracy: 0.1556\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7882 - accuracy: 0.8400 - val_loss: 11.6470 - val_accuracy: 0.1551\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.7867 - accuracy: 0.8405 - val_loss: 11.6386 - val_accuracy: 0.1555\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.7852 - accuracy: 0.8409 - val_loss: 11.6438 - val_accuracy: 0.1555\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.7848 - accuracy: 0.8401 - val_loss: 11.6539 - val_accuracy: 0.1550\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.7845 - accuracy: 0.8406 - val_loss: 11.6697 - val_accuracy: 0.1560\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.7840 - accuracy: 0.8411 - val_loss: 11.6519 - val_accuracy: 0.1552\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.7843 - accuracy: 0.8404 - val_loss: 11.6565 - val_accuracy: 0.1546\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 4s 371ms/step - loss: 0.7826 - accuracy: 0.8411 - val_loss: 11.6639 - val_accuracy: 0.1556\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 4s 363ms/step - loss: 0.7824 - accuracy: 0.8415 - val_loss: 11.6520 - val_accuracy: 0.1553\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7838 - accuracy: 0.8413 - val_loss: 11.6585 - val_accuracy: 0.1562\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7865 - accuracy: 0.8399 - val_loss: 11.6678 - val_accuracy: 0.1560\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7861 - accuracy: 0.8397 - val_loss: 11.6638 - val_accuracy: 0.1560\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.7855 - accuracy: 0.8403 - val_loss: 11.6954 - val_accuracy: 0.1556\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7823 - accuracy: 0.8410 - val_loss: 11.6818 - val_accuracy: 0.1549\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.7799 - accuracy: 0.8417 - val_loss: 11.6892 - val_accuracy: 0.1553\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.7814 - accuracy: 0.8408 - val_loss: 11.6968 - val_accuracy: 0.1556\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.7800 - accuracy: 0.8416 - val_loss: 11.7008 - val_accuracy: 0.1546\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.7780 - accuracy: 0.8421 - val_loss: 11.7034 - val_accuracy: 0.1550\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.7764 - accuracy: 0.8430 - val_loss: 11.7119 - val_accuracy: 0.1546\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.7778 - accuracy: 0.8423 - val_loss: 11.7079 - val_accuracy: 0.1554\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.7769 - accuracy: 0.8423 - val_loss: 11.7183 - val_accuracy: 0.1553\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.7747 - accuracy: 0.8429 - val_loss: 11.7246 - val_accuracy: 0.1556\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7746 - accuracy: 0.8431 - val_loss: 11.7235 - val_accuracy: 0.1544\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 4s 368ms/step - loss: 0.7720 - accuracy: 0.8440 - val_loss: 11.7348 - val_accuracy: 0.1547\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.7705 - accuracy: 0.8437 - val_loss: 11.7345 - val_accuracy: 0.1555\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.7712 - accuracy: 0.8438 - val_loss: 11.7327 - val_accuracy: 0.1552\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 4s 362ms/step - loss: 0.7706 - accuracy: 0.8438 - val_loss: 11.7375 - val_accuracy: 0.1552\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.7690 - accuracy: 0.8443 - val_loss: 11.7579 - val_accuracy: 0.1556\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 4s 370ms/step - loss: 0.7685 - accuracy: 0.8442 - val_loss: 11.7657 - val_accuracy: 0.1548\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.7694 - accuracy: 0.8441 - val_loss: 11.7673 - val_accuracy: 0.1540\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.7693 - accuracy: 0.8445 - val_loss: 11.7695 - val_accuracy: 0.1549\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 4s 369ms/step - loss: 0.7722 - accuracy: 0.8432 - val_loss: 11.7729 - val_accuracy: 0.1555\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 4s 365ms/step - loss: 0.7697 - accuracy: 0.8442 - val_loss: 11.7675 - val_accuracy: 0.1555\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 4s 366ms/step - loss: 0.7670 - accuracy: 0.8447 - val_loss: 11.7641 - val_accuracy: 0.1549\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.7664 - accuracy: 0.8451 - val_loss: 11.7715 - val_accuracy: 0.1538\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 4s 367ms/step - loss: 0.7759 - accuracy: 0.8418 - val_loss: 11.7579 - val_accuracy: 0.1545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8791dd3850>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, \n",
    "          validation_split=0.1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = 'model_ver7.hdf5'\n",
    "model.save(file_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "file_model = 'model_ver7.hdf5'\n",
    "model = load_model(file_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_generation(model, tags):\n",
    "    tags = tags.copy()\n",
    "    tags.append('\\t')\n",
    "    sentence = ''\n",
    "    while tags[-1] != '\\n' and len(tags) < max_seq_length:\n",
    "        x_test = np.zeros(shape=(1, max_seq_length), dtype='int32')\n",
    "        x_test[0, -len(tags):] = [w2i_output[w] for w in tags]\n",
    "        result = model.predict_classes(x_test, verbose=0)\n",
    "        tags.append(output_words[result[0]])\n",
    "        sentence += ' ' + tags[-1]\n",
    "    return sentence.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본\n",
      "맛집 오늘의 포인트 이없다는거\n",
      "['맛집', '없', '오늘', '이', '포인트']\n",
      "예측\n",
      " 누나 거기 다가 컴백 홈 트 자켓으로 오늘 도 하루 도 별 이 들 어서 우리 는 독 박 육아 한 상 이 다른 최 고급 미러 급 제품 직접 받 아 보 시 어요 우드 행 잉 액자 품절 시 행사 가 종료 되 ㅂ니다 예약 은 브레드 세븐 에서 준비 하 아 보 시 어요 \n",
      "\n",
      "원본\n",
      "오늘 하늘 너무 이쁘다\n",
      "['너무', '오늘', '이쁘', '하늘']\n",
      "예측\n",
      " 하늘 보 면서 무슨 생각 보다 \n",
      "\n",
      "원본\n",
      "우오오오오옹 전역 일차 날씨 짱좋다아아아아\n",
      "['오오', '오오', '옹', '우', '전역']\n",
      "예측\n",
      " 이제 아침 이 돌 아서 아침 도 너무 좋 아 지 고 피곤 하 ㄹ 때 마다 항상 쓰 어 먹 었 어요 쨍 쨍 햇빛 에 선글라스 필수 죠 보통 패션 선글라스 는 운동 하 기 간편 하 게 \n",
      "\n",
      "원본\n",
      "하늘이너무이쁘다\n",
      "['너무', '이쁘', '하늘']\n",
      "예측\n",
      " 하늘 이 너무 이쁘 다 \n",
      "\n",
      "원본\n",
      "하늘이 맑고 푸르다\n",
      "['맑', '푸르', '하늘']\n",
      "예측\n",
      " 하늘 이 너무 이쁘 ㄴ 곳 \n",
      "\n",
      "원본\n",
      "얼마만에 이런 하늘이야 넘 좋다\n",
      "['넘', '얼마', '이런', '좋', '하늘']\n",
      "예측\n",
      " 얼마 만 에 보 고 싶 다 \n",
      "\n",
      "원본\n",
      "오랜만에 맑은 하늘\n",
      "['맑', '오랜만', '하늘']\n",
      "예측\n",
      " 오늘 날씨 미치 었 다 산 에 가 아서 팩 이나 하 아 주 어서 좋 으시 ㄴ 분 들 에게 주 시 었 습니다 웃음 이 끊기 지 않 았 습니다 방문 전 함께 분 의 교감 중 \n",
      "\n",
      "원본\n",
      "오우 오늘 무슨일 이쁘다증말 잠시김밥사러 산책 쫌만걸어도배가너무땡겨\n",
      "['무슨', '오늘', '오우', '이쁘', '일']\n",
      "예측\n",
      " 오우 오늘 무슨 일 만 산 롭 어 지 어 지나 ㄴ 시간 이 열심히 채우 어 먹 을 수 있 어서 좋 아요 \n",
      "\n",
      "원본\n",
      "오늘 하늘이 너무 이뻐서 시간차로 계속 찍게되네\n",
      "['너무', '시간', '오늘', '이쁘', '하늘']\n",
      "예측\n",
      " 하늘 보 면서 무슨 생각 하 고 있 는데 금식 하 고 있 는데 금식 하 고 있 는데 금식 하 고 싶 다 \n",
      "\n",
      "원본\n",
      "아니 이게 무슨일이야 이렇게 맑을 수 있어 산이란 산은 내눈에 다보이고 하늘에 떠있는 저 수많은 구름들은 솜사탕 같아서 다 찢어서 먹고 싶어 생각만해도 달콤달콤 최고의 날씨\n",
      "['무슨', '아니', '이', '이렇', '일']\n",
      "예측\n",
      " 이 바람 은 정말 이 ㄴ지 기억 이예 요 너 나 고급 스럽 게 하 아 주 고 누룽지 에 오징어 젓갈 계란말이 해 달래 ㄴ다 작 은 재 재 는 계란말이 에 케찹 크 ㄴ 재 재 입 스럽 ㄴ 금 포 스팅 하 ㄹ게 건강 에 들 어 주 는 마음 으로 마음 에 들 지 않 는 제자 가 되 ㄹ 꺼 라고 하 ㄹ 수 있 는 건 데 서 나 는 엄마 가 곰돌이템은 꾸준히 살 거래 요 왜냐면 전 이 이 니깐 요 \n",
      "\n",
      "원본\n",
      "오늘 너무 예뻐서 안나올 수가 없었네\n",
      "['나오', '너무', '안', '예뻐서', '오늘']\n",
      "예측\n",
      " 오늘 도 너무 이쁘 ㄴ 요즘 날씨 네 요 파스타 가 더 좋 은 상품 을 무료 로 만들 ㄴ 셔츠 의자 주문 하 고 화장실 도 많이 드리 ㅂ니다 저희 명품샵을 통하 아 주 시 어요 답변 이 많 은 곳 을 받 겠 어요 오늘 도 건강히 즐거운 하루 되 시 어요 \n",
      "\n",
      "원본\n",
      "예쁘다 찍은 하늘\n",
      "['예쁘', '찍', '하늘']\n",
      "예측\n",
      " 맑 고 맑 고 너무 좋 다 \n",
      "\n",
      "원본\n",
      "사회를 통제하는 코로나 세상을 움직이는 자연 모든것이 비정상인 것같은 요즘에 시간은 정상적으로 흐르고있으니 만끽하고 살아가라고 멋진 하늘을 보여주는 듯 싶다 변치않아 익숙한 것들에 대한 감사하고 변하는 세상에서 무사히 잘 지내고 있음에 감사하는 일요일\n",
      "['사회', '세상', '움직이', '코로나', '통제']\n",
      "예측\n",
      " 사회 를 통제 하 는 광저우 도매 사무실 이 므로 모든 상품 의 가능 하 ㄴ 사진 은 검 수 좋 아요 저희 는 다수 의 가능 인 스타 일링 방법 을 보이 어 드리 고 있 습니다 안심 하 고 있 습니다 \n",
      "\n",
      "원본\n",
      "낮이되니 흰구름\n",
      "['구름', '낮', '이', '희']\n",
      "예측\n",
      " 요즘 갈색 까 지 동네 사람 이 었 는데 우리 둘 만 알 는 날 은 킥 보드 자전거 보다 개월 이 라는 길 ㄴ 거 아니 ㅁ 젤 나 챙기 어 주 어서 고맙 어 \n",
      "\n",
      "원본\n",
      "이마에 주름 만들던 시간 아이고 의미없다 좀 여유갖고 내일은 한번 더 웃자 능구렁이 같은 짓 잘하자나 힘내셔\n",
      "['만들', '시간', '아이고', '이마', '주름']\n",
      "예측\n",
      " 이마 에 주름 만들 던 시간 아이고 의미 없 다 좀 여유 갖 고 좋 아요 팔 아도 바다 \n",
      "\n",
      "원본\n",
      "오늘은 만들어 먹고 봤음 밖은 어떤가 싶어서 열었더니 보고 기분좋아짐 근데\n",
      "['만들', '먹', '밖', '보', '오늘']\n",
      "예측\n",
      " 오늘 은 오월 이 의 내 인생 에 첫날 \n",
      "\n",
      "원본\n",
      "구름 참 예쁘네\n",
      "['구름', '예쁘', '참']\n",
      "예측\n",
      " 사람 없 는 우리 주 ㄴ 이 에 도 없 고 좋 은 날 아예 모르 고 있 으니 만끽 하 고 살아가 라고 멋지 ㄴ 것 도 하 는지 알 겠 네 용 \n",
      "\n",
      "원본\n",
      "구름 바람 할 나위없는 휴일 걸어가기 봐\n",
      "['구름', '나위', '바람', '없', '하']\n",
      "예측\n",
      " 산책 하 기 딱 좋은 날 씨 자주 눈 에 두 어 올리 어 주 어서 고맙 어 \n",
      "\n",
      "원본\n",
      "캠핑 와서 제일 좋은 때 집 짓기 끝내고 남편 손잡고 캠핑장 한바퀴 돌아볼때 남편 팔베개 하고 낮잠 잘 때 잘 노는 공주님들은 덤\n",
      "['때', '오', '제일', '좋', '캠핑']\n",
      "예측\n",
      " 캠핑 오 아서 입 던 은 조망 보다 넘 나 훈훈 김민석 노래 부르 ㄹ 때 귀 아프 지만 오늘 도 등산 먹 은지 색감 은 바로 가 하 더니 식탁 을 찾 고 웃 어야 하 ㅁ 이 나 보다 더 맛있 었 던 어제 집 짓 고 뜯 고 다 크 어 나가 ㄴ 거 얌 무섭 니까 또 가 고 싶 어 칼 칼 하 게 끓이 어 먹 고 수플레 밑 에 깔리 ㄴ 볶음밥 이랑 계란뭉탱이 같이 먹 으면 쏘 쏘 맛있어욤 평일 저녁 우리 테이블 만 있 는 라면 은 진짜 좋아하 는 재미 맛있 음 에 별 중 이 다 \n",
      "\n",
      "원본\n",
      "유독 반가운 맑은 하늘\n",
      "['맑', '반갑', '유독', '하늘']\n",
      "예측\n",
      " 유독 반갑 ㄴ 하늘 하늘 너무 이쁘 고 맑 은 하늘 을 너무 좋 네요 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_idx = 0\n",
    "end_idx = start_idx + 20\n",
    "for ori, tags in zip(sentence_data[start_idx:end_idx], input_tags[start_idx:end_idx]):\n",
    "    print('원본')\n",
    "    print(ori[1:-1])\n",
    "    print(tags)\n",
    "    print('예측')\n",
    "    print(sequence_generation(model, tags))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['맛집', '오늘', '포인트', '이', '없', '거']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-125-d4df8bf74e1c>:14: BasicLSTMCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_embedding = 64\n",
    "n_hidden = 64\n",
    "learning_rate = 1e-2\n",
    "\n",
    "X = tf.placeholder(tf.int32, shape=(None, max_seq_length))\n",
    "Y = tf.placeholder(tf.int32, shape=(None,))\n",
    "# Y = tf.placeholder(tf.float32, shape=(None,))\n",
    "\n",
    "embedding = tf.Variable(tf.random_uniform((n_output_words, n_embedding), -1, 1))\n",
    "embed = tf.nn.embedding_lookup(embedding, X)\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, embed, dtype=tf.float32)\n",
    "\n",
    "model = tf.layers.dense(tf.reshape(outputs, [-1, max_seq_length*n_hidden]), n_output_words, activation=tf.nn.softmax)\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "predict = tf.arg_max(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:68:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, \n",
    "                                            log_device_placement=True))\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(6883, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/kernel:0' shape=(128, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(14848, 6883) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(6883,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.08it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Cost: 8.803528 Valid Cost: 8.801259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.22it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0002 Cost: 8.800805 Valid Cost: 8.801259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.19it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003 Cost: 8.800805 Valid Cost: 8.801259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 10/22 [00:02<00:03,  3.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-490c932012e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         _, loss = sess.run([optimizer, cost], feed_dict={\n\u001b[1;32m     12\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             })\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_epoch = 100\n",
    "\n",
    "# for epoch in tqdm(range(total_epoch)):\n",
    "for epoch in range(total_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(range(n_batch)):\n",
    "#     for batch in range(n_batch):\n",
    "        batch_xs = x_train[batch*batch_size:(batch+1)*batch_size]\n",
    "        batch_ys = y_train[batch*batch_size:(batch+1)*batch_size]\n",
    "        \n",
    "        _, loss = sess.run([optimizer, cost], feed_dict={\n",
    "                X: batch_xs,\n",
    "                Y: batch_ys\n",
    "            })\n",
    "        \n",
    "        total_loss += loss\n",
    "    \n",
    "    total_valid_loss = 0\n",
    "    for batch in range(n_valid):\n",
    "        valid_xs = x_valid[batch*batch_size:(batch+1)*batch_size]\n",
    "        valid_ys = y_valid[batch*batch_size:(batch+1)*batch_size]\n",
    "        \n",
    "        val_loss = sess.run(cost, feed_dict={\n",
    "                X: valid_xs,\n",
    "                Y: valid_ys\n",
    "            })\n",
    "        total_valid_loss += val_loss\n",
    "    \n",
    "    print('Epoch: %04d Cost: %.6f Valid Cost: %.6f' %(epoch + 1, total_loss / n_batch, total_valid_loss / n_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(tags):\n",
    "    x_test = np.zeros(shape=(1, max_seq_length), dtype='float32')\n",
    "    tags = tags + ['\\t']\n",
    "    idx = -len(tags)\n",
    "    x_test[0, idx:] = [w2i_output[w] for w in tags]\n",
    "    while x_test[0, -1] != w2i_output['\\n'] and x_test[0][0] == 0:\n",
    "        print(idx)\n",
    "        pred = sess.run(predict, feed_dict={X: x_test})[0]\n",
    "        x_test[0, idx-1:-1] = x_test[0, idx:]\n",
    "        x_test[0, -1] = pred\n",
    "        idx -= 1\n",
    "    end = np.where(x_test[0]==w2i_output['\\n'])[0]\n",
    "    end = end[0] if end.shape[0] > 0 else -1\n",
    "    ret = x_test[0, np.where(x_test[0]==w2i_output['\\t'])[0][0]:end]\n",
    "    return ''.join([output_words[ret]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7\n",
      "-8\n",
      "-9\n",
      "-10\n",
      "-11\n",
      "-12\n",
      "-13\n",
      "-14\n",
      "-15\n",
      "-16\n",
      "-17\n",
      "-18\n",
      "-19\n",
      "-20\n",
      "-21\n",
      "-22\n",
      "-23\n",
      "-24\n",
      "-25\n",
      "-26\n",
      "-27\n",
      "-28\n",
      "-29\n",
      "-30\n",
      "-31\n",
      "-32\n",
      "-33\n",
      "-34\n",
      "-35\n",
      "-36\n",
      "-37\n",
      "-38\n",
      "-39\n",
      "-40\n",
      "-41\n",
      "-42\n",
      "-43\n",
      "-44\n",
      "-45\n",
      "-46\n",
      "-47\n",
      "-48\n",
      "-49\n",
      "-50\n",
      "-51\n",
      "-52\n",
      "-53\n",
      "-54\n",
      "-55\n",
      "-56\n",
      "-57\n",
      "-58\n",
      "-59\n",
      "-60\n",
      "-61\n",
      "-62\n",
      "-63\n",
      "-64\n",
      "-65\n",
      "-66\n",
      "-67\n",
      "-68\n",
      "-69\n",
      "-70\n",
      "-71\n",
      "-72\n",
      "-73\n",
      "-74\n",
      "-75\n",
      "-76\n",
      "-77\n",
      "-78\n",
      "-79\n",
      "-80\n",
      "-81\n",
      "-82\n",
      "-83\n",
      "-84\n",
      "-85\n",
      "-86\n",
      "-87\n",
      "-88\n",
      "-89\n",
      "-90\n",
      "-91\n",
      "-92\n",
      "-93\n",
      "-94\n",
      "-95\n",
      "-96\n",
      "-97\n",
      "-98\n",
      "-99\n",
      "-100\n",
      "-101\n",
      "-102\n",
      "-103\n",
      "-104\n",
      "-105\n",
      "-106\n",
      "-107\n",
      "-108\n",
      "-109\n",
      "-110\n",
      "-111\n",
      "-112\n",
      "-113\n",
      "-114\n",
      "-115\n",
      "-116\n",
      "-117\n",
      "-118\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-b1de23712143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw2i_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tags = input_tags[0]\n",
    "x_test = np.zeros(shape=(1, max_seq_length), dtype='float32')\n",
    "tags = tags + ['\\t']\n",
    "idx = -len(tags)\n",
    "x_test[0, idx:] = [w2i_output[w] for w in tags]\n",
    "while x_test[0, -1] != w2i_output['\\n'] and x_test[0][0] == 0:\n",
    "    print(idx)\n",
    "    pred = sess.run(predict, feed_dict={X: x_test})[0]\n",
    "    x_test[0, idx-1:-1] = x_test[0, idx:]\n",
    "    x_test[0, -1] = pred\n",
    "    idx -= 1\n",
    "end = np.where(x_test[0]==w2i_output['\\n'])[0]\n",
    "end = end[0] if end.shape[0] > 0 else -1\n",
    "ret = x_test[0, np.where(x_test[0]==w2i_output['\\t'])[0][0]:end]\n",
    "''.join([output_words[map(int, ret)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([output_words[int(i)] for i in ret])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keich Capstone",
   "language": "python",
   "name": "venv_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
