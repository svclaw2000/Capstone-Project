{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'data_256.pkl'\n",
    "image_data, sentiment_data, sentence_data, sentence_tags, hashtag_data = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 3000\n",
    "\n",
    "image_data = image_data[:size]\n",
    "sentiment_data = sentiment_data[:size]\n",
    "sentence_data = sentence_data[:size]\n",
    "sentence_tags = sentence_tags[:size]\n",
    "hashtag_data = hashtag_data[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 256, 256, 3)\n",
      "(3000, 4)\n",
      "(3000,)\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(image_data.shape)\n",
    "print(sentiment_data.shape)\n",
    "print(sentence_data.shape)\n",
    "print(len(sentence_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tags = [[tag[0] for tag in tags] for tags in sentence_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:02<00:00, 1010.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "\n",
    "output_tags = [[p[0] for p in komoran.pos(s)] for s in tqdm(sentence_data)]\n",
    "[tags.insert(0, '\\t') for tags in output_tags]\n",
    "[tags.append('\\n') for tags in output_tags]\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words = set()\n",
    "for tags in output_tags:\n",
    "    for tag in tags:\n",
    "        if tag not in output_words:\n",
    "            output_words.add(tag)\n",
    "            \n",
    "output_words = sorted(list(output_words))\n",
    "output_words.insert(0, 'P')\n",
    "n_output_words = len(output_words)\n",
    "\n",
    "max_seq_length = max([len(_out) for _out in output_tags])\n",
    "\n",
    "w2i_output = {w:i for i, w in enumerate(output_words)}\n",
    "\n",
    "seq_list = []\n",
    "\n",
    "for i, _out in enumerate(output_tags):\n",
    "    for j in range(1, len(_out)):\n",
    "        seq_list.append(_out[:j+1])\n",
    "        \n",
    "n_seq_data = len(seq_list)\n",
    "\n",
    "x_word_data = np.zeros(shape=(n_seq_data, n_output_words), dtype='int32')\n",
    "\n",
    "for i, tags in enumerate(input_tags):\n",
    "    for tag in tags:\n",
    "        word_data[i, w2i_output[tag]] += 1\n",
    "\n",
    "seq_data = np.zeros(shape=(n_seq_data, max_seq_length + 1), dtype='int32')\n",
    "\n",
    "for i, tags in enumerate(seq_list):\n",
    "    seq_data[i, -len(tags):] = [w2i_output[w] for w in tags]\n",
    "    \n",
    "y_eye = np.eye(n_output_words)\n",
    "x_seq_data = seq_data[:, :-1]\n",
    "y_seq_data = y_eye[seq_data[:, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    1, 2887],\n",
       "       [   0,    0,    0, ...,    1, 2887, 6151],\n",
       "       [   0,    0,    0, ..., 2887, 6151, 6751],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 9770, 4304, 6569],\n",
       "       [   0,    0,    0, ..., 4304, 6569, 4119],\n",
       "       [   0,    0,    0, ..., 6569, 4119,    2]], dtype=int32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((129470, 9948), (129470, 147), (129470, 9948))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_word_data.shape, x_seq_data.shape, y_seq_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0\n",
    "train_size = n_seq_data - valid_size\n",
    "batch_size = 7000\n",
    "n_batch = train_size // batch_size\n",
    "n_valid = valid_size // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN, LSTM, Input, Add\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_inputs = Input(shape=(n_output_words,))\n",
    "word_dense_1 = Dense(256, activation=None)(word_inputs)\n",
    "word_dense_2 = Dense(n_output_words, activation='softmax')(word_dense_1)\n",
    "\n",
    "seq_inputs = Input(shape=(max_seq_length,))\n",
    "embed = Embedding(n_output_words, 64)(seq_inputs)\n",
    "lstm = LSTM(128)(embed)\n",
    "seq_dense = Dense(n_output_words, activation='softmax')(lstm)\n",
    "\n",
    "dense_sum = Add()([word_dense_2, seq_dense])\n",
    "# final_dense = Dense(n_output_words, activation='softmax')(dense_sum)\n",
    "\n",
    "model = Model([word_inputs, seq_inputs], dense_sum)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(n_output_words, 64, input_length=max_seq_length))\n",
    "# model.add(LSTM(128))\n",
    "# model.add(Dense(n_output_words, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           [(None, 147)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 147, 64)      636672      input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           [(None, 9948)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 128)          98816       embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 9948)         98972652    input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 9948)         1283292     lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 9948)         0           dense_17[0][0]                   \n",
      "                                                                 dense_18[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 100,991,432\n",
      "Trainable params: 100,991,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "17/17 [==============================] - 10s 588ms/step - loss: 9.0901 - accuracy: 0.0227 - val_loss: 8.5843 - val_accuracy: 0.0256\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 7.7680 - accuracy: 0.0256 - val_loss: 7.1735 - val_accuracy: 0.0247\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 9s 523ms/step - loss: 7.0524 - accuracy: 0.0308 - val_loss: 7.0692 - val_accuracy: 0.0385\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 7.0122 - accuracy: 0.0364 - val_loss: 7.0493 - val_accuracy: 0.0385\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 9s 524ms/step - loss: 7.0011 - accuracy: 0.0364 - val_loss: 7.0435 - val_accuracy: 0.0385\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 6.9968 - accuracy: 0.0364 - val_loss: 7.0411 - val_accuracy: 0.0385\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 9s 525ms/step - loss: 6.9939 - accuracy: 0.0364 - val_loss: 7.0401 - val_accuracy: 0.0385\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 6.9920 - accuracy: 0.0364 - val_loss: 7.0378 - val_accuracy: 0.0385\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 6.9895 - accuracy: 0.0364 - val_loss: 7.0376 - val_accuracy: 0.0385\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 6.9871 - accuracy: 0.0364 - val_loss: 7.0360 - val_accuracy: 0.0385\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 6.9854 - accuracy: 0.0364 - val_loss: 7.0335 - val_accuracy: 0.0385\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 9s 538ms/step - loss: 6.9833 - accuracy: 0.0364 - val_loss: 7.0337 - val_accuracy: 0.0385\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 6.9814 - accuracy: 0.0364 - val_loss: 7.0311 - val_accuracy: 0.0385\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.9794 - accuracy: 0.0364 - val_loss: 7.0311 - val_accuracy: 0.0385\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 9s 525ms/step - loss: 6.9771 - accuracy: 0.0364 - val_loss: 7.0282 - val_accuracy: 0.0385\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 6.9747 - accuracy: 0.0364 - val_loss: 7.0274 - val_accuracy: 0.0385\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 6.9719 - accuracy: 0.0364 - val_loss: 7.0260 - val_accuracy: 0.0385\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.9681 - accuracy: 0.0364 - val_loss: 7.0214 - val_accuracy: 0.0385\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 6.9604 - accuracy: 0.0364 - val_loss: 7.0111 - val_accuracy: 0.0385\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 6.9333 - accuracy: 0.0364 - val_loss: 6.9740 - val_accuracy: 0.0385\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 6.8852 - accuracy: 0.0364 - val_loss: 6.9360 - val_accuracy: 0.0385\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 6.8391 - accuracy: 0.0380 - val_loss: 6.8982 - val_accuracy: 0.0423\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 6.7900 - accuracy: 0.0425 - val_loss: 6.8572 - val_accuracy: 0.0477\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 9s 546ms/step - loss: 6.7439 - accuracy: 0.0457 - val_loss: 6.8211 - val_accuracy: 0.0457\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 6.7045 - accuracy: 0.0462 - val_loss: 6.7920 - val_accuracy: 0.0460\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 6.6715 - accuracy: 0.0485 - val_loss: 6.7671 - val_accuracy: 0.0464\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 6.6422 - accuracy: 0.0525 - val_loss: 6.7448 - val_accuracy: 0.0480\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.6158 - accuracy: 0.0571 - val_loss: 6.7235 - val_accuracy: 0.0602\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.5924 - accuracy: 0.0654 - val_loss: 6.7071 - val_accuracy: 0.0627\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 6.5711 - accuracy: 0.0674 - val_loss: 6.6908 - val_accuracy: 0.0640\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.5512 - accuracy: 0.0700 - val_loss: 6.6770 - val_accuracy: 0.0671\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.5316 - accuracy: 0.0738 - val_loss: 6.6621 - val_accuracy: 0.0702\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.5123 - accuracy: 0.0764 - val_loss: 6.6478 - val_accuracy: 0.0727\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 6.4932 - accuracy: 0.0770 - val_loss: 6.6340 - val_accuracy: 0.0702\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 6.4740 - accuracy: 0.0773 - val_loss: 6.6203 - val_accuracy: 0.0697\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 6.4546 - accuracy: 0.0744 - val_loss: 6.6078 - val_accuracy: 0.0718\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 6.4348 - accuracy: 0.0762 - val_loss: 6.5948 - val_accuracy: 0.0716\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 6.4170 - accuracy: 0.0763 - val_loss: 6.5832 - val_accuracy: 0.0715\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 6.3959 - accuracy: 0.0779 - val_loss: 6.5682 - val_accuracy: 0.0718\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.3733 - accuracy: 0.0786 - val_loss: 6.5543 - val_accuracy: 0.0762\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 9s 525ms/step - loss: 6.3515 - accuracy: 0.0814 - val_loss: 6.5398 - val_accuracy: 0.0760\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.3270 - accuracy: 0.0846 - val_loss: 6.5232 - val_accuracy: 0.0776\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 6.3034 - accuracy: 0.0865 - val_loss: 6.5097 - val_accuracy: 0.0818\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.2797 - accuracy: 0.0901 - val_loss: 6.4960 - val_accuracy: 0.0839\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.2546 - accuracy: 0.0933 - val_loss: 6.4792 - val_accuracy: 0.0847\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 6.2290 - accuracy: 0.0957 - val_loss: 6.4652 - val_accuracy: 0.0884\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 6.2024 - accuracy: 0.0983 - val_loss: 6.4474 - val_accuracy: 0.0885\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 6.1738 - accuracy: 0.1026 - val_loss: 6.4288 - val_accuracy: 0.0904\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 6.1442 - accuracy: 0.1057 - val_loss: 6.4110 - val_accuracy: 0.0935\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 6.1153 - accuracy: 0.1100 - val_loss: 6.3922 - val_accuracy: 0.0967\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 6.0854 - accuracy: 0.1148 - val_loss: 6.3738 - val_accuracy: 0.1014\n",
      "Epoch 52/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 6.0568 - accuracy: 0.1195 - val_loss: 6.3576 - val_accuracy: 0.1058\n",
      "Epoch 53/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.0280 - accuracy: 0.1258 - val_loss: 6.3399 - val_accuracy: 0.1094\n",
      "Epoch 54/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 6.0004 - accuracy: 0.1310 - val_loss: 6.3245 - val_accuracy: 0.1105\n",
      "Epoch 55/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 5.9729 - accuracy: 0.1328 - val_loss: 6.3082 - val_accuracy: 0.1136\n",
      "Epoch 56/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 5.9464 - accuracy: 0.1389 - val_loss: 6.2914 - val_accuracy: 0.1162\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 529ms/step - loss: 5.9205 - accuracy: 0.1435 - val_loss: 6.2775 - val_accuracy: 0.1194\n",
      "Epoch 58/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 5.8948 - accuracy: 0.1469 - val_loss: 6.2628 - val_accuracy: 0.1235\n",
      "Epoch 59/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.8696 - accuracy: 0.1514 - val_loss: 6.2497 - val_accuracy: 0.1247\n",
      "Epoch 60/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 5.8453 - accuracy: 0.1558 - val_loss: 6.2364 - val_accuracy: 0.1264\n",
      "Epoch 61/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 5.8212 - accuracy: 0.1597 - val_loss: 6.2237 - val_accuracy: 0.1293\n",
      "Epoch 62/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 5.7980 - accuracy: 0.1624 - val_loss: 6.2117 - val_accuracy: 0.1318\n",
      "Epoch 63/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 5.7750 - accuracy: 0.1647 - val_loss: 6.2007 - val_accuracy: 0.1324\n",
      "Epoch 64/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 5.7527 - accuracy: 0.1673 - val_loss: 6.1901 - val_accuracy: 0.1346\n",
      "Epoch 65/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 5.7305 - accuracy: 0.1706 - val_loss: 6.1782 - val_accuracy: 0.1345\n",
      "Epoch 66/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 5.7083 - accuracy: 0.1730 - val_loss: 6.1689 - val_accuracy: 0.1365\n",
      "Epoch 67/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 5.6866 - accuracy: 0.1771 - val_loss: 6.1575 - val_accuracy: 0.1394\n",
      "Epoch 68/1000\n",
      "17/17 [==============================] - 9s 525ms/step - loss: 5.6651 - accuracy: 0.1803 - val_loss: 6.1469 - val_accuracy: 0.1427\n",
      "Epoch 69/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 5.6439 - accuracy: 0.1850 - val_loss: 6.1375 - val_accuracy: 0.1459\n",
      "Epoch 70/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.6229 - accuracy: 0.1892 - val_loss: 6.1282 - val_accuracy: 0.1470\n",
      "Epoch 71/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.6029 - accuracy: 0.1928 - val_loss: 6.1190 - val_accuracy: 0.1493\n",
      "Epoch 72/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.5827 - accuracy: 0.1973 - val_loss: 6.1090 - val_accuracy: 0.1502\n",
      "Epoch 73/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 5.5629 - accuracy: 0.2008 - val_loss: 6.1022 - val_accuracy: 0.1530\n",
      "Epoch 74/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 5.5433 - accuracy: 0.2032 - val_loss: 6.0949 - val_accuracy: 0.1546\n",
      "Epoch 75/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 5.5246 - accuracy: 0.2069 - val_loss: 6.0855 - val_accuracy: 0.1562\n",
      "Epoch 76/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.5055 - accuracy: 0.2096 - val_loss: 6.0782 - val_accuracy: 0.1583\n",
      "Epoch 77/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 5.4866 - accuracy: 0.2129 - val_loss: 6.0722 - val_accuracy: 0.1601\n",
      "Epoch 78/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 5.4684 - accuracy: 0.2169 - val_loss: 6.0642 - val_accuracy: 0.1602\n",
      "Epoch 79/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 5.4499 - accuracy: 0.2187 - val_loss: 6.0578 - val_accuracy: 0.1607\n",
      "Epoch 80/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 5.4322 - accuracy: 0.2203 - val_loss: 6.0515 - val_accuracy: 0.1619\n",
      "Epoch 81/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.4151 - accuracy: 0.2226 - val_loss: 6.0466 - val_accuracy: 0.1630\n",
      "Epoch 82/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 5.3980 - accuracy: 0.2246 - val_loss: 6.0393 - val_accuracy: 0.1610\n",
      "Epoch 83/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.3812 - accuracy: 0.2270 - val_loss: 6.0342 - val_accuracy: 0.1643\n",
      "Epoch 84/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.3651 - accuracy: 0.2283 - val_loss: 6.0284 - val_accuracy: 0.1651\n",
      "Epoch 85/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.3475 - accuracy: 0.2304 - val_loss: 6.0234 - val_accuracy: 0.1652\n",
      "Epoch 86/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 5.3315 - accuracy: 0.2322 - val_loss: 6.0182 - val_accuracy: 0.1662\n",
      "Epoch 87/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.3153 - accuracy: 0.2342 - val_loss: 6.0136 - val_accuracy: 0.1678\n",
      "Epoch 88/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 5.2988 - accuracy: 0.2364 - val_loss: 6.0082 - val_accuracy: 0.1677\n",
      "Epoch 89/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 5.2827 - accuracy: 0.2382 - val_loss: 6.0032 - val_accuracy: 0.1691\n",
      "Epoch 90/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 5.2672 - accuracy: 0.2404 - val_loss: 5.9993 - val_accuracy: 0.1708\n",
      "Epoch 91/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 5.2515 - accuracy: 0.2426 - val_loss: 5.9943 - val_accuracy: 0.1710\n",
      "Epoch 92/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 5.2364 - accuracy: 0.2445 - val_loss: 5.9904 - val_accuracy: 0.1705\n",
      "Epoch 93/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.2215 - accuracy: 0.2464 - val_loss: 5.9859 - val_accuracy: 0.1736\n",
      "Epoch 94/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 5.2061 - accuracy: 0.2483 - val_loss: 5.9814 - val_accuracy: 0.1730\n",
      "Epoch 95/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 5.1919 - accuracy: 0.2503 - val_loss: 5.9774 - val_accuracy: 0.1744\n",
      "Epoch 96/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 5.1776 - accuracy: 0.2521 - val_loss: 5.9754 - val_accuracy: 0.1739\n",
      "Epoch 97/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.1622 - accuracy: 0.2543 - val_loss: 5.9700 - val_accuracy: 0.1753\n",
      "Epoch 98/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 5.1476 - accuracy: 0.2560 - val_loss: 5.9671 - val_accuracy: 0.1766\n",
      "Epoch 99/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 5.1328 - accuracy: 0.2579 - val_loss: 5.9634 - val_accuracy: 0.1756\n",
      "Epoch 100/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 5.1179 - accuracy: 0.2598 - val_loss: 5.9600 - val_accuracy: 0.1763\n",
      "Epoch 101/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 5.1041 - accuracy: 0.2620 - val_loss: 5.9577 - val_accuracy: 0.1766\n",
      "Epoch 102/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 5.0899 - accuracy: 0.2633 - val_loss: 5.9550 - val_accuracy: 0.1780\n",
      "Epoch 103/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 5.0762 - accuracy: 0.2649 - val_loss: 5.9503 - val_accuracy: 0.1763\n",
      "Epoch 104/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 5.0620 - accuracy: 0.2673 - val_loss: 5.9483 - val_accuracy: 0.1770\n",
      "Epoch 105/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 5.0484 - accuracy: 0.2693 - val_loss: 5.9460 - val_accuracy: 0.1788\n",
      "Epoch 106/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 5.0346 - accuracy: 0.2708 - val_loss: 5.9421 - val_accuracy: 0.1790\n",
      "Epoch 107/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 5.0211 - accuracy: 0.2723 - val_loss: 5.9400 - val_accuracy: 0.1788\n",
      "Epoch 108/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 5.0075 - accuracy: 0.2739 - val_loss: 5.9393 - val_accuracy: 0.1794\n",
      "Epoch 109/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.9940 - accuracy: 0.2761 - val_loss: 5.9363 - val_accuracy: 0.1801\n",
      "Epoch 110/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.9806 - accuracy: 0.2775 - val_loss: 5.9334 - val_accuracy: 0.1811\n",
      "Epoch 111/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.9679 - accuracy: 0.2794 - val_loss: 5.9313 - val_accuracy: 0.1806\n",
      "Epoch 112/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.9544 - accuracy: 0.2811 - val_loss: 5.9300 - val_accuracy: 0.1804\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 530ms/step - loss: 4.9408 - accuracy: 0.2831 - val_loss: 5.9281 - val_accuracy: 0.1802\n",
      "Epoch 114/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 4.9285 - accuracy: 0.2845 - val_loss: 5.9266 - val_accuracy: 0.1805\n",
      "Epoch 115/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 4.9154 - accuracy: 0.2865 - val_loss: 5.9251 - val_accuracy: 0.1811\n",
      "Epoch 116/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 4.9037 - accuracy: 0.2889 - val_loss: 5.9213 - val_accuracy: 0.1817\n",
      "Epoch 117/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 4.8900 - accuracy: 0.2900 - val_loss: 5.9210 - val_accuracy: 0.1824\n",
      "Epoch 118/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.8772 - accuracy: 0.2924 - val_loss: 5.9184 - val_accuracy: 0.1823\n",
      "Epoch 119/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.8651 - accuracy: 0.2938 - val_loss: 5.9164 - val_accuracy: 0.1829\n",
      "Epoch 120/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 4.8525 - accuracy: 0.2958 - val_loss: 5.9171 - val_accuracy: 0.1833\n",
      "Epoch 121/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 4.8405 - accuracy: 0.2970 - val_loss: 5.9136 - val_accuracy: 0.1827\n",
      "Epoch 122/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.8269 - accuracy: 0.2995 - val_loss: 5.9124 - val_accuracy: 0.1826\n",
      "Epoch 123/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 4.8152 - accuracy: 0.3009 - val_loss: 5.9116 - val_accuracy: 0.1839\n",
      "Epoch 124/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.8029 - accuracy: 0.3028 - val_loss: 5.9080 - val_accuracy: 0.1841\n",
      "Epoch 125/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.7918 - accuracy: 0.3045 - val_loss: 5.9071 - val_accuracy: 0.1841\n",
      "Epoch 126/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.7789 - accuracy: 0.3067 - val_loss: 5.9062 - val_accuracy: 0.1845\n",
      "Epoch 127/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.7667 - accuracy: 0.3081 - val_loss: 5.9047 - val_accuracy: 0.1846\n",
      "Epoch 128/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.7541 - accuracy: 0.3104 - val_loss: 5.9080 - val_accuracy: 0.1849\n",
      "Epoch 129/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.7423 - accuracy: 0.3120 - val_loss: 5.9018 - val_accuracy: 0.1845\n",
      "Epoch 130/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.7316 - accuracy: 0.3130 - val_loss: 5.9005 - val_accuracy: 0.1855\n",
      "Epoch 131/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.7185 - accuracy: 0.3155 - val_loss: 5.9044 - val_accuracy: 0.1851\n",
      "Epoch 132/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.7076 - accuracy: 0.3170 - val_loss: 5.9025 - val_accuracy: 0.1856\n",
      "Epoch 133/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.6957 - accuracy: 0.3189 - val_loss: 5.9008 - val_accuracy: 0.1859\n",
      "Epoch 134/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.6838 - accuracy: 0.3203 - val_loss: 5.9004 - val_accuracy: 0.1852\n",
      "Epoch 135/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 4.6723 - accuracy: 0.3219 - val_loss: 5.9024 - val_accuracy: 0.1855\n",
      "Epoch 136/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 4.6616 - accuracy: 0.3238 - val_loss: 5.9022 - val_accuracy: 0.1845\n",
      "Epoch 137/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.6504 - accuracy: 0.3255 - val_loss: 5.8999 - val_accuracy: 0.1858\n",
      "Epoch 138/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.6393 - accuracy: 0.3271 - val_loss: 5.9008 - val_accuracy: 0.1859\n",
      "Epoch 139/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.6280 - accuracy: 0.3293 - val_loss: 5.8973 - val_accuracy: 0.1858\n",
      "Epoch 140/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 4.6184 - accuracy: 0.3300 - val_loss: 5.8976 - val_accuracy: 0.1839\n",
      "Epoch 141/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.6068 - accuracy: 0.3315 - val_loss: 5.8994 - val_accuracy: 0.1870\n",
      "Epoch 142/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 4.5966 - accuracy: 0.3327 - val_loss: 5.8964 - val_accuracy: 0.1873\n",
      "Epoch 143/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.5849 - accuracy: 0.3345 - val_loss: 5.8962 - val_accuracy: 0.1857\n",
      "Epoch 144/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.5743 - accuracy: 0.3368 - val_loss: 5.8975 - val_accuracy: 0.1867\n",
      "Epoch 145/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.5643 - accuracy: 0.3385 - val_loss: 5.8956 - val_accuracy: 0.1851\n",
      "Epoch 146/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.5535 - accuracy: 0.3399 - val_loss: 5.8929 - val_accuracy: 0.1855\n",
      "Epoch 147/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.5427 - accuracy: 0.3418 - val_loss: 5.8952 - val_accuracy: 0.1871\n",
      "Epoch 148/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 4.5318 - accuracy: 0.3435 - val_loss: 5.8965 - val_accuracy: 0.1857\n",
      "Epoch 149/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 4.5221 - accuracy: 0.3449 - val_loss: 5.9002 - val_accuracy: 0.1865\n",
      "Epoch 150/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 4.5115 - accuracy: 0.3461 - val_loss: 5.8974 - val_accuracy: 0.1862\n",
      "Epoch 151/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.5018 - accuracy: 0.3481 - val_loss: 5.8976 - val_accuracy: 0.1868\n",
      "Epoch 152/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.4918 - accuracy: 0.3492 - val_loss: 5.8969 - val_accuracy: 0.1862\n",
      "Epoch 153/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 4.4808 - accuracy: 0.3518 - val_loss: 5.8962 - val_accuracy: 0.1867\n",
      "Epoch 154/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.4719 - accuracy: 0.3523 - val_loss: 5.8972 - val_accuracy: 0.1860\n",
      "Epoch 155/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.4620 - accuracy: 0.3544 - val_loss: 5.8951 - val_accuracy: 0.1867\n",
      "Epoch 156/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.4523 - accuracy: 0.3553 - val_loss: 5.9000 - val_accuracy: 0.1866\n",
      "Epoch 157/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.4421 - accuracy: 0.3579 - val_loss: 5.8981 - val_accuracy: 0.1870\n",
      "Epoch 158/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 4.4319 - accuracy: 0.3590 - val_loss: 5.9005 - val_accuracy: 0.1871\n",
      "Epoch 159/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.4216 - accuracy: 0.3606 - val_loss: 5.9006 - val_accuracy: 0.1864\n",
      "Epoch 160/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 4.4124 - accuracy: 0.3624 - val_loss: 5.9009 - val_accuracy: 0.1872\n",
      "Epoch 161/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.4033 - accuracy: 0.3640 - val_loss: 5.8953 - val_accuracy: 0.1883\n",
      "Epoch 162/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.3949 - accuracy: 0.3649 - val_loss: 5.9034 - val_accuracy: 0.1876\n",
      "Epoch 163/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.3850 - accuracy: 0.3670 - val_loss: 5.8994 - val_accuracy: 0.1875\n",
      "Epoch 164/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.3757 - accuracy: 0.3675 - val_loss: 5.9015 - val_accuracy: 0.1874\n",
      "Epoch 165/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 4.3662 - accuracy: 0.3697 - val_loss: 5.9075 - val_accuracy: 0.1858\n",
      "Epoch 166/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.3568 - accuracy: 0.3710 - val_loss: 5.9063 - val_accuracy: 0.1869\n",
      "Epoch 167/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.3478 - accuracy: 0.3725 - val_loss: 5.9075 - val_accuracy: 0.1866\n",
      "Epoch 168/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.3386 - accuracy: 0.3741 - val_loss: 5.9100 - val_accuracy: 0.1867\n",
      "Epoch 169/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 534ms/step - loss: 4.3289 - accuracy: 0.3753 - val_loss: 5.9086 - val_accuracy: 0.1868\n",
      "Epoch 170/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.3203 - accuracy: 0.3771 - val_loss: 5.9099 - val_accuracy: 0.1869\n",
      "Epoch 171/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.3108 - accuracy: 0.3793 - val_loss: 5.9074 - val_accuracy: 0.1877\n",
      "Epoch 172/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.3021 - accuracy: 0.3800 - val_loss: 5.9123 - val_accuracy: 0.1865\n",
      "Epoch 173/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.2934 - accuracy: 0.3817 - val_loss: 5.9091 - val_accuracy: 0.1866\n",
      "Epoch 174/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 4.2850 - accuracy: 0.3826 - val_loss: 5.9097 - val_accuracy: 0.1865\n",
      "Epoch 175/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.2773 - accuracy: 0.3837 - val_loss: 5.9113 - val_accuracy: 0.1868\n",
      "Epoch 176/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 4.2676 - accuracy: 0.3855 - val_loss: 5.9119 - val_accuracy: 0.1864\n",
      "Epoch 177/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 4.2595 - accuracy: 0.3861 - val_loss: 5.9137 - val_accuracy: 0.1870\n",
      "Epoch 178/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 4.2502 - accuracy: 0.3884 - val_loss: 5.9211 - val_accuracy: 0.1857\n",
      "Epoch 179/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.2430 - accuracy: 0.3888 - val_loss: 5.9128 - val_accuracy: 0.1874\n",
      "Epoch 180/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.2337 - accuracy: 0.3907 - val_loss: 5.9128 - val_accuracy: 0.1881\n",
      "Epoch 181/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.2251 - accuracy: 0.3926 - val_loss: 5.9154 - val_accuracy: 0.1879\n",
      "Epoch 182/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.2181 - accuracy: 0.3933 - val_loss: 5.9180 - val_accuracy: 0.1871\n",
      "Epoch 183/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 4.2083 - accuracy: 0.3951 - val_loss: 5.9219 - val_accuracy: 0.1871\n",
      "Epoch 184/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.2007 - accuracy: 0.3962 - val_loss: 5.9210 - val_accuracy: 0.1873\n",
      "Epoch 185/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 4.1929 - accuracy: 0.3976 - val_loss: 5.9222 - val_accuracy: 0.1870\n",
      "Epoch 186/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 4.1842 - accuracy: 0.3994 - val_loss: 5.9184 - val_accuracy: 0.1876\n",
      "Epoch 187/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.1754 - accuracy: 0.4006 - val_loss: 5.9258 - val_accuracy: 0.1872\n",
      "Epoch 188/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 4.1676 - accuracy: 0.4020 - val_loss: 5.9231 - val_accuracy: 0.1871\n",
      "Epoch 189/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 4.1599 - accuracy: 0.4035 - val_loss: 5.9260 - val_accuracy: 0.1861\n",
      "Epoch 190/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 4.1512 - accuracy: 0.4045 - val_loss: 5.9233 - val_accuracy: 0.1874\n",
      "Epoch 191/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.1435 - accuracy: 0.4064 - val_loss: 5.9254 - val_accuracy: 0.1872\n",
      "Epoch 192/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.1361 - accuracy: 0.4073 - val_loss: 5.9288 - val_accuracy: 0.1867\n",
      "Epoch 193/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 4.1281 - accuracy: 0.4085 - val_loss: 5.9297 - val_accuracy: 0.1866\n",
      "Epoch 194/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.1202 - accuracy: 0.4102 - val_loss: 5.9309 - val_accuracy: 0.1858\n",
      "Epoch 195/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.1122 - accuracy: 0.4112 - val_loss: 5.9305 - val_accuracy: 0.1868\n",
      "Epoch 196/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 4.1054 - accuracy: 0.4122 - val_loss: 5.9335 - val_accuracy: 0.1868\n",
      "Epoch 197/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.0984 - accuracy: 0.4131 - val_loss: 5.9372 - val_accuracy: 0.1854\n",
      "Epoch 198/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 4.0905 - accuracy: 0.4149 - val_loss: 5.9355 - val_accuracy: 0.1847\n",
      "Epoch 199/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.0825 - accuracy: 0.4158 - val_loss: 5.9362 - val_accuracy: 0.1863\n",
      "Epoch 200/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.0743 - accuracy: 0.4172 - val_loss: 5.9430 - val_accuracy: 0.1855\n",
      "Epoch 201/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.0670 - accuracy: 0.4184 - val_loss: 5.9407 - val_accuracy: 0.1857\n",
      "Epoch 202/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.0603 - accuracy: 0.4199 - val_loss: 5.9453 - val_accuracy: 0.1857\n",
      "Epoch 203/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.0529 - accuracy: 0.4209 - val_loss: 5.9421 - val_accuracy: 0.1874\n",
      "Epoch 204/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.0454 - accuracy: 0.4222 - val_loss: 5.9463 - val_accuracy: 0.1870\n",
      "Epoch 205/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 4.0384 - accuracy: 0.4224 - val_loss: 5.9437 - val_accuracy: 0.1867\n",
      "Epoch 206/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 4.0314 - accuracy: 0.4246 - val_loss: 5.9479 - val_accuracy: 0.1861\n",
      "Epoch 207/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.0229 - accuracy: 0.4257 - val_loss: 5.9486 - val_accuracy: 0.1857\n",
      "Epoch 208/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 4.0153 - accuracy: 0.4269 - val_loss: 5.9473 - val_accuracy: 0.1862\n",
      "Epoch 209/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 4.0082 - accuracy: 0.4282 - val_loss: 5.9499 - val_accuracy: 0.1860\n",
      "Epoch 210/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 4.0001 - accuracy: 0.4291 - val_loss: 5.9515 - val_accuracy: 0.1862\n",
      "Epoch 211/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.9931 - accuracy: 0.4304 - val_loss: 5.9494 - val_accuracy: 0.1870\n",
      "Epoch 212/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.9868 - accuracy: 0.4318 - val_loss: 5.9478 - val_accuracy: 0.1875\n",
      "Epoch 213/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.9784 - accuracy: 0.4330 - val_loss: 5.9484 - val_accuracy: 0.1880\n",
      "Epoch 214/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.9721 - accuracy: 0.4339 - val_loss: 5.9497 - val_accuracy: 0.1882\n",
      "Epoch 215/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.9658 - accuracy: 0.4344 - val_loss: 5.9549 - val_accuracy: 0.1882\n",
      "Epoch 216/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 3.9593 - accuracy: 0.4357 - val_loss: 5.9631 - val_accuracy: 0.1859\n",
      "Epoch 217/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.9527 - accuracy: 0.4368 - val_loss: 5.9589 - val_accuracy: 0.1886\n",
      "Epoch 218/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.9468 - accuracy: 0.4375 - val_loss: 5.9581 - val_accuracy: 0.1886\n",
      "Epoch 219/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.9385 - accuracy: 0.4394 - val_loss: 5.9598 - val_accuracy: 0.1889\n",
      "Epoch 220/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.9311 - accuracy: 0.4400 - val_loss: 5.9584 - val_accuracy: 0.1883\n",
      "Epoch 221/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.9243 - accuracy: 0.4416 - val_loss: 5.9623 - val_accuracy: 0.1886\n",
      "Epoch 222/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.9170 - accuracy: 0.4424 - val_loss: 5.9627 - val_accuracy: 0.1886\n",
      "Epoch 223/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.9106 - accuracy: 0.4440 - val_loss: 5.9670 - val_accuracy: 0.1874\n",
      "Epoch 224/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.9043 - accuracy: 0.4445 - val_loss: 5.9615 - val_accuracy: 0.1887\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 533ms/step - loss: 3.8970 - accuracy: 0.4467 - val_loss: 5.9638 - val_accuracy: 0.1879\n",
      "Epoch 226/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.8896 - accuracy: 0.4469 - val_loss: 5.9640 - val_accuracy: 0.1885\n",
      "Epoch 227/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.8829 - accuracy: 0.4488 - val_loss: 5.9675 - val_accuracy: 0.1878\n",
      "Epoch 228/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.8777 - accuracy: 0.4489 - val_loss: 5.9684 - val_accuracy: 0.1881\n",
      "Epoch 229/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.8699 - accuracy: 0.4504 - val_loss: 5.9750 - val_accuracy: 0.1886\n",
      "Epoch 230/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.8638 - accuracy: 0.4515 - val_loss: 5.9731 - val_accuracy: 0.1872\n",
      "Epoch 231/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.8577 - accuracy: 0.4523 - val_loss: 5.9715 - val_accuracy: 0.1886\n",
      "Epoch 232/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.8512 - accuracy: 0.4540 - val_loss: 5.9711 - val_accuracy: 0.1891\n",
      "Epoch 233/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.8628 - accuracy: 0.4505 - val_loss: 5.9610 - val_accuracy: 0.1898\n",
      "Epoch 234/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.8444 - accuracy: 0.4543 - val_loss: 5.9718 - val_accuracy: 0.1892\n",
      "Epoch 235/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.8338 - accuracy: 0.4566 - val_loss: 5.9705 - val_accuracy: 0.1878\n",
      "Epoch 236/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.8270 - accuracy: 0.4573 - val_loss: 5.9723 - val_accuracy: 0.1890\n",
      "Epoch 237/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.8198 - accuracy: 0.4588 - val_loss: 5.9744 - val_accuracy: 0.1905\n",
      "Epoch 238/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.8129 - accuracy: 0.4600 - val_loss: 5.9759 - val_accuracy: 0.1899\n",
      "Epoch 239/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.8062 - accuracy: 0.4616 - val_loss: 5.9759 - val_accuracy: 0.1892\n",
      "Epoch 240/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.7998 - accuracy: 0.4628 - val_loss: 5.9781 - val_accuracy: 0.1900\n",
      "Epoch 241/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.7934 - accuracy: 0.4634 - val_loss: 5.9826 - val_accuracy: 0.1877\n",
      "Epoch 242/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.7877 - accuracy: 0.4649 - val_loss: 5.9848 - val_accuracy: 0.1879\n",
      "Epoch 243/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.7813 - accuracy: 0.4656 - val_loss: 5.9869 - val_accuracy: 0.1885\n",
      "Epoch 244/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.7746 - accuracy: 0.4667 - val_loss: 5.9841 - val_accuracy: 0.1887\n",
      "Epoch 245/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.7686 - accuracy: 0.4673 - val_loss: 5.9841 - val_accuracy: 0.1892\n",
      "Epoch 246/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.7632 - accuracy: 0.4685 - val_loss: 5.9872 - val_accuracy: 0.1885\n",
      "Epoch 247/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.7569 - accuracy: 0.4700 - val_loss: 5.9889 - val_accuracy: 0.1878\n",
      "Epoch 248/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.7512 - accuracy: 0.4708 - val_loss: 5.9906 - val_accuracy: 0.1877\n",
      "Epoch 249/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.7452 - accuracy: 0.4720 - val_loss: 5.9929 - val_accuracy: 0.1882\n",
      "Epoch 250/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.7387 - accuracy: 0.4731 - val_loss: 5.9966 - val_accuracy: 0.1880\n",
      "Epoch 251/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.7320 - accuracy: 0.4747 - val_loss: 5.9929 - val_accuracy: 0.1874\n",
      "Epoch 252/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.7269 - accuracy: 0.4755 - val_loss: 5.9977 - val_accuracy: 0.1865\n",
      "Epoch 253/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.7203 - accuracy: 0.4773 - val_loss: 5.9982 - val_accuracy: 0.1868\n",
      "Epoch 254/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.7142 - accuracy: 0.4778 - val_loss: 6.0003 - val_accuracy: 0.1872\n",
      "Epoch 255/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.7088 - accuracy: 0.4792 - val_loss: 5.9977 - val_accuracy: 0.1880\n",
      "Epoch 256/1000\n",
      "17/17 [==============================] - 9s 525ms/step - loss: 3.7017 - accuracy: 0.4802 - val_loss: 6.0040 - val_accuracy: 0.1877\n",
      "Epoch 257/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.6955 - accuracy: 0.4816 - val_loss: 6.0050 - val_accuracy: 0.1865\n",
      "Epoch 258/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.6901 - accuracy: 0.4821 - val_loss: 6.0037 - val_accuracy: 0.1862\n",
      "Epoch 259/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.6860 - accuracy: 0.4830 - val_loss: 6.0074 - val_accuracy: 0.1858\n",
      "Epoch 260/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.6809 - accuracy: 0.4838 - val_loss: 6.0100 - val_accuracy: 0.1848\n",
      "Epoch 261/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.6761 - accuracy: 0.4837 - val_loss: 6.0115 - val_accuracy: 0.1872\n",
      "Epoch 262/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.6691 - accuracy: 0.4857 - val_loss: 6.0141 - val_accuracy: 0.1875\n",
      "Epoch 263/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.6620 - accuracy: 0.4864 - val_loss: 6.0120 - val_accuracy: 0.1868\n",
      "Epoch 264/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.6574 - accuracy: 0.4876 - val_loss: 6.0125 - val_accuracy: 0.1867\n",
      "Epoch 265/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.6506 - accuracy: 0.4894 - val_loss: 6.0202 - val_accuracy: 0.1853\n",
      "Epoch 266/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.6445 - accuracy: 0.4903 - val_loss: 6.0192 - val_accuracy: 0.1861\n",
      "Epoch 267/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.6384 - accuracy: 0.4910 - val_loss: 6.0164 - val_accuracy: 0.1856\n",
      "Epoch 268/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.6338 - accuracy: 0.4917 - val_loss: 6.0200 - val_accuracy: 0.1847\n",
      "Epoch 269/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 3.6281 - accuracy: 0.4928 - val_loss: 6.0272 - val_accuracy: 0.1851\n",
      "Epoch 270/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.6234 - accuracy: 0.4940 - val_loss: 6.0187 - val_accuracy: 0.1868\n",
      "Epoch 271/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.6187 - accuracy: 0.4944 - val_loss: 6.0284 - val_accuracy: 0.1855\n",
      "Epoch 272/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.6121 - accuracy: 0.4955 - val_loss: 6.0257 - val_accuracy: 0.1848\n",
      "Epoch 273/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.6062 - accuracy: 0.4966 - val_loss: 6.0282 - val_accuracy: 0.1856\n",
      "Epoch 274/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.6004 - accuracy: 0.4979 - val_loss: 6.0284 - val_accuracy: 0.1850\n",
      "Epoch 275/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.5959 - accuracy: 0.4984 - val_loss: 6.0337 - val_accuracy: 0.1846\n",
      "Epoch 276/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.5896 - accuracy: 0.4999 - val_loss: 6.0341 - val_accuracy: 0.1846\n",
      "Epoch 277/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 3.5843 - accuracy: 0.5011 - val_loss: 6.0380 - val_accuracy: 0.1835\n",
      "Epoch 278/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.5804 - accuracy: 0.5009 - val_loss: 6.0382 - val_accuracy: 0.1844\n",
      "Epoch 279/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.5741 - accuracy: 0.5022 - val_loss: 6.0383 - val_accuracy: 0.1846\n",
      "Epoch 280/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.5687 - accuracy: 0.5026 - val_loss: 6.0422 - val_accuracy: 0.1844\n",
      "Epoch 281/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 529ms/step - loss: 3.5628 - accuracy: 0.5046 - val_loss: 6.0437 - val_accuracy: 0.1833\n",
      "Epoch 282/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.5574 - accuracy: 0.5048 - val_loss: 6.0437 - val_accuracy: 0.1848\n",
      "Epoch 283/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.5518 - accuracy: 0.5063 - val_loss: 6.0473 - val_accuracy: 0.1842\n",
      "Epoch 284/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.5466 - accuracy: 0.5073 - val_loss: 6.0463 - val_accuracy: 0.1839\n",
      "Epoch 285/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.5409 - accuracy: 0.5083 - val_loss: 6.0501 - val_accuracy: 0.1840\n",
      "Epoch 286/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.5356 - accuracy: 0.5093 - val_loss: 6.0499 - val_accuracy: 0.1851\n",
      "Epoch 287/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.5297 - accuracy: 0.5107 - val_loss: 6.0508 - val_accuracy: 0.1834\n",
      "Epoch 288/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.5241 - accuracy: 0.5114 - val_loss: 6.0584 - val_accuracy: 0.1835\n",
      "Epoch 289/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.5199 - accuracy: 0.5128 - val_loss: 6.0550 - val_accuracy: 0.1839\n",
      "Epoch 290/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.5144 - accuracy: 0.5131 - val_loss: 6.0513 - val_accuracy: 0.1846\n",
      "Epoch 291/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.5115 - accuracy: 0.5132 - val_loss: 6.0556 - val_accuracy: 0.1828\n",
      "Epoch 292/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.5128 - accuracy: 0.5127 - val_loss: 6.0524 - val_accuracy: 0.1837\n",
      "Epoch 293/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 3.5034 - accuracy: 0.5145 - val_loss: 6.0627 - val_accuracy: 0.1828\n",
      "Epoch 294/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.4963 - accuracy: 0.5161 - val_loss: 6.0552 - val_accuracy: 0.1837\n",
      "Epoch 295/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.4970 - accuracy: 0.5152 - val_loss: 6.0670 - val_accuracy: 0.1826\n",
      "Epoch 296/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 3.4858 - accuracy: 0.5177 - val_loss: 6.0650 - val_accuracy: 0.1835\n",
      "Epoch 297/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.4795 - accuracy: 0.5197 - val_loss: 6.0705 - val_accuracy: 0.1827\n",
      "Epoch 298/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.4776 - accuracy: 0.5195 - val_loss: 6.0674 - val_accuracy: 0.1828\n",
      "Epoch 299/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.4696 - accuracy: 0.5216 - val_loss: 6.0704 - val_accuracy: 0.1824\n",
      "Epoch 300/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.4634 - accuracy: 0.5225 - val_loss: 6.0737 - val_accuracy: 0.1829\n",
      "Epoch 301/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.4580 - accuracy: 0.5234 - val_loss: 6.0687 - val_accuracy: 0.1826\n",
      "Epoch 302/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.4527 - accuracy: 0.5245 - val_loss: 6.0731 - val_accuracy: 0.1818\n",
      "Epoch 303/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.4483 - accuracy: 0.5250 - val_loss: 6.0754 - val_accuracy: 0.1819\n",
      "Epoch 304/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 3.4435 - accuracy: 0.5257 - val_loss: 6.0808 - val_accuracy: 0.1835\n",
      "Epoch 305/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.4377 - accuracy: 0.5274 - val_loss: 6.0853 - val_accuracy: 0.1819\n",
      "Epoch 306/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.4350 - accuracy: 0.5281 - val_loss: 6.0802 - val_accuracy: 0.1817\n",
      "Epoch 307/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.4296 - accuracy: 0.5287 - val_loss: 6.0846 - val_accuracy: 0.1823\n",
      "Epoch 308/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 3.4236 - accuracy: 0.5297 - val_loss: 6.0820 - val_accuracy: 0.1812\n",
      "Epoch 309/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.4178 - accuracy: 0.5312 - val_loss: 6.0843 - val_accuracy: 0.1817\n",
      "Epoch 310/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.4135 - accuracy: 0.5322 - val_loss: 6.0888 - val_accuracy: 0.1826\n",
      "Epoch 311/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.4090 - accuracy: 0.5322 - val_loss: 6.0919 - val_accuracy: 0.1817\n",
      "Epoch 312/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.4031 - accuracy: 0.5342 - val_loss: 6.0932 - val_accuracy: 0.1823\n",
      "Epoch 313/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.3998 - accuracy: 0.5347 - val_loss: 6.0908 - val_accuracy: 0.1823\n",
      "Epoch 314/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.3946 - accuracy: 0.5358 - val_loss: 6.0938 - val_accuracy: 0.1817\n",
      "Epoch 315/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.3884 - accuracy: 0.5368 - val_loss: 6.1006 - val_accuracy: 0.1819\n",
      "Epoch 316/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.3837 - accuracy: 0.5377 - val_loss: 6.0952 - val_accuracy: 0.1825\n",
      "Epoch 317/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.3803 - accuracy: 0.5377 - val_loss: 6.0977 - val_accuracy: 0.1810\n",
      "Epoch 318/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.3773 - accuracy: 0.5383 - val_loss: 6.1006 - val_accuracy: 0.1808\n",
      "Epoch 319/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.3706 - accuracy: 0.5402 - val_loss: 6.1003 - val_accuracy: 0.1819\n",
      "Epoch 320/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.3646 - accuracy: 0.5418 - val_loss: 6.0991 - val_accuracy: 0.1817\n",
      "Epoch 321/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.3606 - accuracy: 0.5421 - val_loss: 6.1038 - val_accuracy: 0.1823\n",
      "Epoch 322/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.3555 - accuracy: 0.5433 - val_loss: 6.1075 - val_accuracy: 0.1817\n",
      "Epoch 323/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.3502 - accuracy: 0.5445 - val_loss: 6.1068 - val_accuracy: 0.1821\n",
      "Epoch 324/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.3467 - accuracy: 0.5449 - val_loss: 6.1170 - val_accuracy: 0.1807\n",
      "Epoch 325/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 3.3423 - accuracy: 0.5458 - val_loss: 6.1204 - val_accuracy: 0.1800\n",
      "Epoch 326/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.3391 - accuracy: 0.5467 - val_loss: 6.1075 - val_accuracy: 0.1801\n",
      "Epoch 327/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.3351 - accuracy: 0.5473 - val_loss: 6.1155 - val_accuracy: 0.1816\n",
      "Epoch 328/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.3295 - accuracy: 0.5484 - val_loss: 6.1186 - val_accuracy: 0.1816\n",
      "Epoch 329/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.3243 - accuracy: 0.5497 - val_loss: 6.1211 - val_accuracy: 0.1814\n",
      "Epoch 330/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.3204 - accuracy: 0.5498 - val_loss: 6.1207 - val_accuracy: 0.1801\n",
      "Epoch 331/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.3153 - accuracy: 0.5513 - val_loss: 6.1220 - val_accuracy: 0.1804\n",
      "Epoch 332/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.3104 - accuracy: 0.5519 - val_loss: 6.1269 - val_accuracy: 0.1810\n",
      "Epoch 333/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.3061 - accuracy: 0.5535 - val_loss: 6.1231 - val_accuracy: 0.1810\n",
      "Epoch 334/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.3013 - accuracy: 0.5535 - val_loss: 6.1286 - val_accuracy: 0.1812\n",
      "Epoch 335/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.2963 - accuracy: 0.5545 - val_loss: 6.1305 - val_accuracy: 0.1801\n",
      "Epoch 336/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 3.2921 - accuracy: 0.5561 - val_loss: 6.1303 - val_accuracy: 0.1811\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 531ms/step - loss: 3.2870 - accuracy: 0.5570 - val_loss: 6.1307 - val_accuracy: 0.1809\n",
      "Epoch 338/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.2832 - accuracy: 0.5573 - val_loss: 6.1369 - val_accuracy: 0.1801\n",
      "Epoch 339/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.2778 - accuracy: 0.5586 - val_loss: 6.1382 - val_accuracy: 0.1808\n",
      "Epoch 340/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.2738 - accuracy: 0.5599 - val_loss: 6.1311 - val_accuracy: 0.1815\n",
      "Epoch 341/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.2696 - accuracy: 0.5604 - val_loss: 6.1304 - val_accuracy: 0.1800\n",
      "Epoch 342/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.2660 - accuracy: 0.5609 - val_loss: 6.1336 - val_accuracy: 0.1810\n",
      "Epoch 343/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.2613 - accuracy: 0.5614 - val_loss: 6.1346 - val_accuracy: 0.1805\n",
      "Epoch 344/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.2566 - accuracy: 0.5631 - val_loss: 6.1409 - val_accuracy: 0.1802\n",
      "Epoch 345/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.2513 - accuracy: 0.5639 - val_loss: 6.1491 - val_accuracy: 0.1804\n",
      "Epoch 346/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.2480 - accuracy: 0.5647 - val_loss: 6.1488 - val_accuracy: 0.1804\n",
      "Epoch 347/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.2449 - accuracy: 0.5650 - val_loss: 6.1453 - val_accuracy: 0.1799\n",
      "Epoch 348/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.2392 - accuracy: 0.5664 - val_loss: 6.1485 - val_accuracy: 0.1789\n",
      "Epoch 349/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.2335 - accuracy: 0.5674 - val_loss: 6.1553 - val_accuracy: 0.1800\n",
      "Epoch 350/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.2298 - accuracy: 0.5686 - val_loss: 6.1573 - val_accuracy: 0.1797\n",
      "Epoch 351/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.2317 - accuracy: 0.5674 - val_loss: 6.1498 - val_accuracy: 0.1797\n",
      "Epoch 352/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.2342 - accuracy: 0.5658 - val_loss: 6.1515 - val_accuracy: 0.1804\n",
      "Epoch 353/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.2231 - accuracy: 0.5689 - val_loss: 6.1478 - val_accuracy: 0.1810\n",
      "Epoch 354/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.2160 - accuracy: 0.5706 - val_loss: 6.1542 - val_accuracy: 0.1800\n",
      "Epoch 355/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.2109 - accuracy: 0.5715 - val_loss: 6.1574 - val_accuracy: 0.1786\n",
      "Epoch 356/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.2056 - accuracy: 0.5730 - val_loss: 6.1536 - val_accuracy: 0.1788\n",
      "Epoch 357/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.2010 - accuracy: 0.5739 - val_loss: 6.1590 - val_accuracy: 0.1788\n",
      "Epoch 358/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.1973 - accuracy: 0.5740 - val_loss: 6.1652 - val_accuracy: 0.1802\n",
      "Epoch 359/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.1932 - accuracy: 0.5754 - val_loss: 6.1602 - val_accuracy: 0.1801\n",
      "Epoch 360/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.1887 - accuracy: 0.5760 - val_loss: 6.1697 - val_accuracy: 0.1781\n",
      "Epoch 361/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.1844 - accuracy: 0.5768 - val_loss: 6.1688 - val_accuracy: 0.1797\n",
      "Epoch 362/1000\n",
      "17/17 [==============================] - 9s 536ms/step - loss: 3.1807 - accuracy: 0.5783 - val_loss: 6.1702 - val_accuracy: 0.1792\n",
      "Epoch 363/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.1791 - accuracy: 0.5776 - val_loss: 6.1669 - val_accuracy: 0.1792\n",
      "Epoch 364/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.1737 - accuracy: 0.5786 - val_loss: 6.1699 - val_accuracy: 0.1775\n",
      "Epoch 365/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.1691 - accuracy: 0.5800 - val_loss: 6.1730 - val_accuracy: 0.1779\n",
      "Epoch 366/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.1631 - accuracy: 0.5811 - val_loss: 6.1736 - val_accuracy: 0.1795\n",
      "Epoch 367/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.1589 - accuracy: 0.5817 - val_loss: 6.1750 - val_accuracy: 0.1790\n",
      "Epoch 368/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.1549 - accuracy: 0.5830 - val_loss: 6.1817 - val_accuracy: 0.1783\n",
      "Epoch 369/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.1509 - accuracy: 0.5831 - val_loss: 6.1739 - val_accuracy: 0.1795\n",
      "Epoch 370/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 3.1469 - accuracy: 0.5845 - val_loss: 6.1789 - val_accuracy: 0.1789\n",
      "Epoch 371/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.1426 - accuracy: 0.5852 - val_loss: 6.1823 - val_accuracy: 0.1790\n",
      "Epoch 372/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.1386 - accuracy: 0.5863 - val_loss: 6.1860 - val_accuracy: 0.1783\n",
      "Epoch 373/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.1354 - accuracy: 0.5865 - val_loss: 6.1856 - val_accuracy: 0.1783\n",
      "Epoch 374/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.1313 - accuracy: 0.5873 - val_loss: 6.1890 - val_accuracy: 0.1787\n",
      "Epoch 375/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.1271 - accuracy: 0.5879 - val_loss: 6.1885 - val_accuracy: 0.1785\n",
      "Epoch 376/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 3.1241 - accuracy: 0.5885 - val_loss: 6.1854 - val_accuracy: 0.1787\n",
      "Epoch 377/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.1209 - accuracy: 0.5892 - val_loss: 6.1948 - val_accuracy: 0.1790\n",
      "Epoch 378/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.1158 - accuracy: 0.5900 - val_loss: 6.2026 - val_accuracy: 0.1759\n",
      "Epoch 379/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.1109 - accuracy: 0.5913 - val_loss: 6.1978 - val_accuracy: 0.1780\n",
      "Epoch 380/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 3.1069 - accuracy: 0.5920 - val_loss: 6.2001 - val_accuracy: 0.1771\n",
      "Epoch 381/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.1034 - accuracy: 0.5922 - val_loss: 6.2035 - val_accuracy: 0.1771\n",
      "Epoch 382/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.1029 - accuracy: 0.5922 - val_loss: 6.1996 - val_accuracy: 0.1776\n",
      "Epoch 383/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.0971 - accuracy: 0.5937 - val_loss: 6.2018 - val_accuracy: 0.1780\n",
      "Epoch 384/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 3.0920 - accuracy: 0.5952 - val_loss: 6.2039 - val_accuracy: 0.1780\n",
      "Epoch 385/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.0881 - accuracy: 0.5956 - val_loss: 6.2064 - val_accuracy: 0.1776\n",
      "Epoch 386/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.0836 - accuracy: 0.5969 - val_loss: 6.2108 - val_accuracy: 0.1775\n",
      "Epoch 387/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.0803 - accuracy: 0.5975 - val_loss: 6.2028 - val_accuracy: 0.1783\n",
      "Epoch 388/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.0799 - accuracy: 0.5965 - val_loss: 6.2160 - val_accuracy: 0.1773\n",
      "Epoch 389/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.0790 - accuracy: 0.5960 - val_loss: 6.2081 - val_accuracy: 0.1775\n",
      "Epoch 390/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 3.0724 - accuracy: 0.5981 - val_loss: 6.2057 - val_accuracy: 0.1774\n",
      "Epoch 391/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.0668 - accuracy: 0.5993 - val_loss: 6.2011 - val_accuracy: 0.1780\n",
      "Epoch 392/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.0645 - accuracy: 0.5997 - val_loss: 6.2095 - val_accuracy: 0.1775\n",
      "Epoch 393/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 529ms/step - loss: 3.0588 - accuracy: 0.6010 - val_loss: 6.2114 - val_accuracy: 0.1781\n",
      "Epoch 394/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.0549 - accuracy: 0.6023 - val_loss: 6.2162 - val_accuracy: 0.1779\n",
      "Epoch 395/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.0497 - accuracy: 0.6033 - val_loss: 6.2127 - val_accuracy: 0.1780\n",
      "Epoch 396/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.0465 - accuracy: 0.6039 - val_loss: 6.2206 - val_accuracy: 0.1773\n",
      "Epoch 397/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.0438 - accuracy: 0.6045 - val_loss: 6.2251 - val_accuracy: 0.1766\n",
      "Epoch 398/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.0405 - accuracy: 0.6050 - val_loss: 6.2245 - val_accuracy: 0.1766\n",
      "Epoch 399/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 3.0367 - accuracy: 0.6058 - val_loss: 6.2199 - val_accuracy: 0.1767\n",
      "Epoch 400/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.0325 - accuracy: 0.6069 - val_loss: 6.2259 - val_accuracy: 0.1763\n",
      "Epoch 401/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 3.0288 - accuracy: 0.6072 - val_loss: 6.2279 - val_accuracy: 0.1773\n",
      "Epoch 402/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 3.0249 - accuracy: 0.6086 - val_loss: 6.2261 - val_accuracy: 0.1779\n",
      "Epoch 403/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.0205 - accuracy: 0.6094 - val_loss: 6.2299 - val_accuracy: 0.1758\n",
      "Epoch 404/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 3.0166 - accuracy: 0.6105 - val_loss: 6.2343 - val_accuracy: 0.1763\n",
      "Epoch 405/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 3.0134 - accuracy: 0.6111 - val_loss: 6.2340 - val_accuracy: 0.1769\n",
      "Epoch 406/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 3.0096 - accuracy: 0.6119 - val_loss: 6.2355 - val_accuracy: 0.1769\n",
      "Epoch 407/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.0060 - accuracy: 0.6124 - val_loss: 6.2343 - val_accuracy: 0.1763\n",
      "Epoch 408/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 3.0028 - accuracy: 0.6130 - val_loss: 6.2382 - val_accuracy: 0.1770\n",
      "Epoch 409/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 3.0007 - accuracy: 0.6132 - val_loss: 6.2388 - val_accuracy: 0.1763\n",
      "Epoch 410/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.9972 - accuracy: 0.6141 - val_loss: 6.2326 - val_accuracy: 0.1779\n",
      "Epoch 411/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.9940 - accuracy: 0.6145 - val_loss: 6.2379 - val_accuracy: 0.1756\n",
      "Epoch 412/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.9903 - accuracy: 0.6155 - val_loss: 6.2446 - val_accuracy: 0.1755\n",
      "Epoch 413/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.9856 - accuracy: 0.6162 - val_loss: 6.2455 - val_accuracy: 0.1761\n",
      "Epoch 414/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.9820 - accuracy: 0.6168 - val_loss: 6.2457 - val_accuracy: 0.1767\n",
      "Epoch 415/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.9785 - accuracy: 0.6180 - val_loss: 6.2427 - val_accuracy: 0.1757\n",
      "Epoch 416/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.9757 - accuracy: 0.6182 - val_loss: 6.2440 - val_accuracy: 0.1763\n",
      "Epoch 417/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.9727 - accuracy: 0.6187 - val_loss: 6.2467 - val_accuracy: 0.1761\n",
      "Epoch 418/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.9698 - accuracy: 0.6191 - val_loss: 6.2451 - val_accuracy: 0.1772\n",
      "Epoch 419/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.9657 - accuracy: 0.6198 - val_loss: 6.2548 - val_accuracy: 0.1752\n",
      "Epoch 420/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.9637 - accuracy: 0.6201 - val_loss: 6.2509 - val_accuracy: 0.1757\n",
      "Epoch 421/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.9598 - accuracy: 0.6216 - val_loss: 6.2562 - val_accuracy: 0.1764\n",
      "Epoch 422/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.9564 - accuracy: 0.6218 - val_loss: 6.2580 - val_accuracy: 0.1751\n",
      "Epoch 423/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.9526 - accuracy: 0.6228 - val_loss: 6.2576 - val_accuracy: 0.1761\n",
      "Epoch 424/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.9492 - accuracy: 0.6239 - val_loss: 6.2586 - val_accuracy: 0.1770\n",
      "Epoch 425/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.9470 - accuracy: 0.6242 - val_loss: 6.2549 - val_accuracy: 0.1767\n",
      "Epoch 426/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.9442 - accuracy: 0.6242 - val_loss: 6.2662 - val_accuracy: 0.1755\n",
      "Epoch 427/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.9396 - accuracy: 0.6254 - val_loss: 6.2617 - val_accuracy: 0.1751\n",
      "Epoch 428/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.9367 - accuracy: 0.6258 - val_loss: 6.2679 - val_accuracy: 0.1756\n",
      "Epoch 429/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.9341 - accuracy: 0.6264 - val_loss: 6.2639 - val_accuracy: 0.1763\n",
      "Epoch 430/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.9771 - accuracy: 0.6115 - val_loss: 6.2647 - val_accuracy: 0.1773\n",
      "Epoch 431/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.9584 - accuracy: 0.6180 - val_loss: 6.2542 - val_accuracy: 0.1767\n",
      "Epoch 432/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.9400 - accuracy: 0.6223 - val_loss: 6.2609 - val_accuracy: 0.1759\n",
      "Epoch 433/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.9294 - accuracy: 0.6259 - val_loss: 6.2657 - val_accuracy: 0.1766\n",
      "Epoch 434/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.9222 - accuracy: 0.6281 - val_loss: 6.2628 - val_accuracy: 0.1780\n",
      "Epoch 435/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.9189 - accuracy: 0.6286 - val_loss: 6.2658 - val_accuracy: 0.1763\n",
      "Epoch 436/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.9149 - accuracy: 0.6298 - val_loss: 6.2666 - val_accuracy: 0.1764\n",
      "Epoch 437/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.9106 - accuracy: 0.6308 - val_loss: 6.2690 - val_accuracy: 0.1760\n",
      "Epoch 438/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.9072 - accuracy: 0.6312 - val_loss: 6.2696 - val_accuracy: 0.1763\n",
      "Epoch 439/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.9038 - accuracy: 0.6325 - val_loss: 6.2723 - val_accuracy: 0.1756\n",
      "Epoch 440/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.9011 - accuracy: 0.6329 - val_loss: 6.2736 - val_accuracy: 0.1746\n",
      "Epoch 441/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.8973 - accuracy: 0.6336 - val_loss: 6.2748 - val_accuracy: 0.1751\n",
      "Epoch 442/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.8942 - accuracy: 0.6341 - val_loss: 6.2789 - val_accuracy: 0.1745\n",
      "Epoch 443/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.8908 - accuracy: 0.6357 - val_loss: 6.2799 - val_accuracy: 0.1753\n",
      "Epoch 444/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.8874 - accuracy: 0.6351 - val_loss: 6.2781 - val_accuracy: 0.1761\n",
      "Epoch 445/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.8856 - accuracy: 0.6362 - val_loss: 6.2819 - val_accuracy: 0.1753\n",
      "Epoch 446/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.8823 - accuracy: 0.6366 - val_loss: 6.2795 - val_accuracy: 0.1748\n",
      "Epoch 447/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.8786 - accuracy: 0.6379 - val_loss: 6.2835 - val_accuracy: 0.1744\n",
      "Epoch 448/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.8745 - accuracy: 0.6389 - val_loss: 6.2813 - val_accuracy: 0.1746\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 532ms/step - loss: 2.8733 - accuracy: 0.6386 - val_loss: 6.2838 - val_accuracy: 0.1750\n",
      "Epoch 450/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.8707 - accuracy: 0.6383 - val_loss: 6.2870 - val_accuracy: 0.1744\n",
      "Epoch 451/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.8670 - accuracy: 0.6399 - val_loss: 6.2893 - val_accuracy: 0.1744\n",
      "Epoch 452/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.8640 - accuracy: 0.6407 - val_loss: 6.2895 - val_accuracy: 0.1749\n",
      "Epoch 453/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.8597 - accuracy: 0.6418 - val_loss: 6.2911 - val_accuracy: 0.1753\n",
      "Epoch 454/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.8585 - accuracy: 0.6423 - val_loss: 6.2874 - val_accuracy: 0.1764\n",
      "Epoch 455/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.8559 - accuracy: 0.6424 - val_loss: 6.2937 - val_accuracy: 0.1753\n",
      "Epoch 456/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.8523 - accuracy: 0.6432 - val_loss: 6.2956 - val_accuracy: 0.1748\n",
      "Epoch 457/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.8501 - accuracy: 0.6432 - val_loss: 6.2943 - val_accuracy: 0.1749\n",
      "Epoch 458/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.8460 - accuracy: 0.6446 - val_loss: 6.2968 - val_accuracy: 0.1757\n",
      "Epoch 459/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.8438 - accuracy: 0.6449 - val_loss: 6.3005 - val_accuracy: 0.1739\n",
      "Epoch 460/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.8420 - accuracy: 0.6451 - val_loss: 6.2976 - val_accuracy: 0.1739\n",
      "Epoch 461/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.8379 - accuracy: 0.6461 - val_loss: 6.3024 - val_accuracy: 0.1742\n",
      "Epoch 462/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.8342 - accuracy: 0.6464 - val_loss: 6.3030 - val_accuracy: 0.1742\n",
      "Epoch 463/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.8311 - accuracy: 0.6475 - val_loss: 6.3038 - val_accuracy: 0.1732\n",
      "Epoch 464/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.8274 - accuracy: 0.6486 - val_loss: 6.3062 - val_accuracy: 0.1737\n",
      "Epoch 465/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.8248 - accuracy: 0.6490 - val_loss: 6.3063 - val_accuracy: 0.1744\n",
      "Epoch 466/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.8228 - accuracy: 0.6496 - val_loss: 6.3066 - val_accuracy: 0.1738\n",
      "Epoch 467/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.8221 - accuracy: 0.6492 - val_loss: 6.3114 - val_accuracy: 0.1728\n",
      "Epoch 468/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.8212 - accuracy: 0.6494 - val_loss: 6.3116 - val_accuracy: 0.1733\n",
      "Epoch 469/1000\n",
      "17/17 [==============================] - 9s 536ms/step - loss: 2.9076 - accuracy: 0.6218 - val_loss: 6.3085 - val_accuracy: 0.1726\n",
      "Epoch 470/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 2.8508 - accuracy: 0.6382 - val_loss: 6.3099 - val_accuracy: 0.1741\n",
      "Epoch 471/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.8281 - accuracy: 0.6456 - val_loss: 6.3038 - val_accuracy: 0.1737\n",
      "Epoch 472/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.8162 - accuracy: 0.6497 - val_loss: 6.3110 - val_accuracy: 0.1739\n",
      "Epoch 473/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.8105 - accuracy: 0.6505 - val_loss: 6.3070 - val_accuracy: 0.1735\n",
      "Epoch 474/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.8054 - accuracy: 0.6529 - val_loss: 6.3119 - val_accuracy: 0.1732\n",
      "Epoch 475/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.8011 - accuracy: 0.6538 - val_loss: 6.3122 - val_accuracy: 0.1729\n",
      "Epoch 476/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.7977 - accuracy: 0.6546 - val_loss: 6.3164 - val_accuracy: 0.1725\n",
      "Epoch 477/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.7947 - accuracy: 0.6551 - val_loss: 6.3161 - val_accuracy: 0.1732\n",
      "Epoch 478/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7924 - accuracy: 0.6553 - val_loss: 6.3191 - val_accuracy: 0.1725\n",
      "Epoch 479/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7897 - accuracy: 0.6561 - val_loss: 6.3204 - val_accuracy: 0.1726\n",
      "Epoch 480/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.7871 - accuracy: 0.6561 - val_loss: 6.3233 - val_accuracy: 0.1722\n",
      "Epoch 481/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.7853 - accuracy: 0.6571 - val_loss: 6.3271 - val_accuracy: 0.1731\n",
      "Epoch 482/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.7828 - accuracy: 0.6575 - val_loss: 6.3226 - val_accuracy: 0.1726\n",
      "Epoch 483/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.7801 - accuracy: 0.6578 - val_loss: 6.3293 - val_accuracy: 0.1722\n",
      "Epoch 484/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7762 - accuracy: 0.6591 - val_loss: 6.3297 - val_accuracy: 0.1723\n",
      "Epoch 485/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.7730 - accuracy: 0.6598 - val_loss: 6.3295 - val_accuracy: 0.1721\n",
      "Epoch 486/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.7700 - accuracy: 0.6601 - val_loss: 6.3312 - val_accuracy: 0.1732\n",
      "Epoch 487/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.7668 - accuracy: 0.6614 - val_loss: 6.3366 - val_accuracy: 0.1725\n",
      "Epoch 488/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.7648 - accuracy: 0.6617 - val_loss: 6.3363 - val_accuracy: 0.1719\n",
      "Epoch 489/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.7625 - accuracy: 0.6624 - val_loss: 6.3391 - val_accuracy: 0.1728\n",
      "Epoch 490/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7608 - accuracy: 0.6627 - val_loss: 6.3367 - val_accuracy: 0.1731\n",
      "Epoch 491/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.7585 - accuracy: 0.6630 - val_loss: 6.3384 - val_accuracy: 0.1725\n",
      "Epoch 492/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7566 - accuracy: 0.6629 - val_loss: 6.3355 - val_accuracy: 0.1728\n",
      "Epoch 493/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.7539 - accuracy: 0.6641 - val_loss: 6.3395 - val_accuracy: 0.1713\n",
      "Epoch 494/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.7520 - accuracy: 0.6640 - val_loss: 6.3387 - val_accuracy: 0.1736\n",
      "Epoch 495/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.7501 - accuracy: 0.6645 - val_loss: 6.3439 - val_accuracy: 0.1717\n",
      "Epoch 496/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7452 - accuracy: 0.6657 - val_loss: 6.3461 - val_accuracy: 0.1735\n",
      "Epoch 497/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.7429 - accuracy: 0.6659 - val_loss: 6.3456 - val_accuracy: 0.1721\n",
      "Epoch 498/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7405 - accuracy: 0.6668 - val_loss: 6.3501 - val_accuracy: 0.1722\n",
      "Epoch 499/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7370 - accuracy: 0.6677 - val_loss: 6.3532 - val_accuracy: 0.1715\n",
      "Epoch 500/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.7336 - accuracy: 0.6684 - val_loss: 6.3532 - val_accuracy: 0.1705\n",
      "Epoch 501/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.7303 - accuracy: 0.6686 - val_loss: 6.3518 - val_accuracy: 0.1720\n",
      "Epoch 502/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7287 - accuracy: 0.6690 - val_loss: 6.3531 - val_accuracy: 0.1710\n",
      "Epoch 503/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7264 - accuracy: 0.6696 - val_loss: 6.3565 - val_accuracy: 0.1714\n",
      "Epoch 504/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.7246 - accuracy: 0.6693 - val_loss: 6.3592 - val_accuracy: 0.1711\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 533ms/step - loss: 2.7209 - accuracy: 0.6709 - val_loss: 6.3639 - val_accuracy: 0.1716\n",
      "Epoch 506/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.7183 - accuracy: 0.6715 - val_loss: 6.3599 - val_accuracy: 0.1716\n",
      "Epoch 507/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.7163 - accuracy: 0.6723 - val_loss: 6.3590 - val_accuracy: 0.1710\n",
      "Epoch 508/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7144 - accuracy: 0.6724 - val_loss: 6.3608 - val_accuracy: 0.1715\n",
      "Epoch 509/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.7114 - accuracy: 0.6733 - val_loss: 6.3675 - val_accuracy: 0.1707\n",
      "Epoch 510/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.7088 - accuracy: 0.6741 - val_loss: 6.3688 - val_accuracy: 0.1702\n",
      "Epoch 511/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.7069 - accuracy: 0.6740 - val_loss: 6.3671 - val_accuracy: 0.1709\n",
      "Epoch 512/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.7043 - accuracy: 0.6745 - val_loss: 6.3694 - val_accuracy: 0.1715\n",
      "Epoch 513/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.7020 - accuracy: 0.6753 - val_loss: 6.3669 - val_accuracy: 0.1707\n",
      "Epoch 514/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.6995 - accuracy: 0.6758 - val_loss: 6.3703 - val_accuracy: 0.1702\n",
      "Epoch 515/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.6977 - accuracy: 0.6759 - val_loss: 6.3739 - val_accuracy: 0.1715\n",
      "Epoch 516/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.6959 - accuracy: 0.6757 - val_loss: 6.3789 - val_accuracy: 0.1709\n",
      "Epoch 517/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.6929 - accuracy: 0.6766 - val_loss: 6.3761 - val_accuracy: 0.1707\n",
      "Epoch 518/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.6894 - accuracy: 0.6778 - val_loss: 6.3807 - val_accuracy: 0.1705\n",
      "Epoch 519/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6870 - accuracy: 0.6784 - val_loss: 6.3739 - val_accuracy: 0.1715\n",
      "Epoch 520/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.6848 - accuracy: 0.6787 - val_loss: 6.3809 - val_accuracy: 0.1703\n",
      "Epoch 521/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6818 - accuracy: 0.6794 - val_loss: 6.3796 - val_accuracy: 0.1714\n",
      "Epoch 522/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.6783 - accuracy: 0.6806 - val_loss: 6.3846 - val_accuracy: 0.1712\n",
      "Epoch 523/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6768 - accuracy: 0.6811 - val_loss: 6.3876 - val_accuracy: 0.1704\n",
      "Epoch 524/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.6757 - accuracy: 0.6808 - val_loss: 6.3803 - val_accuracy: 0.1719\n",
      "Epoch 525/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.6749 - accuracy: 0.6807 - val_loss: 6.3866 - val_accuracy: 0.1705\n",
      "Epoch 526/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.6732 - accuracy: 0.6806 - val_loss: 6.3880 - val_accuracy: 0.1719\n",
      "Epoch 527/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6701 - accuracy: 0.6818 - val_loss: 6.3911 - val_accuracy: 0.1715\n",
      "Epoch 528/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.6668 - accuracy: 0.6826 - val_loss: 6.3920 - val_accuracy: 0.1709\n",
      "Epoch 529/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6642 - accuracy: 0.6829 - val_loss: 6.3873 - val_accuracy: 0.1720\n",
      "Epoch 530/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 2.6623 - accuracy: 0.6833 - val_loss: 6.3960 - val_accuracy: 0.1715\n",
      "Epoch 531/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.6591 - accuracy: 0.6841 - val_loss: 6.3926 - val_accuracy: 0.1713\n",
      "Epoch 532/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.6573 - accuracy: 0.6844 - val_loss: 6.3977 - val_accuracy: 0.1719\n",
      "Epoch 533/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.6572 - accuracy: 0.6842 - val_loss: 6.3965 - val_accuracy: 0.1719\n",
      "Epoch 534/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.6564 - accuracy: 0.6840 - val_loss: 6.3992 - val_accuracy: 0.1722\n",
      "Epoch 535/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.6538 - accuracy: 0.6847 - val_loss: 6.4014 - val_accuracy: 0.1722\n",
      "Epoch 536/1000\n",
      "17/17 [==============================] - 9s 536ms/step - loss: 2.6491 - accuracy: 0.6864 - val_loss: 6.4031 - val_accuracy: 0.1721\n",
      "Epoch 537/1000\n",
      "17/17 [==============================] - 9s 536ms/step - loss: 2.6463 - accuracy: 0.6870 - val_loss: 6.4007 - val_accuracy: 0.1709\n",
      "Epoch 538/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6452 - accuracy: 0.6873 - val_loss: 6.4048 - val_accuracy: 0.1719\n",
      "Epoch 539/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.6420 - accuracy: 0.6880 - val_loss: 6.4070 - val_accuracy: 0.1712\n",
      "Epoch 540/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6395 - accuracy: 0.6887 - val_loss: 6.4049 - val_accuracy: 0.1716\n",
      "Epoch 541/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6381 - accuracy: 0.6887 - val_loss: 6.4103 - val_accuracy: 0.1718\n",
      "Epoch 542/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.6344 - accuracy: 0.6898 - val_loss: 6.4146 - val_accuracy: 0.1705\n",
      "Epoch 543/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.6312 - accuracy: 0.6906 - val_loss: 6.4176 - val_accuracy: 0.1716\n",
      "Epoch 544/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.6293 - accuracy: 0.6915 - val_loss: 6.4201 - val_accuracy: 0.1720\n",
      "Epoch 545/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6279 - accuracy: 0.6913 - val_loss: 6.4169 - val_accuracy: 0.1709\n",
      "Epoch 546/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6261 - accuracy: 0.6919 - val_loss: 6.4147 - val_accuracy: 0.1713\n",
      "Epoch 547/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.6246 - accuracy: 0.6917 - val_loss: 6.4183 - val_accuracy: 0.1701\n",
      "Epoch 548/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.6220 - accuracy: 0.6923 - val_loss: 6.4194 - val_accuracy: 0.1717\n",
      "Epoch 549/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.6202 - accuracy: 0.6928 - val_loss: 6.4201 - val_accuracy: 0.1729\n",
      "Epoch 550/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.6171 - accuracy: 0.6942 - val_loss: 6.4268 - val_accuracy: 0.1692\n",
      "Epoch 551/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.6159 - accuracy: 0.6934 - val_loss: 6.4233 - val_accuracy: 0.1706\n",
      "Epoch 552/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6140 - accuracy: 0.6940 - val_loss: 6.4245 - val_accuracy: 0.1712\n",
      "Epoch 553/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6110 - accuracy: 0.6947 - val_loss: 6.4319 - val_accuracy: 0.1710\n",
      "Epoch 554/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.6082 - accuracy: 0.6954 - val_loss: 6.4317 - val_accuracy: 0.1705\n",
      "Epoch 555/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.6076 - accuracy: 0.6953 - val_loss: 6.4313 - val_accuracy: 0.1712\n",
      "Epoch 556/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.6063 - accuracy: 0.6963 - val_loss: 6.4292 - val_accuracy: 0.1716\n",
      "Epoch 557/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.6041 - accuracy: 0.6957 - val_loss: 6.4334 - val_accuracy: 0.1705\n",
      "Epoch 558/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.6016 - accuracy: 0.6967 - val_loss: 6.4361 - val_accuracy: 0.1698\n",
      "Epoch 559/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.6000 - accuracy: 0.6969 - val_loss: 6.4388 - val_accuracy: 0.1719\n",
      "Epoch 560/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5981 - accuracy: 0.6979 - val_loss: 6.4411 - val_accuracy: 0.1703\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 527ms/step - loss: 2.5965 - accuracy: 0.6969 - val_loss: 6.4401 - val_accuracy: 0.1704\n",
      "Epoch 562/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.5934 - accuracy: 0.6985 - val_loss: 6.4406 - val_accuracy: 0.1714\n",
      "Epoch 563/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.5905 - accuracy: 0.6989 - val_loss: 6.4453 - val_accuracy: 0.1711\n",
      "Epoch 564/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.5883 - accuracy: 0.6996 - val_loss: 6.4439 - val_accuracy: 0.1710\n",
      "Epoch 565/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5859 - accuracy: 0.7002 - val_loss: 6.4490 - val_accuracy: 0.1706\n",
      "Epoch 566/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5836 - accuracy: 0.7001 - val_loss: 6.4497 - val_accuracy: 0.1703\n",
      "Epoch 567/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.5821 - accuracy: 0.7010 - val_loss: 6.4520 - val_accuracy: 0.1706\n",
      "Epoch 568/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5830 - accuracy: 0.7006 - val_loss: 6.4478 - val_accuracy: 0.1711\n",
      "Epoch 569/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.5797 - accuracy: 0.7012 - val_loss: 6.4511 - val_accuracy: 0.1709\n",
      "Epoch 570/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.5762 - accuracy: 0.7018 - val_loss: 6.4535 - val_accuracy: 0.1709\n",
      "Epoch 571/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.5735 - accuracy: 0.7028 - val_loss: 6.4522 - val_accuracy: 0.1714\n",
      "Epoch 572/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.5713 - accuracy: 0.7036 - val_loss: 6.4582 - val_accuracy: 0.1698\n",
      "Epoch 573/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.5696 - accuracy: 0.7040 - val_loss: 6.4569 - val_accuracy: 0.1698\n",
      "Epoch 574/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.5685 - accuracy: 0.7041 - val_loss: 6.4576 - val_accuracy: 0.1709\n",
      "Epoch 575/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5673 - accuracy: 0.7042 - val_loss: 6.4584 - val_accuracy: 0.1695\n",
      "Epoch 576/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5664 - accuracy: 0.7044 - val_loss: 6.4610 - val_accuracy: 0.1704\n",
      "Epoch 577/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.5631 - accuracy: 0.7048 - val_loss: 6.4620 - val_accuracy: 0.1703\n",
      "Epoch 578/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.5601 - accuracy: 0.7056 - val_loss: 6.4655 - val_accuracy: 0.1702\n",
      "Epoch 579/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.5581 - accuracy: 0.7068 - val_loss: 6.4685 - val_accuracy: 0.1706\n",
      "Epoch 580/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.5557 - accuracy: 0.7069 - val_loss: 6.4677 - val_accuracy: 0.1702\n",
      "Epoch 581/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.5553 - accuracy: 0.7064 - val_loss: 6.4716 - val_accuracy: 0.1698\n",
      "Epoch 582/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.5540 - accuracy: 0.7067 - val_loss: 6.4718 - val_accuracy: 0.1693\n",
      "Epoch 583/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5523 - accuracy: 0.7072 - val_loss: 6.4742 - val_accuracy: 0.1693\n",
      "Epoch 584/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.5511 - accuracy: 0.7076 - val_loss: 6.4736 - val_accuracy: 0.1712\n",
      "Epoch 585/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.5491 - accuracy: 0.7081 - val_loss: 6.4766 - val_accuracy: 0.1707\n",
      "Epoch 586/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.5464 - accuracy: 0.7087 - val_loss: 6.4761 - val_accuracy: 0.1715\n",
      "Epoch 587/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.5466 - accuracy: 0.7086 - val_loss: 6.4793 - val_accuracy: 0.1687\n",
      "Epoch 588/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.5442 - accuracy: 0.7094 - val_loss: 6.4781 - val_accuracy: 0.1692\n",
      "Epoch 589/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5407 - accuracy: 0.7101 - val_loss: 6.4770 - val_accuracy: 0.1707\n",
      "Epoch 590/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.5380 - accuracy: 0.7106 - val_loss: 6.4819 - val_accuracy: 0.1700\n",
      "Epoch 591/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.5367 - accuracy: 0.7107 - val_loss: 6.4850 - val_accuracy: 0.1692\n",
      "Epoch 592/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.5355 - accuracy: 0.7112 - val_loss: 6.4853 - val_accuracy: 0.1686\n",
      "Epoch 593/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5327 - accuracy: 0.7116 - val_loss: 6.4882 - val_accuracy: 0.1699\n",
      "Epoch 594/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5319 - accuracy: 0.7120 - val_loss: 6.4876 - val_accuracy: 0.1705\n",
      "Epoch 595/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5297 - accuracy: 0.7125 - val_loss: 6.4900 - val_accuracy: 0.1701\n",
      "Epoch 596/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5275 - accuracy: 0.7130 - val_loss: 6.4895 - val_accuracy: 0.1702\n",
      "Epoch 597/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.5254 - accuracy: 0.7136 - val_loss: 6.4900 - val_accuracy: 0.1696\n",
      "Epoch 598/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 2.5242 - accuracy: 0.7142 - val_loss: 6.4936 - val_accuracy: 0.1702\n",
      "Epoch 599/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 2.5240 - accuracy: 0.7138 - val_loss: 6.4961 - val_accuracy: 0.1698\n",
      "Epoch 600/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.5220 - accuracy: 0.7147 - val_loss: 6.4966 - val_accuracy: 0.1694\n",
      "Epoch 601/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.5199 - accuracy: 0.7152 - val_loss: 6.5015 - val_accuracy: 0.1689\n",
      "Epoch 602/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.5210 - accuracy: 0.7144 - val_loss: 6.4991 - val_accuracy: 0.1694\n",
      "Epoch 603/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.5220 - accuracy: 0.7139 - val_loss: 6.5010 - val_accuracy: 0.1696\n",
      "Epoch 604/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 2.5178 - accuracy: 0.7148 - val_loss: 6.5024 - val_accuracy: 0.1689\n",
      "Epoch 605/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5145 - accuracy: 0.7162 - val_loss: 6.5038 - val_accuracy: 0.1696\n",
      "Epoch 606/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.5112 - accuracy: 0.7167 - val_loss: 6.5018 - val_accuracy: 0.1707\n",
      "Epoch 607/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.5090 - accuracy: 0.7175 - val_loss: 6.5081 - val_accuracy: 0.1689\n",
      "Epoch 608/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.5086 - accuracy: 0.7179 - val_loss: 6.5072 - val_accuracy: 0.1687\n",
      "Epoch 609/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.5065 - accuracy: 0.7180 - val_loss: 6.5083 - val_accuracy: 0.1692\n",
      "Epoch 610/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.5034 - accuracy: 0.7187 - val_loss: 6.5090 - val_accuracy: 0.1692\n",
      "Epoch 611/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.5021 - accuracy: 0.7184 - val_loss: 6.5101 - val_accuracy: 0.1698\n",
      "Epoch 612/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.5006 - accuracy: 0.7191 - val_loss: 6.5173 - val_accuracy: 0.1677\n",
      "Epoch 613/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.4976 - accuracy: 0.7200 - val_loss: 6.5173 - val_accuracy: 0.1686\n",
      "Epoch 614/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.4964 - accuracy: 0.7199 - val_loss: 6.5196 - val_accuracy: 0.1683\n",
      "Epoch 615/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.4939 - accuracy: 0.7205 - val_loss: 6.5180 - val_accuracy: 0.1696\n",
      "Epoch 616/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.4925 - accuracy: 0.7212 - val_loss: 6.5203 - val_accuracy: 0.1685\n",
      "Epoch 617/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 537ms/step - loss: 2.4909 - accuracy: 0.7212 - val_loss: 6.5221 - val_accuracy: 0.1692\n",
      "Epoch 618/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.4887 - accuracy: 0.7224 - val_loss: 6.5203 - val_accuracy: 0.1695\n",
      "Epoch 619/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.4886 - accuracy: 0.7222 - val_loss: 6.5225 - val_accuracy: 0.1681\n",
      "Epoch 620/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.4975 - accuracy: 0.7185 - val_loss: 6.5268 - val_accuracy: 0.1684\n",
      "Epoch 621/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.4934 - accuracy: 0.7196 - val_loss: 6.5296 - val_accuracy: 0.1688\n",
      "Epoch 622/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.4870 - accuracy: 0.7224 - val_loss: 6.5274 - val_accuracy: 0.1702\n",
      "Epoch 623/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.4828 - accuracy: 0.7234 - val_loss: 6.5310 - val_accuracy: 0.1684\n",
      "Epoch 624/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.4797 - accuracy: 0.7245 - val_loss: 6.5342 - val_accuracy: 0.1681\n",
      "Epoch 625/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.4774 - accuracy: 0.7247 - val_loss: 6.5352 - val_accuracy: 0.1678\n",
      "Epoch 626/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.4764 - accuracy: 0.7253 - val_loss: 6.5379 - val_accuracy: 0.1683\n",
      "Epoch 627/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.4749 - accuracy: 0.7250 - val_loss: 6.5371 - val_accuracy: 0.1695\n",
      "Epoch 628/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.4734 - accuracy: 0.7254 - val_loss: 6.5363 - val_accuracy: 0.1684\n",
      "Epoch 629/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.4705 - accuracy: 0.7261 - val_loss: 6.5358 - val_accuracy: 0.1692\n",
      "Epoch 630/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.4676 - accuracy: 0.7274 - val_loss: 6.5408 - val_accuracy: 0.1683\n",
      "Epoch 631/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.4657 - accuracy: 0.7275 - val_loss: 6.5445 - val_accuracy: 0.1685\n",
      "Epoch 632/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.4654 - accuracy: 0.7276 - val_loss: 6.5421 - val_accuracy: 0.1681\n",
      "Epoch 633/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.4662 - accuracy: 0.7266 - val_loss: 6.5457 - val_accuracy: 0.1678\n",
      "Epoch 634/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.4659 - accuracy: 0.7272 - val_loss: 6.5469 - val_accuracy: 0.1685\n",
      "Epoch 635/1000\n",
      "17/17 [==============================] - 9s 537ms/step - loss: 2.4628 - accuracy: 0.7281 - val_loss: 6.5476 - val_accuracy: 0.1691\n",
      "Epoch 636/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.4608 - accuracy: 0.7281 - val_loss: 6.5526 - val_accuracy: 0.1679\n",
      "Epoch 637/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.4594 - accuracy: 0.7288 - val_loss: 6.5520 - val_accuracy: 0.1680\n",
      "Epoch 638/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.4568 - accuracy: 0.7294 - val_loss: 6.5501 - val_accuracy: 0.1681\n",
      "Epoch 639/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.4563 - accuracy: 0.7294 - val_loss: 6.5544 - val_accuracy: 0.1675\n",
      "Epoch 640/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.4723 - accuracy: 0.7245 - val_loss: 6.5543 - val_accuracy: 0.1688\n",
      "Epoch 641/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.4618 - accuracy: 0.7276 - val_loss: 6.5527 - val_accuracy: 0.1681\n",
      "Epoch 642/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.4564 - accuracy: 0.7291 - val_loss: 6.5541 - val_accuracy: 0.1683\n",
      "Epoch 643/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.4531 - accuracy: 0.7302 - val_loss: 6.5565 - val_accuracy: 0.1686\n",
      "Epoch 644/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.4492 - accuracy: 0.7307 - val_loss: 6.5613 - val_accuracy: 0.1676\n",
      "Epoch 645/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.4471 - accuracy: 0.7314 - val_loss: 6.5638 - val_accuracy: 0.1678\n",
      "Epoch 646/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.4442 - accuracy: 0.7324 - val_loss: 6.5653 - val_accuracy: 0.1666\n",
      "Epoch 647/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.4434 - accuracy: 0.7325 - val_loss: 6.5639 - val_accuracy: 0.1672\n",
      "Epoch 648/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.4415 - accuracy: 0.7329 - val_loss: 6.5669 - val_accuracy: 0.1677\n",
      "Epoch 649/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.4394 - accuracy: 0.7336 - val_loss: 6.5652 - val_accuracy: 0.1685\n",
      "Epoch 650/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.4387 - accuracy: 0.7335 - val_loss: 6.5681 - val_accuracy: 0.1671\n",
      "Epoch 651/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.4367 - accuracy: 0.7344 - val_loss: 6.5713 - val_accuracy: 0.1678\n",
      "Epoch 652/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.4350 - accuracy: 0.7343 - val_loss: 6.5694 - val_accuracy: 0.1665\n",
      "Epoch 653/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.4342 - accuracy: 0.7345 - val_loss: 6.5746 - val_accuracy: 0.1672\n",
      "Epoch 654/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.4351 - accuracy: 0.7341 - val_loss: 6.5772 - val_accuracy: 0.1677\n",
      "Epoch 655/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.4337 - accuracy: 0.7345 - val_loss: 6.5762 - val_accuracy: 0.1686\n",
      "Epoch 656/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.4313 - accuracy: 0.7351 - val_loss: 6.5780 - val_accuracy: 0.1670\n",
      "Epoch 657/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.4288 - accuracy: 0.7358 - val_loss: 6.5810 - val_accuracy: 0.1668\n",
      "Epoch 658/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.4273 - accuracy: 0.7360 - val_loss: 6.5789 - val_accuracy: 0.1674\n",
      "Epoch 659/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.4256 - accuracy: 0.7367 - val_loss: 6.5782 - val_accuracy: 0.1667\n",
      "Epoch 660/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.4249 - accuracy: 0.7368 - val_loss: 6.5814 - val_accuracy: 0.1675\n",
      "Epoch 661/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.4229 - accuracy: 0.7373 - val_loss: 6.5855 - val_accuracy: 0.1664\n",
      "Epoch 662/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.4202 - accuracy: 0.7384 - val_loss: 6.5866 - val_accuracy: 0.1660\n",
      "Epoch 663/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.4189 - accuracy: 0.7382 - val_loss: 6.5860 - val_accuracy: 0.1681\n",
      "Epoch 664/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 2.4178 - accuracy: 0.7387 - val_loss: 6.5931 - val_accuracy: 0.1671\n",
      "Epoch 665/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.4183 - accuracy: 0.7378 - val_loss: 6.5923 - val_accuracy: 0.1656\n",
      "Epoch 666/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.4161 - accuracy: 0.7392 - val_loss: 6.5887 - val_accuracy: 0.1670\n",
      "Epoch 667/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.4159 - accuracy: 0.7385 - val_loss: 6.5925 - val_accuracy: 0.1670\n",
      "Epoch 668/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.4142 - accuracy: 0.7394 - val_loss: 6.5947 - val_accuracy: 0.1665\n",
      "Epoch 669/1000\n",
      "17/17 [==============================] - 9s 525ms/step - loss: 2.4119 - accuracy: 0.7396 - val_loss: 6.5894 - val_accuracy: 0.1671\n",
      "Epoch 670/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.4104 - accuracy: 0.7403 - val_loss: 6.5984 - val_accuracy: 0.1666\n",
      "Epoch 671/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.4077 - accuracy: 0.7411 - val_loss: 6.5949 - val_accuracy: 0.1675\n",
      "Epoch 672/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.4057 - accuracy: 0.7411 - val_loss: 6.5984 - val_accuracy: 0.1671\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 532ms/step - loss: 2.4051 - accuracy: 0.7417 - val_loss: 6.6006 - val_accuracy: 0.1678\n",
      "Epoch 674/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.4059 - accuracy: 0.7408 - val_loss: 6.6025 - val_accuracy: 0.1671\n",
      "Epoch 675/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.4058 - accuracy: 0.7410 - val_loss: 6.6051 - val_accuracy: 0.1686\n",
      "Epoch 676/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.4024 - accuracy: 0.7420 - val_loss: 6.6047 - val_accuracy: 0.1676\n",
      "Epoch 677/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3994 - accuracy: 0.7430 - val_loss: 6.6074 - val_accuracy: 0.1666\n",
      "Epoch 678/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.3974 - accuracy: 0.7436 - val_loss: 6.6080 - val_accuracy: 0.1672\n",
      "Epoch 679/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3971 - accuracy: 0.7429 - val_loss: 6.6102 - val_accuracy: 0.1678\n",
      "Epoch 680/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3955 - accuracy: 0.7436 - val_loss: 6.6123 - val_accuracy: 0.1671\n",
      "Epoch 681/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3949 - accuracy: 0.7438 - val_loss: 6.6109 - val_accuracy: 0.1664\n",
      "Epoch 682/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3948 - accuracy: 0.7434 - val_loss: 6.6143 - val_accuracy: 0.1672\n",
      "Epoch 683/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3922 - accuracy: 0.7440 - val_loss: 6.6167 - val_accuracy: 0.1669\n",
      "Epoch 684/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.3902 - accuracy: 0.7448 - val_loss: 6.6201 - val_accuracy: 0.1659\n",
      "Epoch 685/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3888 - accuracy: 0.7456 - val_loss: 6.6246 - val_accuracy: 0.1661\n",
      "Epoch 686/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3874 - accuracy: 0.7453 - val_loss: 6.6230 - val_accuracy: 0.1667\n",
      "Epoch 687/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3856 - accuracy: 0.7463 - val_loss: 6.6224 - val_accuracy: 0.1658\n",
      "Epoch 688/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.3841 - accuracy: 0.7462 - val_loss: 6.6237 - val_accuracy: 0.1664\n",
      "Epoch 689/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3824 - accuracy: 0.7465 - val_loss: 6.6205 - val_accuracy: 0.1671\n",
      "Epoch 690/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3810 - accuracy: 0.7464 - val_loss: 6.6278 - val_accuracy: 0.1667\n",
      "Epoch 691/1000\n",
      "17/17 [==============================] - 9s 537ms/step - loss: 2.3808 - accuracy: 0.7468 - val_loss: 6.6285 - val_accuracy: 0.1672\n",
      "Epoch 692/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3827 - accuracy: 0.7457 - val_loss: 6.6308 - val_accuracy: 0.1658\n",
      "Epoch 693/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3808 - accuracy: 0.7464 - val_loss: 6.6274 - val_accuracy: 0.1661\n",
      "Epoch 694/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3786 - accuracy: 0.7474 - val_loss: 6.6323 - val_accuracy: 0.1667\n",
      "Epoch 695/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3763 - accuracy: 0.7476 - val_loss: 6.6349 - val_accuracy: 0.1653\n",
      "Epoch 696/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3761 - accuracy: 0.7475 - val_loss: 6.6335 - val_accuracy: 0.1665\n",
      "Epoch 697/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.3745 - accuracy: 0.7478 - val_loss: 6.6377 - val_accuracy: 0.1663\n",
      "Epoch 698/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3713 - accuracy: 0.7493 - val_loss: 6.6355 - val_accuracy: 0.1660\n",
      "Epoch 699/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3693 - accuracy: 0.7496 - val_loss: 6.6390 - val_accuracy: 0.1665\n",
      "Epoch 700/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.3679 - accuracy: 0.7499 - val_loss: 6.6397 - val_accuracy: 0.1656\n",
      "Epoch 701/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.3664 - accuracy: 0.7504 - val_loss: 6.6446 - val_accuracy: 0.1662\n",
      "Epoch 702/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3665 - accuracy: 0.7502 - val_loss: 6.6485 - val_accuracy: 0.1656\n",
      "Epoch 703/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3655 - accuracy: 0.7505 - val_loss: 6.6407 - val_accuracy: 0.1666\n",
      "Epoch 704/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3630 - accuracy: 0.7510 - val_loss: 6.6474 - val_accuracy: 0.1655\n",
      "Epoch 705/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3606 - accuracy: 0.7518 - val_loss: 6.6500 - val_accuracy: 0.1666\n",
      "Epoch 706/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3600 - accuracy: 0.7516 - val_loss: 6.6485 - val_accuracy: 0.1650\n",
      "Epoch 707/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3611 - accuracy: 0.7515 - val_loss: 6.6537 - val_accuracy: 0.1653\n",
      "Epoch 708/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3594 - accuracy: 0.7516 - val_loss: 6.6527 - val_accuracy: 0.1666\n",
      "Epoch 709/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.3572 - accuracy: 0.7526 - val_loss: 6.6531 - val_accuracy: 0.1650\n",
      "Epoch 710/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3571 - accuracy: 0.7523 - val_loss: 6.6523 - val_accuracy: 0.1658\n",
      "Epoch 711/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3586 - accuracy: 0.7508 - val_loss: 6.6526 - val_accuracy: 0.1661\n",
      "Epoch 712/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.3587 - accuracy: 0.7514 - val_loss: 6.6608 - val_accuracy: 0.1661\n",
      "Epoch 713/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3555 - accuracy: 0.7525 - val_loss: 6.6626 - val_accuracy: 0.1658\n",
      "Epoch 714/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3524 - accuracy: 0.7537 - val_loss: 6.6616 - val_accuracy: 0.1658\n",
      "Epoch 715/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3508 - accuracy: 0.7539 - val_loss: 6.6636 - val_accuracy: 0.1644\n",
      "Epoch 716/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3491 - accuracy: 0.7539 - val_loss: 6.6658 - val_accuracy: 0.1653\n",
      "Epoch 717/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3471 - accuracy: 0.7544 - val_loss: 6.6687 - val_accuracy: 0.1652\n",
      "Epoch 718/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3471 - accuracy: 0.7541 - val_loss: 6.6662 - val_accuracy: 0.1656\n",
      "Epoch 719/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3447 - accuracy: 0.7552 - val_loss: 6.6657 - val_accuracy: 0.1658\n",
      "Epoch 720/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3435 - accuracy: 0.7557 - val_loss: 6.6733 - val_accuracy: 0.1652\n",
      "Epoch 721/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3436 - accuracy: 0.7556 - val_loss: 6.6723 - val_accuracy: 0.1654\n",
      "Epoch 722/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3422 - accuracy: 0.7553 - val_loss: 6.6729 - val_accuracy: 0.1654\n",
      "Epoch 723/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.3406 - accuracy: 0.7555 - val_loss: 6.6752 - val_accuracy: 0.1657\n",
      "Epoch 724/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3387 - accuracy: 0.7565 - val_loss: 6.6757 - val_accuracy: 0.1651\n",
      "Epoch 725/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3374 - accuracy: 0.7562 - val_loss: 6.6783 - val_accuracy: 0.1654\n",
      "Epoch 726/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.3354 - accuracy: 0.7569 - val_loss: 6.6819 - val_accuracy: 0.1650\n",
      "Epoch 727/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3334 - accuracy: 0.7579 - val_loss: 6.6831 - val_accuracy: 0.1645\n",
      "Epoch 728/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3318 - accuracy: 0.7579 - val_loss: 6.6796 - val_accuracy: 0.1647\n",
      "Epoch 729/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3315 - accuracy: 0.7580 - val_loss: 6.6843 - val_accuracy: 0.1653\n",
      "Epoch 730/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3342 - accuracy: 0.7572 - val_loss: 6.6850 - val_accuracy: 0.1641\n",
      "Epoch 731/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3337 - accuracy: 0.7568 - val_loss: 6.6843 - val_accuracy: 0.1645\n",
      "Epoch 732/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.3311 - accuracy: 0.7576 - val_loss: 6.6822 - val_accuracy: 0.1651\n",
      "Epoch 733/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3280 - accuracy: 0.7588 - val_loss: 6.6879 - val_accuracy: 0.1640\n",
      "Epoch 734/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3262 - accuracy: 0.7590 - val_loss: 6.6898 - val_accuracy: 0.1643\n",
      "Epoch 735/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3248 - accuracy: 0.7597 - val_loss: 6.6884 - val_accuracy: 0.1650\n",
      "Epoch 736/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3235 - accuracy: 0.7597 - val_loss: 6.6921 - val_accuracy: 0.1640\n",
      "Epoch 737/1000\n",
      "17/17 [==============================] - 9s 525ms/step - loss: 2.3217 - accuracy: 0.7602 - val_loss: 6.6939 - val_accuracy: 0.1634\n",
      "Epoch 738/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3204 - accuracy: 0.7609 - val_loss: 6.6955 - val_accuracy: 0.1644\n",
      "Epoch 739/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3215 - accuracy: 0.7602 - val_loss: 6.6960 - val_accuracy: 0.1642\n",
      "Epoch 740/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3193 - accuracy: 0.7608 - val_loss: 6.6989 - val_accuracy: 0.1646\n",
      "Epoch 741/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3165 - accuracy: 0.7615 - val_loss: 6.7004 - val_accuracy: 0.1642\n",
      "Epoch 742/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3157 - accuracy: 0.7616 - val_loss: 6.7002 - val_accuracy: 0.1643\n",
      "Epoch 743/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3147 - accuracy: 0.7618 - val_loss: 6.7022 - val_accuracy: 0.1650\n",
      "Epoch 744/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3124 - accuracy: 0.7627 - val_loss: 6.7043 - val_accuracy: 0.1641\n",
      "Epoch 745/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.3119 - accuracy: 0.7626 - val_loss: 6.7070 - val_accuracy: 0.1647\n",
      "Epoch 746/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3121 - accuracy: 0.7624 - val_loss: 6.7086 - val_accuracy: 0.1640\n",
      "Epoch 747/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3115 - accuracy: 0.7622 - val_loss: 6.7071 - val_accuracy: 0.1648\n",
      "Epoch 748/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3151 - accuracy: 0.7608 - val_loss: 6.7078 - val_accuracy: 0.1646\n",
      "Epoch 749/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3159 - accuracy: 0.7604 - val_loss: 6.7053 - val_accuracy: 0.1644\n",
      "Epoch 750/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3111 - accuracy: 0.7624 - val_loss: 6.7118 - val_accuracy: 0.1638\n",
      "Epoch 751/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3077 - accuracy: 0.7626 - val_loss: 6.7141 - val_accuracy: 0.1644\n",
      "Epoch 752/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3067 - accuracy: 0.7630 - val_loss: 6.7135 - val_accuracy: 0.1643\n",
      "Epoch 753/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3052 - accuracy: 0.7633 - val_loss: 6.7142 - val_accuracy: 0.1641\n",
      "Epoch 754/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.3032 - accuracy: 0.7642 - val_loss: 6.7144 - val_accuracy: 0.1655\n",
      "Epoch 755/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.3016 - accuracy: 0.7643 - val_loss: 6.7172 - val_accuracy: 0.1647\n",
      "Epoch 756/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.5773 - accuracy: 0.6797 - val_loss: 6.6952 - val_accuracy: 0.1615\n",
      "Epoch 757/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.5155 - accuracy: 0.6914 - val_loss: 6.6976 - val_accuracy: 0.1657\n",
      "Epoch 758/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.4198 - accuracy: 0.7235 - val_loss: 6.6980 - val_accuracy: 0.1656\n",
      "Epoch 759/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3711 - accuracy: 0.7414 - val_loss: 6.7029 - val_accuracy: 0.1650\n",
      "Epoch 760/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3453 - accuracy: 0.7509 - val_loss: 6.6978 - val_accuracy: 0.1662\n",
      "Epoch 761/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3303 - accuracy: 0.7550 - val_loss: 6.6988 - val_accuracy: 0.1658\n",
      "Epoch 762/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.3217 - accuracy: 0.7580 - val_loss: 6.7038 - val_accuracy: 0.1664\n",
      "Epoch 763/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.3154 - accuracy: 0.7596 - val_loss: 6.7039 - val_accuracy: 0.1664\n",
      "Epoch 764/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3104 - accuracy: 0.7613 - val_loss: 6.7093 - val_accuracy: 0.1668\n",
      "Epoch 765/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.3073 - accuracy: 0.7620 - val_loss: 6.7067 - val_accuracy: 0.1665\n",
      "Epoch 766/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.3049 - accuracy: 0.7628 - val_loss: 6.7141 - val_accuracy: 0.1657\n",
      "Epoch 767/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3016 - accuracy: 0.7638 - val_loss: 6.7145 - val_accuracy: 0.1664\n",
      "Epoch 768/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.2987 - accuracy: 0.7644 - val_loss: 6.7158 - val_accuracy: 0.1664\n",
      "Epoch 769/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2968 - accuracy: 0.7648 - val_loss: 6.7152 - val_accuracy: 0.1675\n",
      "Epoch 770/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2963 - accuracy: 0.7649 - val_loss: 6.7177 - val_accuracy: 0.1668\n",
      "Epoch 771/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2946 - accuracy: 0.7654 - val_loss: 6.7208 - val_accuracy: 0.1658\n",
      "Epoch 772/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.2922 - accuracy: 0.7660 - val_loss: 6.7215 - val_accuracy: 0.1656\n",
      "Epoch 773/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.2900 - accuracy: 0.7667 - val_loss: 6.7248 - val_accuracy: 0.1659\n",
      "Epoch 774/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2884 - accuracy: 0.7669 - val_loss: 6.7217 - val_accuracy: 0.1661\n",
      "Epoch 775/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.2868 - accuracy: 0.7675 - val_loss: 6.7267 - val_accuracy: 0.1666\n",
      "Epoch 776/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2860 - accuracy: 0.7674 - val_loss: 6.7281 - val_accuracy: 0.1655\n",
      "Epoch 777/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.3029 - accuracy: 0.7620 - val_loss: 6.7255 - val_accuracy: 0.1654\n",
      "Epoch 778/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2996 - accuracy: 0.7626 - val_loss: 6.7246 - val_accuracy: 0.1659\n",
      "Epoch 779/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2914 - accuracy: 0.7650 - val_loss: 6.7293 - val_accuracy: 0.1665\n",
      "Epoch 780/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2852 - accuracy: 0.7675 - val_loss: 6.7289 - val_accuracy: 0.1652\n",
      "Epoch 781/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2820 - accuracy: 0.7685 - val_loss: 6.7311 - val_accuracy: 0.1666\n",
      "Epoch 782/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2802 - accuracy: 0.7692 - val_loss: 6.7326 - val_accuracy: 0.1664\n",
      "Epoch 783/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.2782 - accuracy: 0.7696 - val_loss: 6.7346 - val_accuracy: 0.1662\n",
      "Epoch 784/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2769 - accuracy: 0.7696 - val_loss: 6.7396 - val_accuracy: 0.1662\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2748 - accuracy: 0.7701 - val_loss: 6.7410 - val_accuracy: 0.1658\n",
      "Epoch 786/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2735 - accuracy: 0.7705 - val_loss: 6.7392 - val_accuracy: 0.1662\n",
      "Epoch 787/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.2724 - accuracy: 0.7704 - val_loss: 6.7446 - val_accuracy: 0.1660\n",
      "Epoch 788/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2710 - accuracy: 0.7709 - val_loss: 6.7389 - val_accuracy: 0.1667\n",
      "Epoch 789/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2700 - accuracy: 0.7714 - val_loss: 6.7426 - val_accuracy: 0.1656\n",
      "Epoch 790/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2686 - accuracy: 0.7718 - val_loss: 6.7477 - val_accuracy: 0.1658\n",
      "Epoch 791/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.2688 - accuracy: 0.7717 - val_loss: 6.7453 - val_accuracy: 0.1658\n",
      "Epoch 792/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2694 - accuracy: 0.7708 - val_loss: 6.7529 - val_accuracy: 0.1656\n",
      "Epoch 793/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2671 - accuracy: 0.7719 - val_loss: 6.7503 - val_accuracy: 0.1655\n",
      "Epoch 794/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2653 - accuracy: 0.7723 - val_loss: 6.7515 - val_accuracy: 0.1652\n",
      "Epoch 795/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 2.2637 - accuracy: 0.7728 - val_loss: 6.7558 - val_accuracy: 0.1657\n",
      "Epoch 796/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2632 - accuracy: 0.7729 - val_loss: 6.7544 - val_accuracy: 0.1658\n",
      "Epoch 797/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2623 - accuracy: 0.7729 - val_loss: 6.7565 - val_accuracy: 0.1656\n",
      "Epoch 798/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2610 - accuracy: 0.7733 - val_loss: 6.7596 - val_accuracy: 0.1650\n",
      "Epoch 799/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2596 - accuracy: 0.7732 - val_loss: 6.7554 - val_accuracy: 0.1651\n",
      "Epoch 800/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2591 - accuracy: 0.7736 - val_loss: 6.7609 - val_accuracy: 0.1646\n",
      "Epoch 801/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2579 - accuracy: 0.7740 - val_loss: 6.7649 - val_accuracy: 0.1664\n",
      "Epoch 802/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2624 - accuracy: 0.7725 - val_loss: 6.7627 - val_accuracy: 0.1671\n",
      "Epoch 803/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2597 - accuracy: 0.7732 - val_loss: 6.7661 - val_accuracy: 0.1661\n",
      "Epoch 804/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.2570 - accuracy: 0.7739 - val_loss: 6.7662 - val_accuracy: 0.1654\n",
      "Epoch 805/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2545 - accuracy: 0.7743 - val_loss: 6.7679 - val_accuracy: 0.1658\n",
      "Epoch 806/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2530 - accuracy: 0.7751 - val_loss: 6.7693 - val_accuracy: 0.1658\n",
      "Epoch 807/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2521 - accuracy: 0.7752 - val_loss: 6.7668 - val_accuracy: 0.1659\n",
      "Epoch 808/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2513 - accuracy: 0.7753 - val_loss: 6.7690 - val_accuracy: 0.1654\n",
      "Epoch 809/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.2502 - accuracy: 0.7758 - val_loss: 6.7727 - val_accuracy: 0.1661\n",
      "Epoch 810/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2490 - accuracy: 0.7757 - val_loss: 6.7734 - val_accuracy: 0.1654\n",
      "Epoch 811/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2489 - accuracy: 0.7759 - val_loss: 6.7751 - val_accuracy: 0.1662\n",
      "Epoch 812/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2479 - accuracy: 0.7758 - val_loss: 6.7717 - val_accuracy: 0.1665\n",
      "Epoch 813/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.2469 - accuracy: 0.7761 - val_loss: 6.7748 - val_accuracy: 0.1661\n",
      "Epoch 814/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2470 - accuracy: 0.7763 - val_loss: 6.7735 - val_accuracy: 0.1658\n",
      "Epoch 815/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2467 - accuracy: 0.7761 - val_loss: 6.7803 - val_accuracy: 0.1654\n",
      "Epoch 816/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.2449 - accuracy: 0.7763 - val_loss: 6.7828 - val_accuracy: 0.1646\n",
      "Epoch 817/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.2440 - accuracy: 0.7770 - val_loss: 6.7828 - val_accuracy: 0.1651\n",
      "Epoch 818/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2432 - accuracy: 0.7772 - val_loss: 6.7858 - val_accuracy: 0.1650\n",
      "Epoch 819/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2414 - accuracy: 0.7775 - val_loss: 6.7875 - val_accuracy: 0.1646\n",
      "Epoch 820/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.2405 - accuracy: 0.7774 - val_loss: 6.7865 - val_accuracy: 0.1642\n",
      "Epoch 821/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2392 - accuracy: 0.7784 - val_loss: 6.7872 - val_accuracy: 0.1650\n",
      "Epoch 822/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2379 - accuracy: 0.7781 - val_loss: 6.7900 - val_accuracy: 0.1651\n",
      "Epoch 823/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2376 - accuracy: 0.7782 - val_loss: 6.7900 - val_accuracy: 0.1654\n",
      "Epoch 824/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2372 - accuracy: 0.7781 - val_loss: 6.7915 - val_accuracy: 0.1649\n",
      "Epoch 825/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2362 - accuracy: 0.7787 - val_loss: 6.7976 - val_accuracy: 0.1650\n",
      "Epoch 826/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2347 - accuracy: 0.7789 - val_loss: 6.7971 - val_accuracy: 0.1654\n",
      "Epoch 827/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 2.2335 - accuracy: 0.7795 - val_loss: 6.7979 - val_accuracy: 0.1644\n",
      "Epoch 828/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2329 - accuracy: 0.7798 - val_loss: 6.7968 - val_accuracy: 0.1647\n",
      "Epoch 829/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2325 - accuracy: 0.7796 - val_loss: 6.8001 - val_accuracy: 0.1649\n",
      "Epoch 830/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2311 - accuracy: 0.7799 - val_loss: 6.7994 - val_accuracy: 0.1645\n",
      "Epoch 831/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.2301 - accuracy: 0.7803 - val_loss: 6.8017 - val_accuracy: 0.1644\n",
      "Epoch 832/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.2296 - accuracy: 0.7800 - val_loss: 6.8018 - val_accuracy: 0.1652\n",
      "Epoch 833/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2288 - accuracy: 0.7804 - val_loss: 6.8056 - val_accuracy: 0.1650\n",
      "Epoch 834/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2282 - accuracy: 0.7807 - val_loss: 6.8037 - val_accuracy: 0.1646\n",
      "Epoch 835/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2282 - accuracy: 0.7805 - val_loss: 6.8113 - val_accuracy: 0.1651\n",
      "Epoch 836/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2277 - accuracy: 0.7810 - val_loss: 6.8117 - val_accuracy: 0.1644\n",
      "Epoch 837/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2264 - accuracy: 0.7808 - val_loss: 6.8064 - val_accuracy: 0.1654\n",
      "Epoch 838/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2269 - accuracy: 0.7806 - val_loss: 6.8154 - val_accuracy: 0.1644\n",
      "Epoch 839/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.2256 - accuracy: 0.7809 - val_loss: 6.8116 - val_accuracy: 0.1642\n",
      "Epoch 840/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2248 - accuracy: 0.7811 - val_loss: 6.8096 - val_accuracy: 0.1653\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2232 - accuracy: 0.7816 - val_loss: 6.8112 - val_accuracy: 0.1659\n",
      "Epoch 842/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2227 - accuracy: 0.7817 - val_loss: 6.8139 - val_accuracy: 0.1655\n",
      "Epoch 843/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.2209 - accuracy: 0.7825 - val_loss: 6.8159 - val_accuracy: 0.1653\n",
      "Epoch 844/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2199 - accuracy: 0.7821 - val_loss: 6.8133 - val_accuracy: 0.1664\n",
      "Epoch 845/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2211 - accuracy: 0.7819 - val_loss: 6.8213 - val_accuracy: 0.1652\n",
      "Epoch 846/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2317 - accuracy: 0.7781 - val_loss: 6.8181 - val_accuracy: 0.1650\n",
      "Epoch 847/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2307 - accuracy: 0.7785 - val_loss: 6.8158 - val_accuracy: 0.1642\n",
      "Epoch 848/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2254 - accuracy: 0.7806 - val_loss: 6.8280 - val_accuracy: 0.1621\n",
      "Epoch 849/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2213 - accuracy: 0.7821 - val_loss: 6.8231 - val_accuracy: 0.1641\n",
      "Epoch 850/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.2182 - accuracy: 0.7824 - val_loss: 6.8236 - val_accuracy: 0.1637\n",
      "Epoch 851/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2158 - accuracy: 0.7833 - val_loss: 6.8255 - val_accuracy: 0.1643\n",
      "Epoch 852/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2140 - accuracy: 0.7835 - val_loss: 6.8325 - val_accuracy: 0.1641\n",
      "Epoch 853/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2126 - accuracy: 0.7842 - val_loss: 6.8279 - val_accuracy: 0.1642\n",
      "Epoch 854/1000\n",
      "17/17 [==============================] - 9s 526ms/step - loss: 2.2122 - accuracy: 0.7837 - val_loss: 6.8295 - val_accuracy: 0.1635\n",
      "Epoch 855/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2114 - accuracy: 0.7839 - val_loss: 6.8293 - val_accuracy: 0.1642\n",
      "Epoch 856/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2096 - accuracy: 0.7843 - val_loss: 6.8333 - val_accuracy: 0.1630\n",
      "Epoch 857/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2085 - accuracy: 0.7851 - val_loss: 6.8356 - val_accuracy: 0.1634\n",
      "Epoch 858/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2081 - accuracy: 0.7851 - val_loss: 6.8385 - val_accuracy: 0.1636\n",
      "Epoch 859/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2082 - accuracy: 0.7845 - val_loss: 6.8384 - val_accuracy: 0.1631\n",
      "Epoch 860/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2075 - accuracy: 0.7851 - val_loss: 6.8388 - val_accuracy: 0.1634\n",
      "Epoch 861/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2057 - accuracy: 0.7855 - val_loss: 6.8457 - val_accuracy: 0.1626\n",
      "Epoch 862/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2047 - accuracy: 0.7859 - val_loss: 6.8471 - val_accuracy: 0.1624\n",
      "Epoch 863/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.2042 - accuracy: 0.7857 - val_loss: 6.8412 - val_accuracy: 0.1646\n",
      "Epoch 864/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.2035 - accuracy: 0.7858 - val_loss: 6.8439 - val_accuracy: 0.1634\n",
      "Epoch 865/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2027 - accuracy: 0.7857 - val_loss: 6.8441 - val_accuracy: 0.1634\n",
      "Epoch 866/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2015 - accuracy: 0.7863 - val_loss: 6.8474 - val_accuracy: 0.1626\n",
      "Epoch 867/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1999 - accuracy: 0.7869 - val_loss: 6.8481 - val_accuracy: 0.1633\n",
      "Epoch 868/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1987 - accuracy: 0.7871 - val_loss: 6.8510 - val_accuracy: 0.1627\n",
      "Epoch 869/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1978 - accuracy: 0.7874 - val_loss: 6.8542 - val_accuracy: 0.1631\n",
      "Epoch 870/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.1985 - accuracy: 0.7865 - val_loss: 6.8510 - val_accuracy: 0.1643\n",
      "Epoch 871/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.2014 - accuracy: 0.7856 - val_loss: 6.8575 - val_accuracy: 0.1622\n",
      "Epoch 872/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.2097 - accuracy: 0.7831 - val_loss: 6.8532 - val_accuracy: 0.1639\n",
      "Epoch 873/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.2120 - accuracy: 0.7822 - val_loss: 6.8600 - val_accuracy: 0.1638\n",
      "Epoch 874/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.2045 - accuracy: 0.7846 - val_loss: 6.8505 - val_accuracy: 0.1644\n",
      "Epoch 875/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.2008 - accuracy: 0.7858 - val_loss: 6.8516 - val_accuracy: 0.1643\n",
      "Epoch 876/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.1972 - accuracy: 0.7869 - val_loss: 6.8588 - val_accuracy: 0.1637\n",
      "Epoch 877/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1937 - accuracy: 0.7879 - val_loss: 6.8547 - val_accuracy: 0.1649\n",
      "Epoch 878/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1922 - accuracy: 0.7884 - val_loss: 6.8601 - val_accuracy: 0.1638\n",
      "Epoch 879/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1911 - accuracy: 0.7887 - val_loss: 6.8606 - val_accuracy: 0.1647\n",
      "Epoch 880/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1921 - accuracy: 0.7883 - val_loss: 6.8616 - val_accuracy: 0.1647\n",
      "Epoch 881/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1918 - accuracy: 0.7882 - val_loss: 6.8598 - val_accuracy: 0.1644\n",
      "Epoch 882/1000\n",
      "17/17 [==============================] - 9s 537ms/step - loss: 2.1910 - accuracy: 0.7883 - val_loss: 6.8674 - val_accuracy: 0.1639\n",
      "Epoch 883/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1891 - accuracy: 0.7888 - val_loss: 6.8614 - val_accuracy: 0.1654\n",
      "Epoch 884/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1881 - accuracy: 0.7890 - val_loss: 6.8712 - val_accuracy: 0.1629\n",
      "Epoch 885/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1873 - accuracy: 0.7890 - val_loss: 6.8704 - val_accuracy: 0.1640\n",
      "Epoch 886/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.1864 - accuracy: 0.7897 - val_loss: 6.8757 - val_accuracy: 0.1633\n",
      "Epoch 887/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1861 - accuracy: 0.7895 - val_loss: 6.8725 - val_accuracy: 0.1624\n",
      "Epoch 888/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1850 - accuracy: 0.7897 - val_loss: 6.8741 - val_accuracy: 0.1630\n",
      "Epoch 889/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1844 - accuracy: 0.7900 - val_loss: 6.8695 - val_accuracy: 0.1639\n",
      "Epoch 890/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1850 - accuracy: 0.7895 - val_loss: 6.8801 - val_accuracy: 0.1634\n",
      "Epoch 891/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1839 - accuracy: 0.7897 - val_loss: 6.8819 - val_accuracy: 0.1628\n",
      "Epoch 892/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1829 - accuracy: 0.7900 - val_loss: 6.8795 - val_accuracy: 0.1639\n",
      "Epoch 893/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1814 - accuracy: 0.7906 - val_loss: 6.8771 - val_accuracy: 0.1635\n",
      "Epoch 894/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1801 - accuracy: 0.7910 - val_loss: 6.8771 - val_accuracy: 0.1642\n",
      "Epoch 895/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1794 - accuracy: 0.7908 - val_loss: 6.8808 - val_accuracy: 0.1631\n",
      "Epoch 896/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1784 - accuracy: 0.7912 - val_loss: 6.8808 - val_accuracy: 0.1643\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1787 - accuracy: 0.7910 - val_loss: 6.8845 - val_accuracy: 0.1637\n",
      "Epoch 898/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.1780 - accuracy: 0.7913 - val_loss: 6.8816 - val_accuracy: 0.1641\n",
      "Epoch 899/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1772 - accuracy: 0.7915 - val_loss: 6.8879 - val_accuracy: 0.1641\n",
      "Epoch 900/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1807 - accuracy: 0.7905 - val_loss: 6.8876 - val_accuracy: 0.1643\n",
      "Epoch 901/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1769 - accuracy: 0.7913 - val_loss: 6.8881 - val_accuracy: 0.1641\n",
      "Epoch 902/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1744 - accuracy: 0.7923 - val_loss: 6.8890 - val_accuracy: 0.1641\n",
      "Epoch 903/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1737 - accuracy: 0.7920 - val_loss: 6.8956 - val_accuracy: 0.1631\n",
      "Epoch 904/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1733 - accuracy: 0.7918 - val_loss: 6.8926 - val_accuracy: 0.1631\n",
      "Epoch 905/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1734 - accuracy: 0.7920 - val_loss: 6.8913 - val_accuracy: 0.1631\n",
      "Epoch 906/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1743 - accuracy: 0.7917 - val_loss: 6.8930 - val_accuracy: 0.1639\n",
      "Epoch 907/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.1719 - accuracy: 0.7928 - val_loss: 6.8937 - val_accuracy: 0.1624\n",
      "Epoch 908/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1707 - accuracy: 0.7928 - val_loss: 6.8943 - val_accuracy: 0.1640\n",
      "Epoch 909/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1695 - accuracy: 0.7928 - val_loss: 6.8990 - val_accuracy: 0.1633\n",
      "Epoch 910/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1687 - accuracy: 0.7932 - val_loss: 6.8989 - val_accuracy: 0.1637\n",
      "Epoch 911/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1678 - accuracy: 0.7933 - val_loss: 6.8992 - val_accuracy: 0.1636\n",
      "Epoch 912/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1678 - accuracy: 0.7932 - val_loss: 6.9013 - val_accuracy: 0.1634\n",
      "Epoch 913/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1671 - accuracy: 0.7934 - val_loss: 6.9031 - val_accuracy: 0.1637\n",
      "Epoch 914/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1658 - accuracy: 0.7934 - val_loss: 6.9042 - val_accuracy: 0.1634\n",
      "Epoch 915/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1664 - accuracy: 0.7934 - val_loss: 6.9034 - val_accuracy: 0.1633\n",
      "Epoch 916/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1676 - accuracy: 0.7927 - val_loss: 6.9101 - val_accuracy: 0.1627\n",
      "Epoch 917/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1668 - accuracy: 0.7935 - val_loss: 6.9128 - val_accuracy: 0.1626\n",
      "Epoch 918/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1651 - accuracy: 0.7937 - val_loss: 6.9129 - val_accuracy: 0.1625\n",
      "Epoch 919/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1642 - accuracy: 0.7939 - val_loss: 6.9089 - val_accuracy: 0.1629\n",
      "Epoch 920/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1644 - accuracy: 0.7935 - val_loss: 6.9094 - val_accuracy: 0.1630\n",
      "Epoch 921/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1635 - accuracy: 0.7939 - val_loss: 6.9121 - val_accuracy: 0.1629\n",
      "Epoch 922/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.1629 - accuracy: 0.7942 - val_loss: 6.9139 - val_accuracy: 0.1628\n",
      "Epoch 923/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1613 - accuracy: 0.7946 - val_loss: 6.9150 - val_accuracy: 0.1630\n",
      "Epoch 924/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1601 - accuracy: 0.7947 - val_loss: 6.9159 - val_accuracy: 0.1631\n",
      "Epoch 925/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1590 - accuracy: 0.7952 - val_loss: 6.9168 - val_accuracy: 0.1628\n",
      "Epoch 926/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1579 - accuracy: 0.7953 - val_loss: 6.9213 - val_accuracy: 0.1629\n",
      "Epoch 927/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1576 - accuracy: 0.7953 - val_loss: 6.9194 - val_accuracy: 0.1631\n",
      "Epoch 928/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1571 - accuracy: 0.7954 - val_loss: 6.9236 - val_accuracy: 0.1624\n",
      "Epoch 929/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1588 - accuracy: 0.7950 - val_loss: 6.9259 - val_accuracy: 0.1625\n",
      "Epoch 930/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1559 - accuracy: 0.7956 - val_loss: 6.9230 - val_accuracy: 0.1632\n",
      "Epoch 931/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1538 - accuracy: 0.7965 - val_loss: 6.9214 - val_accuracy: 0.1642\n",
      "Epoch 932/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1542 - accuracy: 0.7961 - val_loss: 6.9221 - val_accuracy: 0.1624\n",
      "Epoch 933/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1545 - accuracy: 0.7958 - val_loss: 6.9263 - val_accuracy: 0.1631\n",
      "Epoch 934/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1532 - accuracy: 0.7962 - val_loss: 6.9295 - val_accuracy: 0.1627\n",
      "Epoch 935/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.1519 - accuracy: 0.7966 - val_loss: 6.9295 - val_accuracy: 0.1627\n",
      "Epoch 936/1000\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 2.1506 - accuracy: 0.7971 - val_loss: 6.9267 - val_accuracy: 0.1624\n",
      "Epoch 937/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1497 - accuracy: 0.7973 - val_loss: 6.9302 - val_accuracy: 0.1638\n",
      "Epoch 938/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1487 - accuracy: 0.7976 - val_loss: 6.9317 - val_accuracy: 0.1614\n",
      "Epoch 939/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1497 - accuracy: 0.7969 - val_loss: 6.9302 - val_accuracy: 0.1635\n",
      "Epoch 940/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1511 - accuracy: 0.7965 - val_loss: 6.9309 - val_accuracy: 0.1631\n",
      "Epoch 941/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1529 - accuracy: 0.7958 - val_loss: 6.9356 - val_accuracy: 0.1629\n",
      "Epoch 942/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1514 - accuracy: 0.7963 - val_loss: 6.9362 - val_accuracy: 0.1628\n",
      "Epoch 943/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1489 - accuracy: 0.7971 - val_loss: 6.9325 - val_accuracy: 0.1630\n",
      "Epoch 944/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1472 - accuracy: 0.7973 - val_loss: 6.9374 - val_accuracy: 0.1629\n",
      "Epoch 945/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1454 - accuracy: 0.7978 - val_loss: 6.9370 - val_accuracy: 0.1623\n",
      "Epoch 946/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1441 - accuracy: 0.7983 - val_loss: 6.9367 - val_accuracy: 0.1627\n",
      "Epoch 947/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1433 - accuracy: 0.7983 - val_loss: 6.9419 - val_accuracy: 0.1628\n",
      "Epoch 948/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1433 - accuracy: 0.7983 - val_loss: 6.9390 - val_accuracy: 0.1621\n",
      "Epoch 949/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1425 - accuracy: 0.7990 - val_loss: 6.9402 - val_accuracy: 0.1620\n",
      "Epoch 950/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1417 - accuracy: 0.7990 - val_loss: 6.9415 - val_accuracy: 0.1624\n",
      "Epoch 951/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1416 - accuracy: 0.7987 - val_loss: 6.9396 - val_accuracy: 0.1624\n",
      "Epoch 952/1000\n",
      "17/17 [==============================] - 9s 535ms/step - loss: 2.1401 - accuracy: 0.7992 - val_loss: 6.9441 - val_accuracy: 0.1620\n",
      "Epoch 953/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1388 - accuracy: 0.7994 - val_loss: 6.9463 - val_accuracy: 0.1623\n",
      "Epoch 954/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1384 - accuracy: 0.7993 - val_loss: 6.9458 - val_accuracy: 0.1620\n",
      "Epoch 955/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1379 - accuracy: 0.7996 - val_loss: 6.9476 - val_accuracy: 0.1619\n",
      "Epoch 956/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1373 - accuracy: 0.7995 - val_loss: 6.9495 - val_accuracy: 0.1610\n",
      "Epoch 957/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1371 - accuracy: 0.7998 - val_loss: 6.9476 - val_accuracy: 0.1617\n",
      "Epoch 958/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1370 - accuracy: 0.7997 - val_loss: 6.9494 - val_accuracy: 0.1610\n",
      "Epoch 959/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1373 - accuracy: 0.7994 - val_loss: 6.9472 - val_accuracy: 0.1629\n",
      "Epoch 960/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1360 - accuracy: 0.8000 - val_loss: 6.9506 - val_accuracy: 0.1613\n",
      "Epoch 961/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1348 - accuracy: 0.8005 - val_loss: 6.9485 - val_accuracy: 0.1618\n",
      "Epoch 962/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1342 - accuracy: 0.8004 - val_loss: 6.9526 - val_accuracy: 0.1617\n",
      "Epoch 963/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1354 - accuracy: 0.8001 - val_loss: 6.9536 - val_accuracy: 0.1637\n",
      "Epoch 964/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1368 - accuracy: 0.7996 - val_loss: 6.9554 - val_accuracy: 0.1628\n",
      "Epoch 965/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1345 - accuracy: 0.8005 - val_loss: 6.9575 - val_accuracy: 0.1622\n",
      "Epoch 966/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1327 - accuracy: 0.8009 - val_loss: 6.9552 - val_accuracy: 0.1623\n",
      "Epoch 967/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1318 - accuracy: 0.8009 - val_loss: 6.9599 - val_accuracy: 0.1622\n",
      "Epoch 968/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1303 - accuracy: 0.8013 - val_loss: 6.9588 - val_accuracy: 0.1613\n",
      "Epoch 969/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1308 - accuracy: 0.8010 - val_loss: 6.9557 - val_accuracy: 0.1630\n",
      "Epoch 970/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1308 - accuracy: 0.8009 - val_loss: 6.9597 - val_accuracy: 0.1626\n",
      "Epoch 971/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1295 - accuracy: 0.8015 - val_loss: 6.9597 - val_accuracy: 0.1634\n",
      "Epoch 972/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1297 - accuracy: 0.8015 - val_loss: 6.9573 - val_accuracy: 0.1625\n",
      "Epoch 973/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1293 - accuracy: 0.8014 - val_loss: 6.9596 - val_accuracy: 0.1624\n",
      "Epoch 974/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.1282 - accuracy: 0.8019 - val_loss: 6.9633 - val_accuracy: 0.1631\n",
      "Epoch 975/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1269 - accuracy: 0.8015 - val_loss: 6.9662 - val_accuracy: 0.1614\n",
      "Epoch 976/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1262 - accuracy: 0.8023 - val_loss: 6.9698 - val_accuracy: 0.1614\n",
      "Epoch 977/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1264 - accuracy: 0.8024 - val_loss: 6.9665 - val_accuracy: 0.1623\n",
      "Epoch 978/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1263 - accuracy: 0.8018 - val_loss: 6.9641 - val_accuracy: 0.1619\n",
      "Epoch 979/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.1268 - accuracy: 0.8016 - val_loss: 6.9682 - val_accuracy: 0.1624\n",
      "Epoch 980/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1346 - accuracy: 0.7992 - val_loss: 6.9637 - val_accuracy: 0.1620\n",
      "Epoch 981/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1326 - accuracy: 0.8001 - val_loss: 6.9641 - val_accuracy: 0.1627\n",
      "Epoch 982/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1288 - accuracy: 0.8010 - val_loss: 6.9655 - val_accuracy: 0.1616\n",
      "Epoch 983/1000\n",
      "17/17 [==============================] - 9s 534ms/step - loss: 2.1281 - accuracy: 0.8012 - val_loss: 6.9687 - val_accuracy: 0.1619\n",
      "Epoch 984/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1249 - accuracy: 0.8025 - val_loss: 6.9710 - val_accuracy: 0.1624\n",
      "Epoch 985/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1218 - accuracy: 0.8032 - val_loss: 6.9665 - val_accuracy: 0.1634\n",
      "Epoch 986/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1200 - accuracy: 0.8035 - val_loss: 6.9717 - val_accuracy: 0.1625\n",
      "Epoch 987/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1194 - accuracy: 0.8036 - val_loss: 6.9734 - val_accuracy: 0.1618\n",
      "Epoch 988/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1397 - accuracy: 0.7969 - val_loss: 6.9722 - val_accuracy: 0.1627\n",
      "Epoch 989/1000\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 2.1439 - accuracy: 0.7962 - val_loss: 6.9612 - val_accuracy: 0.1627\n",
      "Epoch 990/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1334 - accuracy: 0.7992 - val_loss: 6.9635 - val_accuracy: 0.1616\n",
      "Epoch 991/1000\n",
      "17/17 [==============================] - 9s 525ms/step - loss: 2.1259 - accuracy: 0.8018 - val_loss: 6.9747 - val_accuracy: 0.1617\n",
      "Epoch 992/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1213 - accuracy: 0.8034 - val_loss: 6.9740 - val_accuracy: 0.1620\n",
      "Epoch 993/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1187 - accuracy: 0.8037 - val_loss: 6.9750 - val_accuracy: 0.1624\n",
      "Epoch 994/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1172 - accuracy: 0.8040 - val_loss: 6.9767 - val_accuracy: 0.1615\n",
      "Epoch 995/1000\n",
      "17/17 [==============================] - 9s 533ms/step - loss: 2.1165 - accuracy: 0.8043 - val_loss: 6.9740 - val_accuracy: 0.1615\n",
      "Epoch 996/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1177 - accuracy: 0.8041 - val_loss: 6.9790 - val_accuracy: 0.1623\n",
      "Epoch 997/1000\n",
      "17/17 [==============================] - 9s 532ms/step - loss: 2.1155 - accuracy: 0.8044 - val_loss: 6.9776 - val_accuracy: 0.1614\n",
      "Epoch 998/1000\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 2.1138 - accuracy: 0.8047 - val_loss: 6.9799 - val_accuracy: 0.1617\n",
      "Epoch 999/1000\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 2.1160 - accuracy: 0.8043 - val_loss: 6.9818 - val_accuracy: 0.1619\n",
      "Epoch 1000/1000\n",
      "17/17 [==============================] - 9s 528ms/step - loss: 2.1155 - accuracy: 0.8042 - val_loss: 6.9794 - val_accuracy: 0.1620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f462c099990>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_word_data, x_seq_data], y_seq_data, \n",
    "          validation_split=0.1,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = 'model_ver6.hdf5'\n",
    "model.save(file_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "file_model = 'model_ver6.hdf5'\n",
    "model = load_model(file_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_generation(model):\n",
    "    tags = ['\\t']\n",
    "    sentence = ''\n",
    "    while tags[-1] != '\\n' and len(tags) < max_seq_length:\n",
    "        x_test_word = np.zeros(shape=(1, n_output_words), dtype='int32')\n",
    "        x_test_seq = np.zeros(shape=(1, max_seq_length), dtype='int32')\n",
    "        x_test_seq[0, -len(tags):] = [w2i_output[w] for w in tags]\n",
    "        result = model.predict([x_test_word, x_test_seq], verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "        tags.append(output_words[result[0]])\n",
    "        sentence += ' ' + tags[-1]\n",
    "    return sentence.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본\n",
      "더메디닥터 클렌징 요즘 클렌징을 로 바꿨는데 피부가 더 깔끔해지고 좋아지고 있는 것 같아요 순수하고 자극이 없어 피부가 민감한분들도 사용하시는거 강추 드립니다 클렌징 하면서 피부에 영양 공급을 해준답니다 임산부 영유아 모두 사용 가능 해용 본 리뷰는 제품을 제공받아 작성 되었습니다\n",
      "['더', '메', '디', '닥터', '클렌징', '요즘', '클렌징', '로', '바꾸', '피부', '더', '깔끔', '지', '좋', '지', '있', '것', '같', '순수', '자극', '없', '피부', '민감', '분', '사용', '거', '강', '추', '드리', '클렌징', '하', '피부', '영양', '공급', '하', '주', '임산부', '영유아', '모두', '사용', '가능', '해', '보', '리뷰', '제품', '제공', '받', '작성', '되']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "예쁘다 내 새끼들\n",
      "['예쁘', '내', '새끼']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "훗 나의 통통하고 멋진 젤리 만져볼텨\n",
      "['훗', '나', '통통', '멋지', '젤리', '만져볼텨']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "감정표현 확실한 댕댕이들 내가 주인인데\n",
      "['감정', '표현', '확실', '댕', '댕', '이', '내', '주인', '이']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "뉴나 이건 내 박스얌 부러우면 누나도 시켜\n",
      "['뉴', '이건', '내', '박스', '얌', '부럽', '누나', '시키']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "현대카드에서 새로 오픈한 피플사진관에서 사진 찍고 왔어요 현대카드 바이닐 앤 플라스틱에 오빠랑 같이 추억 남겼답니다 이용은 무료이고 사진도 여러장 찍을 수 있어서 좋았어요 해시태그 이벤트 참여하면 폴라로이드 사진도 뽑아주셔요 추첨을 통해 경품도 준다고 하니 모두 참여하시고 경품 같이 받아요 본 포스팅은 현대카드에서 소정의 원고료를 받아 작성되었습니다\n",
      "['현대카드', '새로', '오픈', '한', '피플', '사진관', '사진', '찍', '오', '현대카드', '바', '이', '닐', '앤', '플라스틱', '오빠', '같이', '추억', '남기', '이용', '무료', '이', '사진', '여러', '장', '찍', '수', '있', '좋', '해시태그', '이벤트', '참여', '폴라로이드', '사진', '뽑', '주', '시', '추첨', '통하', '경품', '주', '하', '모두', '참여', '경품', '같이', '받', '보', '포', '스팅', '현대카드', '소정', '원고료', '받', '작성']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "아니 이렇게 멋있으면 어떡하죠 커플사진 이라니\n",
      "['아니', '이렇', '멋있', '어떡하', '커플', '사진', '이', '이']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "사랑가득 환한 웃음이 설레임 가득 예뻤던 해붕님 커플이 감스에 방문해주셨습니다 미소에 서로에 대한 예쁜 마음이 더욱 설레고 사랑스럽게 담겨진 사진 한장에 웃음 속 밝음이 두분의 예쁜 사랑을 알리듯 예쁘게 담아졌습니다 행복한 웃음 가득 함께한 시간이 시간가는 줄 모르고 즐겁게 촬영했던 시간이었습니다 감스에서의 소중한 시간 예쁜 추억으로 잘 간직하셨길 기도하며 두분의 사랑 예쁜 웃음만큼 축복합니다 기쁜날 다시 또 만나요\n",
      "['사랑', '가득', '환하', '웃음', '설레임', '가득', '예쁘', '해', '붕', '커플', '감스에', '방문', '주', '미소', '서로', '대하', '예쁘', '마음', '더욱', '설레', '사랑', '담기', '지', '사진', '한장', '웃음', '속', '밝', '두', '분', '예쁘', '사랑', '알리', '예쁘', '담', '지', '행복', '웃음', '가득', '함께', '시간', '시간', '가', '주', '모르', '즐겁', '촬영', '시간', '이', '감스에서의', '소중', '시간', '예쁘', '추억', '잘', '간직', '기도', '두', '분', '사랑', '예쁘', '웃음', '축복', '기쁘', '날', '다시', '또', '만나']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "사랑가득 환한 웃음이 설레임 가득 예뻤던 해붕님 커플이 감스에 방문해주셨습니다 미소에 서로에 대한 예쁜 마음이 더욱 설레고 사랑스럽게 담겨진 사진 한장에 웃음 속 밝음이 두분의 예쁜 사랑을 알리듯 예쁘게 담아졌습니다 행복한 웃음 가득 함께한 시간이 시간가는 줄 모르고 즐겁게 촬영했던 시간이었습니다 감스에서의 소중한 시간 예쁜 추억으로 잘 간직하셨길 기도하며 두분의 사랑 예쁜 웃음만큼 축복합니다 기쁜날 다시 또 만나요\n",
      "['사랑', '가득', '환하', '웃음', '설레임', '가득', '예쁘', '해', '붕', '커플', '감스에', '방문', '주', '미소', '서로', '대하', '예쁘', '마음', '더욱', '설레', '사랑', '담기', '지', '사진', '한장', '웃음', '속', '밝', '두', '분', '예쁘', '사랑', '알리', '예쁘', '담', '지', '행복', '웃음', '가득', '함께', '시간', '시간', '가', '주', '모르', '즐겁', '촬영', '시간', '이', '감스에서의', '소중', '시간', '예쁘', '추억', '잘', '간직', '기도', '두', '분', '사랑', '예쁘', '웃음', '축복', '기쁘', '날', '다시', '또', '만나']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "추억을 담아드리는 사진관 소중한 시간을 사진으로 담아드립니다 흑백사진 평일 만원인기준 인화 액자 점 제공 수정컷 카톡메일 발송 주말의 경우 만원 추가 이벤트 참여시 전체이미지 제공\n",
      "['추억', '담', '드리', '사진관', '소중', '시간', '사진', '담', '드리', '흑백', '사진', '평일', '만', '원인', '기준', '인화', '액자', '점', '제공', '수정', '컷', '카', '톡', '메이', '발송', '주말', '경우', '만원', '추가', '이벤트', '참여', '전체', '이미지', '제공']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "일년만에 사랑가득 환한 웃음이 설레임 가득 예뻤던 정미님 커플이 감스에 방문해주셨습니다 예쁜 미소에 서로에 대한 마음이 더욱 설레고 사랑스럽게 담겨진 사진 한장에 웃음 속 밝음이 두분의 예쁜 사랑을 알리듯 행복하게 담아졌습니다 웃음 가득 함께한 시간이 시간가는 줄 모르고 즐겁게 촬영했던 시간이었습니다 감스에서의 소중한 시간 예쁜 추억으로 잘 간직하셨길 기도하며 두분의 사랑 예쁜 웃음만큼 축복합니다 기쁜날 다시 또 만나요\n",
      "['일', '년', '사랑', '가득', '환하', '웃음', '설레임', '가득', '예쁘', '정미', '커플', '감스에', '방문', '주', '예쁘', '미소', '서로', '대하', '마음', '더욱', '설레', '사랑', '담기', '지', '사진', '한장', '웃음', '속', '밝', '두', '분', '예쁘', '사랑', '알리', '행복', '담', '지', '웃음', '가득', '함께', '시간', '시간', '가', '주', '모르', '즐겁', '촬영', '시간', '이', '감스에서의', '소중', '시간', '예쁘', '추억', '잘', '간직', '기도', '두', '분', '사랑', '예쁘', '웃음', '축복', '기쁘', '날', '다시', '또', '만나']\n",
      "예측\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "따뜻함 속 예쁜 사랑이 담긴 환한 웃음으로 함께한 유영님 커플의 함께한 기념일 촬영이 진행되었습니다 담백하게 손잡고 나란히 서서 웃고 있는 모습에 두분의 사랑과 설렘이 그대로 자연스럽게 담아집니다 사랑하는 연인과 함께하는 사진엔 언제나 그 밝음에 행복함을 담게됩니다 설렘 속 따뜻한 대화와 예쁜 웃음으로 함께한 시간 제게도 예쁘게 전달되었습니다 감스에서의 시간 기쁨의 선물 되셨길바라며 두분의 사랑 축복합니다 기쁜날 다시 또 만나요\n",
      "['따뜻', '속', '예쁘', '사랑', '담기', '환하', '웃음', '함께', '유영', '커플', '함께', '기념일', '촬영', '진행', '담백', '손잡', '나란히', '서서', '웃', '있', '모습', '두', '분', '사랑', '설레', '그대로', '자연', '담', '지', '사랑', '연인', '함께', '사진', '언제나', '그', '밝', '행복', '담', '되', '설레', '속', '따뜻', '대화', '예쁘', '웃음', '함께', '시간', '게도', '예쁘', '전달', '감스에서의', '시간', '기쁨', '선물', '되', '바라', '두', '분', '사랑', '축복', '기쁘', '날', '다시', '또', '만나']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "따뜻함 속 예쁜 사랑이 담긴 환한 웃음으로 함께한 나경님 부부의 함께한 기념일 촬영이 진행되었습니다 담백하게 손잡고 나란히 앉아 함께 웃고 있는 모습에 두분의 사랑과 설렘이 그대로 자연스럽게 담아집니다 사랑하는 연인과 함께하는 사진엔 언제나 그 밝음에 행복함을 담게됩니다 설렘 속 따뜻한 대화와 예쁜 웃음으로 함께한 시간 제게도 예쁘게 전달되었습니다 감스에서의 시간 기쁨의 선물 되셨길바라며 두분의 사랑 축복합니다 기쁜날 다시 또 만나요\n",
      "['따뜻', '속', '예쁘', '사랑', '담기', '환하', '웃음', '함께', '나경', '부부', '함께', '기념일', '촬영', '진행', '담백', '손잡', '나란히', '앉', '함께', '웃', '있', '모습', '두', '분', '사랑', '설레', '그대로', '자연', '담', '지', '사랑', '연인', '함께', '사진', '언제나', '그', '밝', '행복', '담', '되', '설레', '속', '따뜻', '대화', '예쁘', '웃음', '함께', '시간', '게도', '예쁘', '전달', '감스에서의', '시간', '기쁨', '선물', '되', '바라', '두', '분', '사랑', '축복', '기쁘', '날', '다시', '또', '만나']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "어떤 기념하고싶은 날에 사진 한장씩 남겨두세요 한장씩 모아가면 나중에 정말 소중한 기록들이 될거에요\n",
      "['어떤', '기념', '싶', '날', '사진', '한장', '남기', '두', '한장', '모아', '가면', '나중', '정말', '소중', '기록', '되', '거']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "눈에 넣어도 아플녀석\n",
      "['눈', '넣', '아프', '녀석']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "굳이 없는 길을 가려는 거북이 문제가 뭔지 모르는것 같다 어떤 물건에도 관심이 없었는데 가습기라고 만들어놓은 덩어리엔 굉장히 호전적이다\n",
      "['굳이', '없', '길', '가', '거북이', '문제', '뭔', '지', '모르', '것', '같', '어떤', '물건', '관심', '없', '가습기', '라고', '만들', '놓', '덩어리', '굉장히', '호전', '이']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "우리 집 첫째 탠과의 첫 만남 때 사진이에요 여러 아이들 중 박수치면서 이리와 이리와 할 때 가장 먼저 저희 가족에게 달려온 아이였어요 저 때 너무 예뻤네요 지금은 너무 늠름해서 탈이죠\n",
      "['우리', '집', '첫째', '태', '첫', '만남', '때', '사진', '이', '여러', '아이들', '중', '박', '수치', '이', '이리', '이리', '하', '때', '가장', '먼저', '저희', '가족', '달려오', '아이', '이', '저', '때', '너무', '예쁘', '지금', '너무', '늠름', '탈', '이']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "펀딩 꼭 안 하셔도 괜찮아요 지지서명만 해주시면 만 원 상당의 소변자가키트를 참여자 전원에게 무료로 증정해드립니다 펀딩 참여자 펀딩 참여 후 지지서명을 한 서포터님은 결제 종료 후 지지서명 여부를 확인하여 리워드와 선물이 합배송 됩니다 펀딩 미참여자 펀딩 미참여 시 지지서명만 하실 경우 확인이 불가하므로 카플친 위그힐로 인증 캡처를 보내주세요 인증 확인 후 리워드 발송 시기에 맞춰 우편배송 됩니다 위그힐 펀딩 하러 가기\n",
      "['푸', '딩', '꼭', '안', '하', '괜찮', '지지', '서명', '해주시', '이', '만', '원', '상당', '소변', '자가', '키트', '참여자', '전원', '무료', '증정', '드리', '푸', '딩', '참여자', '푸', '딩', '참여', '후', '지지', '서명', '한', '서', '포터', '결제', '종료', '후', '지지', '서명', '여부', '확인', '리', '워드', '선물', '합', '배', '송', '되', '푸', '딩', '미', '참여자', '푸', '딩', '미', '참여', '시', '지지', '서명', '하', '경우', '확인', '불가', '카프', '치', '위그', '힐로', '인증', '캡처', '보내', '주', '인증', '확인', '후', '리', '워드', '발송', '시기', '맞추', '우편', '배', '송', '되', '위그', '힐', '푸', '딩', '하', '가']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "단 시간 안에 펀딩 한 서포터분들께만 드리는 위그힐의 특별한 선물 오픈 후 시간 안에 펀딩 한 서포터님들께 으라차차 위시바 를 추가로 드립니다 이벤트 시간 수 목 리워드 옵션과 관절튼튼위시바 개수와 관계없이 으라차차 에너지바는 개만 추가 증정됩니다 위그힐 펀딩 하러 가기\n",
      "['단', '시간', '안', '푸', '딩', '한', '서', '포터', '분', '드리', '위그', '힐', '특별', '선물', '오픈', '후', '시간', '안', '푸', '딩', '한', '서', '포터', '으', '라', '차차', '위', '시바', '추가', '드리', '이벤트', '시간', '수', '목', '리', '워드', '옵션', '관절', '튼튼', '위', '시바', '개수', '관계없이', '으', '라', '차차', '에너지', '바', '개', '추가', '증정', '위그', '힐', '푸', '딩', '하', '가']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n",
      "원본\n",
      "까비 털을 밀었더니 춥네 그래서 담요 덮었더니 따뜻하고 왜이리 잠이오냐\n",
      "['까', '비', '털', '밀', '춥', '그래서', '담요', '덮', '따뜻', '왜', '이리', '잠', '이']\n",
      "예측\n",
      " 버섯 분리수거 잊어버리 분리수거 잊어버리 정신없 졸리 졸리 탈취 탈취 다만 변색 우이 얼터밋썹 오차 마니 정류장 마늘 애매모호 화안히 말도 르와 에다가 어린이 예정 손톱 공부 공부 공부 테이블 흐트러지 서프라이즈 레몬 얼떨결 프론트 남해금산 엄정 등지 존맛탱 존맛탱 찔리 주차공간 듀크 캐비어 채 일요모오닝 일요모오닝 어째서 간직 안대 오사카 미술관 루즈핏이며 비밀 오랜만 약수역 변 송가 송가 전부 전부 전부 전부 전부 퍼렐 퍼렐 여우 여우 여우 여우 시스루 자라 려구요 상당 따라오 대량 함께 대하 메 베이직 초록 웨이팅 웨이팅 삼시세끼 제 체험 영롱 덜렁 성형 고통 클릭 너뮤좋아 놓치 하지만 하지만 손등 종로구 티 노라 블랙홀 최후의 만찬 서프라이즈 원전 담백꼬숩 인샵이다보니 새집 장도 새집 립스틱 월초 감탄 고만 유럽 갈색 밖 넷플릭스 애용 넷플릭스 후후 수다 끈 은데 하답 들르 려 넘보 로즈마리 미친 사랑 들키 레오 것 것 환상 환상 지옥 풋풋 유발 풋풋 양팔 양팔 양팔 구려 오늘 비트 원평 어네이티브\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_idx = 70\n",
    "end_idx = start_idx + 20\n",
    "for ori, tags in zip(sentence_data[start_idx:end_idx], input_tags[start_idx:end_idx]):\n",
    "    print('원본')\n",
    "    print(ori[1:-1])\n",
    "    print(tags)\n",
    "    print('예측')\n",
    "    print(sequence_generation(model))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['맛집', '오늘', '포인트', '이', '없', '거']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-125-d4df8bf74e1c>:14: BasicLSTMCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_embedding = 64\n",
    "n_hidden = 64\n",
    "learning_rate = 1e-2\n",
    "\n",
    "X = tf.placeholder(tf.int32, shape=(None, max_seq_length))\n",
    "Y = tf.placeholder(tf.int32, shape=(None,))\n",
    "# Y = tf.placeholder(tf.float32, shape=(None,))\n",
    "\n",
    "embedding = tf.Variable(tf.random_uniform((n_output_words, n_embedding), -1, 1))\n",
    "embed = tf.nn.embedding_lookup(embedding, X)\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, embed, dtype=tf.float32)\n",
    "\n",
    "model = tf.layers.dense(tf.reshape(outputs, [-1, max_seq_length*n_hidden]), n_output_words, activation=tf.nn.softmax)\n",
    "# cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "predict = tf.arg_max(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:68:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, \n",
    "                                            log_device_placement=True))\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(6883, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/kernel:0' shape=(128, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/basic_lstm_cell/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(14848, 6883) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(6883,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.08it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Cost: 8.803528 Valid Cost: 8.801259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.22it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0002 Cost: 8.800805 Valid Cost: 8.801259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:05<00:00,  4.19it/s]\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003 Cost: 8.800805 Valid Cost: 8.801259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 10/22 [00:02<00:03,  3.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-490c932012e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         _, loss = sess.run([optimizer, cost], feed_dict={\n\u001b[1;32m     12\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             })\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_epoch = 100\n",
    "\n",
    "# for epoch in tqdm(range(total_epoch)):\n",
    "for epoch in range(total_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(range(n_batch)):\n",
    "#     for batch in range(n_batch):\n",
    "        batch_xs = x_train[batch*batch_size:(batch+1)*batch_size]\n",
    "        batch_ys = y_train[batch*batch_size:(batch+1)*batch_size]\n",
    "        \n",
    "        _, loss = sess.run([optimizer, cost], feed_dict={\n",
    "                X: batch_xs,\n",
    "                Y: batch_ys\n",
    "            })\n",
    "        \n",
    "        total_loss += loss\n",
    "    \n",
    "    total_valid_loss = 0\n",
    "    for batch in range(n_valid):\n",
    "        valid_xs = x_valid[batch*batch_size:(batch+1)*batch_size]\n",
    "        valid_ys = y_valid[batch*batch_size:(batch+1)*batch_size]\n",
    "        \n",
    "        val_loss = sess.run(cost, feed_dict={\n",
    "                X: valid_xs,\n",
    "                Y: valid_ys\n",
    "            })\n",
    "        total_valid_loss += val_loss\n",
    "    \n",
    "    print('Epoch: %04d Cost: %.6f Valid Cost: %.6f' %(epoch + 1, total_loss / n_batch, total_valid_loss / n_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(tags):\n",
    "    x_test = np.zeros(shape=(1, max_seq_length), dtype='float32')\n",
    "    tags = tags + ['\\t']\n",
    "    idx = -len(tags)\n",
    "    x_test[0, idx:] = [w2i_output[w] for w in tags]\n",
    "    while x_test[0, -1] != w2i_output['\\n'] and x_test[0][0] == 0:\n",
    "        print(idx)\n",
    "        pred = sess.run(predict, feed_dict={X: x_test})[0]\n",
    "        x_test[0, idx-1:-1] = x_test[0, idx:]\n",
    "        x_test[0, -1] = pred\n",
    "        idx -= 1\n",
    "    end = np.where(x_test[0]==w2i_output['\\n'])[0]\n",
    "    end = end[0] if end.shape[0] > 0 else -1\n",
    "    ret = x_test[0, np.where(x_test[0]==w2i_output['\\t'])[0][0]:end]\n",
    "    return ''.join([output_words[ret]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7\n",
      "-8\n",
      "-9\n",
      "-10\n",
      "-11\n",
      "-12\n",
      "-13\n",
      "-14\n",
      "-15\n",
      "-16\n",
      "-17\n",
      "-18\n",
      "-19\n",
      "-20\n",
      "-21\n",
      "-22\n",
      "-23\n",
      "-24\n",
      "-25\n",
      "-26\n",
      "-27\n",
      "-28\n",
      "-29\n",
      "-30\n",
      "-31\n",
      "-32\n",
      "-33\n",
      "-34\n",
      "-35\n",
      "-36\n",
      "-37\n",
      "-38\n",
      "-39\n",
      "-40\n",
      "-41\n",
      "-42\n",
      "-43\n",
      "-44\n",
      "-45\n",
      "-46\n",
      "-47\n",
      "-48\n",
      "-49\n",
      "-50\n",
      "-51\n",
      "-52\n",
      "-53\n",
      "-54\n",
      "-55\n",
      "-56\n",
      "-57\n",
      "-58\n",
      "-59\n",
      "-60\n",
      "-61\n",
      "-62\n",
      "-63\n",
      "-64\n",
      "-65\n",
      "-66\n",
      "-67\n",
      "-68\n",
      "-69\n",
      "-70\n",
      "-71\n",
      "-72\n",
      "-73\n",
      "-74\n",
      "-75\n",
      "-76\n",
      "-77\n",
      "-78\n",
      "-79\n",
      "-80\n",
      "-81\n",
      "-82\n",
      "-83\n",
      "-84\n",
      "-85\n",
      "-86\n",
      "-87\n",
      "-88\n",
      "-89\n",
      "-90\n",
      "-91\n",
      "-92\n",
      "-93\n",
      "-94\n",
      "-95\n",
      "-96\n",
      "-97\n",
      "-98\n",
      "-99\n",
      "-100\n",
      "-101\n",
      "-102\n",
      "-103\n",
      "-104\n",
      "-105\n",
      "-106\n",
      "-107\n",
      "-108\n",
      "-109\n",
      "-110\n",
      "-111\n",
      "-112\n",
      "-113\n",
      "-114\n",
      "-115\n",
      "-116\n",
      "-117\n",
      "-118\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-b1de23712143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw2i_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1181\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv_capstone/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tags = input_tags[0]\n",
    "x_test = np.zeros(shape=(1, max_seq_length), dtype='float32')\n",
    "tags = tags + ['\\t']\n",
    "idx = -len(tags)\n",
    "x_test[0, idx:] = [w2i_output[w] for w in tags]\n",
    "while x_test[0, -1] != w2i_output['\\n'] and x_test[0][0] == 0:\n",
    "    print(idx)\n",
    "    pred = sess.run(predict, feed_dict={X: x_test})[0]\n",
    "    x_test[0, idx-1:-1] = x_test[0, idx:]\n",
    "    x_test[0, -1] = pred\n",
    "    idx -= 1\n",
    "end = np.where(x_test[0]==w2i_output['\\n'])[0]\n",
    "end = end[0] if end.shape[0] > 0 else -1\n",
    "ret = x_test[0, np.where(x_test[0]==w2i_output['\\t'])[0][0]:end]\n",
    "''.join([output_words[map(int, ret)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하하'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([output_words[int(i)] for i in ret])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Keich Capstone",
   "language": "python",
   "name": "venv_capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
